# @package _global_
# Acquisition Training Configuration (Surrogate-Free + Surrogate-Aware)

training:
  # Core training parameters
  n_training_steps: 30
  episodes_per_step: 1
  interventions_per_episode: 5
  learning_rate: 0.0003
  
  # GRPO specific settings
  grpo:
    gamma: 0.99
    gae_lambda: 0.95
    clip_epsilon: 0.2
    value_loss_coef: 0.5
    entropy_coef: 0.01
  
  # Architecture settings
  architecture:
    level: "full"  # "baseline", "simplified", "full"
    performance_mode: "balanced"  # "fast", "balanced", "quality"
    use_enhanced_networks: true
  
  # Reward system
  rewards:
    use_verifiable_rewards: true
    weights:
      target_improvement_weight: 2.5
      true_parent_weight: 1.5
      exploration_weight: 0.8
      diversity_weight: 0.3
  
  # Surrogate-aware specific (when applicable)
  surrogate:
    use_surrogate_predictions: false
    checkpoint_path: null
    uncertainty_weight: 1.0
    information_gain_weight: 0.8
  
  # Training optimization
  optimization:
    experience_replay: true
    replay_buffer_size: 1000
    batch_size: 16
  
  # Demo configuration (legacy support)
  demo:
    n_observational_samples: 30
    n_intervention_steps: 20
    intervention_value_range: [-2.0, 2.0]
    scoring_method: "bic"

# Override default checkpointing for acquisition
checkpointing:
  save_frequency: 10
  checkpoint_dir: "${paths.checkpoint_base_dir}/acquisition"

# Override default curriculum thresholds for acquisition
curriculum:
  advancement_thresholds:
    avg_reward: 0.5
    improvement_rate: 0.1