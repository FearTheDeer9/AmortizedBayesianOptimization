# @package training
# High-performance GRPO configuration for large-scale experiments

defaults:
  - grpo_base

algorithm:
  learning_rate: 0.0005  # Higher learning rate
  batch_size: 128        # Larger batches
  entropy_coefficient: 0.005  # Lower for exploitation

experience:
  buffer_size: 50000     # Larger buffer
  prioritized_replay: true
  min_experiences_before_training: 500

optimization:
  eval_frequency: 50     # More frequent evaluation
  checkpoint_frequency: 200
