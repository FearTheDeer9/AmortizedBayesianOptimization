# Configuration for target optimization trajectory experiment

experiment:
  name: "target_optimization"
  description: "Core optimization performance evaluation across scales"
  seed: 42

# Evaluation settings
evaluation:
  # Graph sizes to test - start small, scale up
  graph_sizes: [10, 20, 50, 100]
  
  # Number of graphs per size for statistical significance
  n_graphs_per_size: 5
  
  # Intervention budget per graph
  n_interventions: 50
  
  # Track additional metrics beyond target optimization
  track_parent_accuracy: true
  track_exploration_diversity: true
  track_convergence_rate: true

# SCM generation settings
scm_generation:
  structure_types: ["random", "chain"]  # Test different structures
  edge_density: 0.3
  mechanism_type: "linear"
  noise_std: 0.1

# Data generation
data_generation:
  n_observational_samples: 100  # Initial observational data
  
# Model pairings to evaluate
pairings:
  # Baselines
  - name: "Random"
    policy_type: "random"
    description: "Random intervention baseline"
    
  - name: "Oracle"
    policy_type: "oracle" 
    description: "Perfect knowledge upper bound"
    
  # Untrained models
  - name: "Untrained Policy"
    policy_type: "untrained"
    policy_architecture: "simple_permutation_invariant"
    description: "Randomly initialized policy"
    
  - name: "Untrained Policy + Untrained Surrogate"
    policy_type: "untrained"
    surrogate_type: "untrained"
    description: "Both models randomly initialized"
    
  # Trained models (auto-discovered from checkpoints)
  - name: "Joint Trained" 
    policy_checkpoint: "auto_discover"  # Will find joint training checkpoints
    surrogate_checkpoint: "auto_discover"
    description: "Joint trained policy and surrogate"
    
  - name: "Policy Only Trained"
    policy_checkpoint: "auto_discover_policy_only"
    description: "Trained policy without surrogate"

# Metrics to track during optimization
metrics:
  trajectory_metrics:
    - "target_value"           # Primary optimization target
    - "intervention_variable"  # Which variable was chosen
    - "intervention_value"     # Value of intervention
    - "is_parent_intervention" # Whether variable is true parent
    - "cumulative_regret"      # Running regret calculation
    
  convergence_metrics:
    - "final_target_value"     # Final achieved value
    - "best_target_value"      # Best value during trajectory
    - "convergence_rate"       # Rate of improvement
    - "interventions_to_threshold" # Sample efficiency
    
  structure_metrics:
    - "parent_accuracy"        # Fraction of parent interventions
    - "exploration_diversity"  # Diversity of variable selection
    - "variable_coverage"      # Fraction of variables tried

# Analysis settings
analysis:
  # Convergence analysis
  convergence_thresholds: [-2.0, -5.0, -8.0]  # Multiple thresholds
  smoothing_window: 5  # For trajectory smoothing
  
  # Statistical analysis
  confidence_level: 0.95
  bootstrap_samples: 1000
  
  # Comparison analysis
  compare_to_oracle: true
  normalize_by_oracle: true
  compute_regret_bounds: true

# Output settings
output:
  save_trajectories: true
  save_intervention_details: true
  generate_plots: true
  create_summary_table: true
  export_latex: true

# Plotting configuration
plotting:
  trajectory_plots:
    show_confidence_intervals: true
    highlight_parent_interventions: true
    separate_by_graph_size: true
    
  convergence_plots:
    show_convergence_rates: true
    mark_threshold_crossings: true
    
  comparison_plots:
    method_ranking_table: true
    performance_radar_chart: true

# Resource limits
resource_limits:
  max_time_per_trajectory: 300  # 5 minutes per trajectory
  max_total_experiment_time: 7200  # 2 hours total
  
# Logging
logging:
  level: "INFO"
  save_detailed_logs: true
  log_intervention_details: false  # Set true for debugging