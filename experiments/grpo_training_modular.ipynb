{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRPO Training Pipeline - Modular Version\n",
    "\n",
    "**Purpose**: Train GRPO policies with explicit optimization direction support and modular execution.\n",
    "\n",
    "**Key Features**:\n",
    "- ‚úÖ **No silent failures** - explicit errors when things go wrong\n",
    "- ‚úÖ **Independent cells** - run any cell with checkpoint support\n",
    "- ‚úÖ **Optimization direction** - support both MINIMIZE and MAXIMIZE\n",
    "- ‚úÖ **Clean checkpoint management** - save/load with full metadata\n",
    "- ‚úÖ **Consistent with PARENT_SCALE** - correct handling of minimization objective\n",
    "\n",
    "**Workflow**:\n",
    "1. Configure training parameters and optimization direction\n",
    "2. Load existing checkpoint OR initialize new training\n",
    "3. Generate or load training SCMs\n",
    "4. Train with appropriate reward signals\n",
    "5. Save checkpoint with complete metadata\n",
    "6. Quick validation with correct metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment Setup Complete\n",
      "üìÅ Project root: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt\n",
      "üîß JAX devices: [CpuDevice(id=0)]\n",
      "üîß JAX backend: cpu\n",
      "üìÖ Date: 2025-07-28 15:47:22\n",
      "\n",
      "üîß Using GRPO configuration with collapse prevention fixes:\n",
      "  - Global standardization for state enrichment\n",
      "  - Increased entropy coefficient (0.1)\n",
      "  - Bootstrap surrogate with structural priors\n",
      "  - Adaptive reward system\n",
      "\n",
      "üìÅ Checkpoint directory: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/checkpoints/grpo_training\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Cell 1: Import base components and configure environment\n",
    "\n",
    "This cell can be run independently at any time.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent if Path.cwd().name == \"experiments\" else Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import base components\n",
    "from scripts.notebooks.base_components import (\n",
    "    NotebookError, CheckpointManager, SCMGenerator, \n",
    "    OptimizationConfig, CheckpointMetadata, validate_environment,\n",
    "    format_results_summary\n",
    ")\n",
    "from scripts.notebooks.config_templates import (\n",
    "    create_training_config, TRAINING_MODES, OBJECTIVE_CONFIGS,\n",
    "    get_quick_minimize_config, get_quick_maximize_config\n",
    ")\n",
    "\n",
    "# Import fixed configuration\n",
    "from src.causal_bayes_opt.training.grpo_fixed_config import (\n",
    "    create_grpo_config_with_fixes,\n",
    "    create_bootstrap_phase_config,\n",
    "    create_bootstrap_config,\n",
    "    validate_fixed_config\n",
    ")\n",
    "\n",
    "# Core imports\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as random\n",
    "import numpy as onp\n",
    "import pyrsistent as pyr\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Validate environment\n",
    "try:\n",
    "    env_info = validate_environment()\n",
    "    print(\"‚úÖ Environment Setup Complete\")\n",
    "    print(f\"üìÅ Project root: {project_root}\")\n",
    "    print(f\"üîß JAX devices: {env_info['jax_devices']}\")\n",
    "    print(f\"üîß JAX backend: {env_info['jax_backend']}\")\n",
    "    print(f\"üìÖ Date: {env_info['timestamp']}\")\n",
    "    print(\"\\nüîß Using GRPO configuration with collapse prevention fixes:\")\n",
    "    print(\"  - Global standardization for state enrichment\")\n",
    "    print(\"  - Increased entropy coefficient (0.1)\")\n",
    "    print(\"  - Bootstrap surrogate with structural priors\")\n",
    "    print(\"  - Adaptive reward system\")\n",
    "except Exception as e:\n",
    "    raise NotebookError(f\"Environment validation failed: {e}\")\n",
    "\n",
    "# Initialize checkpoint manager\n",
    "checkpoint_dir = project_root / \"checkpoints\" / \"grpo_training\"\n",
    "checkpoint_manager = CheckpointManager(checkpoint_dir)\n",
    "print(f\"\\nüìÅ Checkpoint directory: {checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Training Configuration\n",
      "==================================================\n",
      "Mode: FULL - Production-quality training\n",
      "Objective: TARGET_MINIMIZE - Minimize target variable (like PARENT_SCALE)\n",
      "Optimization: MINIMIZE\n",
      "Random seed: 42\n",
      "\n",
      "Training parameters:\n",
      "  Total episodes: 512\n",
      "  Episode length: 12\n",
      "  Learning rate: 0.001\n",
      "  Number of SCMs: 64\n",
      "\n",
      "Reward weights:\n",
      "  optimization: 0.8\n",
      "  discovery: 0.1\n",
      "  efficiency: 0.1\n",
      "\n",
      "üöÄ Will train from scratch\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cell 2: Configure training parameters\n",
    "\n",
    "Choose training mode and optimization objective.\n",
    "This cell defines what kind of training will be performed.\n",
    "\"\"\"\n",
    "\n",
    "# SELECT TRAINING CONFIGURATION\n",
    "TRAINING_MODE = \"FULL\"  # Options: \"QUICK\", \"STANDARD\", \"FULL\", \"PRECISION\"\n",
    "OPTIMIZATION_OBJECTIVE = \"TARGET_MINIMIZE\"  # Options: \"TARGET_MINIMIZE\", \"TARGET_MAXIMIZE\", \"STRUCTURE_FOCUSED\", \"BALANCED\"\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Optional: Load from existing checkpoint (set to None to train from scratch)\n",
    "RESUME_FROM_CHECKPOINT = None  # Or path like \"checkpoints/grpo_training/grpo_minimize_20250722_120000\"\n",
    "\n",
    "# Create configuration\n",
    "try:\n",
    "    config = create_training_config(\n",
    "        mode=TRAINING_MODE,\n",
    "        objective=OPTIMIZATION_OBJECTIVE,\n",
    "        random_seed=RANDOM_SEED,\n",
    "        checkpoint_dir=str(checkpoint_dir)\n",
    "    )\n",
    "    \n",
    "    # Create optimization config\n",
    "    optimization_config = OptimizationConfig(\n",
    "        direction=config.optimization.direction,\n",
    "        target_baseline=config.optimization.target_baseline\n",
    "    )\n",
    "    \n",
    "    print(\"üéØ Training Configuration\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Mode: {TRAINING_MODE} - {TRAINING_MODES[TRAINING_MODE].description}\")\n",
    "    print(f\"Objective: {OPTIMIZATION_OBJECTIVE} - {OBJECTIVE_CONFIGS[OPTIMIZATION_OBJECTIVE].description}\")\n",
    "    print(f\"Optimization: {optimization_config.direction}\")\n",
    "    print(f\"Random seed: {RANDOM_SEED}\")\n",
    "    print(f\"\\nTraining parameters:\")\n",
    "    print(f\"  Total episodes: {config.training.n_episodes}\")\n",
    "    print(f\"  Episode length: {config.training.episode_length}\")\n",
    "    print(f\"  Learning rate: {config.training.learning_rate}\")\n",
    "    print(f\"  Number of SCMs: {config.experiment.scm_generation.num_scms}\")  # Fixed path\n",
    "    print(f\"\\nReward weights:\")\n",
    "    for component, weight in config.training.reward_weights.items():\n",
    "        print(f\"  {component}: {weight}\")\n",
    "    \n",
    "    if RESUME_FROM_CHECKPOINT:\n",
    "        print(f\"\\nüîÑ Will resume from: {RESUME_FROM_CHECKPOINT}\")\n",
    "    else:\n",
    "        print(f\"\\nüöÄ Will train from scratch\")\n",
    "        \n",
    "except Exception as e:\n",
    "    raise NotebookError(f\"Failed to create configuration: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Creating GRPO configuration with collapse prevention fixes\n",
      "‚úÖ Configuration validation passed\n",
      "\n",
      "üìä Key configuration parameters:\n",
      "  Entropy coefficient: 0.1\n",
      "  Standardization: Global\n",
      "  Bootstrap surrogate: Enabled\n",
      "  Adaptive rewards: Enabled\n",
      "  Structure threshold: 0.95\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cell 2.5: Create GRPO configuration with collapse prevention fixes\n",
    "\n",
    "This cell creates the enhanced GRPO configuration that prevents posterior collapse.\n",
    "\"\"\"\n",
    "\n",
    "# Create GRPO configuration with fixes\n",
    "USE_COLLAPSE_FIXES = True  # Set to False to use original configuration\n",
    "\n",
    "if USE_COLLAPSE_FIXES:\n",
    "    print(\"üîß Creating GRPO configuration with collapse prevention fixes\")\n",
    "    \n",
    "    # Create fixed configuration\n",
    "    fixed_grpo_config = create_grpo_config_with_fixes(\n",
    "        max_training_steps=50000,\n",
    "        batch_size=64,\n",
    "        group_size=64,\n",
    "        use_bootstrap=True,\n",
    "        use_adaptive_rewards=True,\n",
    "        entropy_coefficient=0.1  # Increased from default 0.01\n",
    "    )\n",
    "    \n",
    "    # Create phase configurations for bootstrap\n",
    "    phase_config = create_bootstrap_phase_config(\n",
    "        bootstrap_steps=100,\n",
    "        transition_steps=50\n",
    "    )\n",
    "    \n",
    "    bootstrap_config = create_bootstrap_config()\n",
    "    \n",
    "    # Validate configuration\n",
    "    try:\n",
    "        validate_fixed_config(fixed_grpo_config)\n",
    "        print(\"‚úÖ Configuration validation passed\")\n",
    "    except ValueError as e:\n",
    "        print(f\"‚ö†Ô∏è Configuration warning: {e}\")\n",
    "    \n",
    "    # Update the training config with fixed parameters\n",
    "    if 'config' in locals():\n",
    "        # Update entropy coefficient\n",
    "        config.training.grpo_config.entropy_coeff = 0.1\n",
    "        \n",
    "        # Add state enrichment configuration\n",
    "        config.training.state_enrichment = {\n",
    "            'standardize_values': True,\n",
    "            'use_global_standardization': True,\n",
    "            'channels': ['values', 'interventions', 'target', 'parent_probs', 'recency']\n",
    "        }\n",
    "        \n",
    "        # Add adaptive rewards configuration\n",
    "        config.training.adaptive_rewards = {\n",
    "            'enabled': True,\n",
    "            'structure_threshold': 0.95,\n",
    "            'adaptation_rate': 0.1,\n",
    "            'initial_weights': {'discovery': 0.7, 'optimization': 0.3},\n",
    "            'final_weights': {'discovery': 0.05, 'optimization': 0.95},\n",
    "            'update_frequency': 10\n",
    "        }\n",
    "        \n",
    "        print(\"\\nüìä Key configuration parameters:\")\n",
    "        print(f\"  Entropy coefficient: {config.training.grpo_config.entropy_coeff}\")\n",
    "        print(f\"  Standardization: Global\")\n",
    "        print(f\"  Bootstrap surrogate: Enabled\")\n",
    "        print(f\"  Adaptive rewards: Enabled\")\n",
    "        print(f\"  Structure threshold: 0.95\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Using original configuration (may experience collapse)\")\n",
    "    print(\"  Set USE_COLLAPSE_FIXES = True to use fixed configuration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üõë Configuring Early Stopping...\n",
      "‚úì Early stopping enabled with improved parameters\n",
      "  - Convergence threshold: 0.95\n",
      "  - Patience: 5 episodes\n",
      "  - Min episodes per SCM: 5\n",
      "  - Max episodes per SCM: 30\n",
      "  - Reward variance threshold: 0.05\n",
      "‚úì Global standardization verified\n",
      "\n",
      "üìä Expected behavior with early stopping (FIXED):\n",
      "  - Training will progress through SCMs dynamically\n",
      "  - Simple SCMs (3-var) may converge in 5-10 episodes\n",
      "  - Complex SCMs (5-6 var) may take 15-25 episodes\n",
      "  - Overall training distribution should be ~40-60% discovery\n",
      "  - Prevents posterior collapse from over-training\n",
      "\n",
      "‚ö†Ô∏è Note: Episode counting bug has been fixed!\n",
      "  Each SCM will now track episodes correctly\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cell 2.6: Configure Early Stopping (NEW - Prevents Over-training)\n",
    "\n",
    "This cell enables early stopping to prevent over-training on solved SCMs\n",
    "and maintain a balanced exploration/exploitation distribution.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nüõë Configuring Early Stopping...\")\n",
    "\n",
    "# Enable early stopping to prevent over-training on solved SCMs\n",
    "early_stopping_config = {\n",
    "    'early_stopping_enabled': True,\n",
    "    'convergence_accuracy_threshold': 0.95,  # Consider converged at 95% accuracy\n",
    "    'convergence_patience': 5,                # Reduced from 10 - wait 5 episodes before declaring convergence\n",
    "    'min_episodes_per_scm': 5,               # Reduced from 10 - train at least 5 episodes per SCM\n",
    "    'max_episodes_per_scm': 30,              # Reduced from 50 - stop after 30 episodes even if not converged\n",
    "    'reward_variance_threshold': 0.05        # Tighter threshold - was 0.1\n",
    "}\n",
    "\n",
    "# Update the configuration\n",
    "config.training.update(early_stopping_config)\n",
    "\n",
    "print(\"‚úì Early stopping enabled with improved parameters\")\n",
    "print(f\"  - Convergence threshold: {early_stopping_config['convergence_accuracy_threshold']}\")\n",
    "print(f\"  - Patience: {early_stopping_config['convergence_patience']} episodes\")\n",
    "print(f\"  - Min episodes per SCM: {early_stopping_config['min_episodes_per_scm']}\")\n",
    "print(f\"  - Max episodes per SCM: {early_stopping_config['max_episodes_per_scm']}\")\n",
    "print(f\"  - Reward variance threshold: {early_stopping_config['reward_variance_threshold']}\")\n",
    "\n",
    "# Also ensure the fixed entropy coefficient is maintained\n",
    "if hasattr(config.training, 'grpo_config'):\n",
    "    current_entropy = config.training.grpo_config.get('entropy_coeff', 0.01)\n",
    "    if current_entropy < 0.1:\n",
    "        config.training.grpo_config['entropy_coeff'] = 0.1\n",
    "        print(f\"\\n‚úì Maintained entropy coefficient: {current_entropy} ‚Üí {config.training.grpo_config['entropy_coeff']}\")\n",
    "\n",
    "# Ensure global standardization is enabled\n",
    "if hasattr(config.training, 'state_config'):\n",
    "    config.training.state_config['standardize_values'] = True\n",
    "    config.training.state_config['use_global_standardization'] = True\n",
    "    print(\"‚úì Global standardization verified\")\n",
    "else:\n",
    "    # Add state config if missing\n",
    "    config.training['state_config'] = {\n",
    "        'standardize_values': True,\n",
    "        'use_global_standardization': True\n",
    "    }\n",
    "    print(\"‚úì Added state config with global standardization\")\n",
    "\n",
    "print(\"\\nüìä Expected behavior with early stopping (FIXED):\")\n",
    "print(\"  - Training will progress through SCMs dynamically\")\n",
    "print(\"  - Simple SCMs (3-var) may converge in 5-10 episodes\")\n",
    "print(\"  - Complex SCMs (5-6 var) may take 15-25 episodes\")\n",
    "print(\"  - Overall training distribution should be ~40-60% discovery\")\n",
    "print(\"  - Prevents posterior collapse from over-training\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è Note: Episode counting bug has been fixed!\")\n",
    "print(\"  Each SCM will now track episodes correctly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize or Load Training State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Initializing new training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X1'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 3 vars, 2 edges, target=X1\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 3 vars, 2 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X1'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 3 vars, 2 edges, target=X1\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X1'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 3 vars, 2 edges, target=X1\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 4 vars, 3 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X3'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 4 vars, 3 edges, target=X3\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 4 vars, 3 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 4 vars, 3 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 5 vars, 4 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X4'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 5 vars, 4 edges, target=X4\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 5 vars, 4 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 5 vars, 4 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X3'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 6 vars, 5 edges, target=X3\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X5'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 6 vars, 5 edges, target=X5\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X3'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 6 vars, 5 edges, target=X3\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X4'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 6 vars, 5 edges, target=X4\n",
      "INFO:causal_bayes_opt.training.modular_trainer:Created 16 variable SCMs for training\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Using optimized GRPO config: group_size=64, interventions_per_state=8\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Correct GRPO Config: group_size=64, lr=0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Correct GRPO Config: entropy_coeff=0.100, clip_ratio=0.20\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Initialized trainer with 6 max variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:GRPO group size: 64, update frequency: 1 episodes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Trainer initialized successfully\n",
      "  Optimization: MINIMIZE\n",
      "  Surrogate integration: Enabled\n",
      "\n",
      "‚úÖ Training state ready\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cell 3: Initialize new training or load from checkpoint\n",
    "\n",
    "This cell handles checkpoint loading and training initialization.\n",
    "Can be run independently to load a specific checkpoint.\n",
    "\"\"\"\n",
    "\n",
    "# Import trainer and related modules\n",
    "try:\n",
    "    from causal_bayes_opt.training.enriched_trainer import EnrichedGRPOTrainer\n",
    "    from causal_bayes_opt.surrogate.bootstrap import create_bootstrap_surrogate_features\n",
    "    from causal_bayes_opt.surrogate.phase_manager import PhaseConfig, BootstrapConfig\n",
    "except ImportError as e:\n",
    "    raise NotebookError(f\"Failed to import training modules: {e}\")\n",
    "\n",
    "# Production phase configuration\n",
    "PRODUCTION_PHASE_CONFIG = PhaseConfig(\n",
    "    bootstrap_steps=100,\n",
    "    transition_steps=50,\n",
    "    exploration_noise_start=0.5,\n",
    "    exploration_noise_end=0.1,\n",
    "    transition_schedule=\"linear\"\n",
    ")\n",
    "\n",
    "PRODUCTION_BOOTSTRAP_CONFIG = BootstrapConfig(\n",
    "    structure_encoding_dim=128,\n",
    "    use_graph_distance=True,\n",
    "    use_structural_priors=True,\n",
    "    noise_schedule=\"exponential_decay\",\n",
    "    min_noise_factor=0.1\n",
    ")\n",
    "\n",
    "# Update config with production settings\n",
    "config.surrogate_integration = {\n",
    "    'enabled': True,\n",
    "    'phase_config': {\n",
    "        'bootstrap_steps': PRODUCTION_PHASE_CONFIG.bootstrap_steps,\n",
    "        'transition_steps': PRODUCTION_PHASE_CONFIG.transition_steps,\n",
    "        'exploration_noise_start': PRODUCTION_PHASE_CONFIG.exploration_noise_start,\n",
    "        'exploration_noise_end': PRODUCTION_PHASE_CONFIG.exploration_noise_end,\n",
    "        'transition_schedule': PRODUCTION_PHASE_CONFIG.transition_schedule\n",
    "    },\n",
    "    'bootstrap_config': {\n",
    "        'structure_encoding_dim': PRODUCTION_BOOTSTRAP_CONFIG.structure_encoding_dim,\n",
    "        'use_graph_distance': PRODUCTION_BOOTSTRAP_CONFIG.use_graph_distance,\n",
    "        'use_structural_priors': PRODUCTION_BOOTSTRAP_CONFIG.use_structural_priors,\n",
    "        'noise_schedule': PRODUCTION_BOOTSTRAP_CONFIG.noise_schedule,\n",
    "        'min_noise_factor': PRODUCTION_BOOTSTRAP_CONFIG.min_noise_factor\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize trainer state\n",
    "trainer = None\n",
    "starting_episode = 0\n",
    "checkpoint_metadata = None\n",
    "\n",
    "if RESUME_FROM_CHECKPOINT:\n",
    "    print(f\"üì• Loading checkpoint: {RESUME_FROM_CHECKPOINT}\")\n",
    "    try:\n",
    "        checkpoint_data, checkpoint_metadata = checkpoint_manager.load_checkpoint(RESUME_FROM_CHECKPOINT)\n",
    "        \n",
    "        # Validate compatibility\n",
    "        if checkpoint_metadata.optimization_config.direction != optimization_config.direction:\n",
    "            raise NotebookError(\n",
    "                f\"Optimization direction mismatch! \"\n",
    "                f\"Checkpoint: {checkpoint_metadata.optimization_config.direction}, \"\n",
    "                f\"Config: {optimization_config.direction}\"\n",
    "            )\n",
    "        \n",
    "        print(f\"‚úÖ Loaded checkpoint: {checkpoint_metadata.name}\")\n",
    "        print(f\"  Training mode: {checkpoint_metadata.training_config.get('mode', 'unknown')}\")\n",
    "        print(f\"  Optimization: {checkpoint_metadata.optimization_config.direction}\")\n",
    "        print(f\"  Timestamp: {checkpoint_metadata.timestamp}\")\n",
    "        \n",
    "        # TODO: Actually load trainer state from checkpoint_data\n",
    "        # For now, we'll initialize a new trainer\n",
    "        trainer = EnrichedGRPOTrainer(config=config)\n",
    "        starting_episode = checkpoint_metadata.training_results.get('episodes_completed', 0)\n",
    "        \n",
    "        print(f\"  Starting from episode: {starting_episode}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise NotebookError(f\"Failed to load checkpoint: {e}\")\n",
    "else:\n",
    "    print(\"üöÄ Initializing new training\")\n",
    "    try:\n",
    "        # Add optimization direction to config\n",
    "        config.optimization = optimization_config.__dict__\n",
    "        \n",
    "        # Initialize trainer\n",
    "        trainer = EnrichedGRPOTrainer(config=config)\n",
    "        \n",
    "        print(\"‚úÖ Trainer initialized successfully\")\n",
    "        print(f\"  Optimization: {optimization_config.direction}\")\n",
    "        print(f\"  Surrogate integration: {'Enabled' if config.surrogate_integration.enabled else 'Disabled'}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise NotebookError(f\"Failed to initialize trainer: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ Training state ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate or Load Training SCMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X1'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 3 vars, 2 edges, target=X1\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X1'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 3 vars, 2 edges, target=X1\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X1'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 3 vars, 2 edges, target=X1\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X1'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 3 vars, 2 edges, target=X1\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 4 vars, 3 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 4 vars, 3 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 4 vars, 3 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 4 vars, 3 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 5 vars, 4 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 5 vars, 4 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 5 vars, 4 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 5 vars, 4 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X3'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 6 vars, 5 edges, target=X3\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X3'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 6 vars, 5 edges, target=X3\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X3'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 6 vars, 5 edges, target=X3\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X3'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 6 vars, 5 edges, target=X3\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 3 vars, 2 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 3 vars, 2 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 3 vars, 2 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 3 vars, 2 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X3'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 4 vars, 3 edges, target=X3\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X3'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 4 vars, 3 edges, target=X3\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X3'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 4 vars, 3 edges, target=X3\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X3'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 4 vars, 3 edges, target=X3\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X4'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 5 vars, 4 edges, target=X4\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X4'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 5 vars, 4 edges, target=X4\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X4'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 5 vars, 4 edges, target=X4\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X4'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 5 vars, 4 edges, target=X4\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X5'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 6 vars, 5 edges, target=X5\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X5'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 6 vars, 5 edges, target=X5\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X5'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 6 vars, 5 edges, target=X5\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X5'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 6 vars, 5 edges, target=X5\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X1'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 3 vars, 2 edges, target=X1\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X1'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 3 vars, 2 edges, target=X1\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X1'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 3 vars, 2 edges, target=X1\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X1'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 3 vars, 2 edges, target=X1\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 4 vars, 3 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 4 vars, 3 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 4 vars, 3 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 4 vars, 3 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 5 vars, 4 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 5 vars, 4 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 5 vars, 4 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 5 vars, 4 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X3'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 6 vars, 5 edges, target=X3\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X3'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 6 vars, 5 edges, target=X3\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X3'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 6 vars, 5 edges, target=X3\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X3'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 6 vars, 5 edges, target=X3\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 3 vars, 2 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X1'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 3 vars, 2 edges, target=X1\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 3 vars, 2 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 3 vars, 2 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X1'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 4 vars, 3 edges, target=X1\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 4 vars, 3 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X1'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 4 vars, 3 edges, target=X1\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 4 vars, 3 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X3'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 5 vars, 4 edges, target=X3\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 5 vars, 4 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X4'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 5 vars, 4 edges, target=X4\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X1'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 5 vars, 4 edges, target=X1\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 6 vars, 5 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X1'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 6 vars, 5 edges, target=X1\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X1'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 6 vars, 5 edges, target=X1\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X1'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 6 vars, 5 edges, target=X1\n",
      "INFO:scripts.notebooks.base_components:Generated 64 SCMs\n",
      "INFO:scripts.notebooks.base_components:Distribution: {'structure_types': {'fork': 16, 'chain': 16, 'collider': 16, 'mixed': 16}, 'variable_counts': {3: 16, 4: 16, 5: 16, 6: 16}, 'total': 64}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ Generating Training SCMs\n",
      "==================================================\n",
      "\n",
      "‚úÖ Generated 64 training SCMs\n",
      "\n",
      "üìä SCM Distribution:\n",
      "  Structure types: {'fork': 16, 'chain': 16, 'collider': 16, 'mixed': 16}\n",
      "  Variable counts: {3: 16, 4: 16, 5: 16, 6: 16}\n",
      "\n",
      "üìà Training schedule:\n",
      "  Episodes per SCM: 8\n",
      "  Total episodes: 512\n",
      "\n",
      "üíæ Saved SCM metadata to: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/checkpoints/grpo_training/training_scms/scms_FULL_42.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cell 4: Generate training SCMs\n",
    "\n",
    "This cell generates the SCMs for training.\n",
    "Can be run independently to regenerate SCMs.\n",
    "\"\"\"\n",
    "\n",
    "print(\"üî¨ Generating Training SCMs\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Initialize SCM generator\n",
    "scm_generator = SCMGenerator()\n",
    "\n",
    "# Generate SCMs\n",
    "try:\n",
    "    training_scms, scm_metadata = scm_generator.generate_balanced_scms(\n",
    "        num_scms=config.experiment.scm_generation.num_scms,\n",
    "        variable_range=tuple(config.experiment.scm_generation.variable_range),\n",
    "        structure_types=config.experiment.scm_generation.structure_types,\n",
    "        seed=RANDOM_SEED\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ Generated {len(training_scms)} training SCMs\")\n",
    "    \n",
    "    # Analyze distribution\n",
    "    distribution = scm_generator._summarize_distribution(scm_metadata)\n",
    "    print(f\"\\nüìä SCM Distribution:\")\n",
    "    print(f\"  Structure types: {distribution['structure_types']}\")\n",
    "    print(f\"  Variable counts: {distribution['variable_counts']}\")\n",
    "    \n",
    "    # Calculate total episodes\n",
    "    episodes_per_scm = config.training.n_episodes // len(training_scms)\n",
    "    total_episodes = len(training_scms) * episodes_per_scm\n",
    "    print(f\"\\nüìà Training schedule:\")\n",
    "    print(f\"  Episodes per SCM: {episodes_per_scm}\")\n",
    "    print(f\"  Total episodes: {total_episodes}\")\n",
    "    \n",
    "    # Store in config for trainer\n",
    "    config.training.n_episodes = total_episodes\n",
    "    \n",
    "except Exception as e:\n",
    "    raise NotebookError(f\"Failed to generate SCMs: {e}\")\n",
    "\n",
    "# Optional: Save SCMs for reproducibility\n",
    "scm_save_path = checkpoint_dir / \"training_scms\" / f\"scms_{TRAINING_MODE}_{RANDOM_SEED}.json\"\n",
    "scm_save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save metadata only (SCMs are too complex to serialize directly)\n",
    "with open(scm_save_path, 'w') as f:\n",
    "    json.dump({\n",
    "        'metadata': scm_metadata,\n",
    "        'config': {\n",
    "            'num_scms': len(training_scms),\n",
    "            'seed': RANDOM_SEED,\n",
    "            'variable_range': list(config.experiment.scm_generation.variable_range),\n",
    "            'structure_types': list(config.experiment.scm_generation.structure_types)\n",
    "        }\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"\\nüíæ Saved SCM metadata to: {scm_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train GRPO Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causal_bayes_opt.training.enriched_trainer:Starting enriched GRPO training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting GRPO Policy Training\n",
      "======================================================================\n",
      "üîß Training mode: FULL\n",
      "üéØ Optimization: MINIMIZE\n",
      "üìä Total episodes: 512\n",
      "‚öñÔ∏è Reward weights: {'optimization': 0.8, 'discovery': 0.1, 'efficiency': 0.1}\n",
      "‚úÖ Surrogate integration: ACTIVE\n",
      "======================================================================\n",
      "\n",
      "üèÉ Starting Training Loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 10):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 0.e+00 -1.e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 2.00\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.0000, Std: 1.0000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.50\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -2.0168\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 10):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -2.016810864566476)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -2.016810864566476}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.20168108645664762}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.701681\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.701681\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000053826255\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 0: reward=0.607, intervention_rate=1.000, scm=fork_3var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 20):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.36303926e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 2.00\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2222, Std: 1.2048\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.50\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.7664\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 20):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 0.7664039437804)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 0.7664039437804}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.07664039437804}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.576640\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.576640\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000032954101\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 30):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.87292124e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.99\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.1985, Std: 1.2117\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.50\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.0577\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 30):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -1.0576687494064116)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -1.0576687494064116}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.10576687494064117}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.605767\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.605767\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000020047627\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 40):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.0589462e-01 -1.0000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.99\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.1599, Std: 1.2162\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.50\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -4.2230\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 40):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -4.223034587066309)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -4.223034587066309}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.4223034587066309}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.922303\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.922303\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.922) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000015780894\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 50):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-6.52275278e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.99\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.1642, Std: 1.1895\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.50\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.8221\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 50):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -1.8220579769857308)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -1.8220579769857308}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.1822057976985731}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.682206\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.682206\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 60):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.98034478e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.99\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.1243, Std: 1.1469\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.50\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.7444\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 60):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 2.7444268071846327)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 2.7444268071846327}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.2744426807184633}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.774443\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.774443\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000071256752\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 5):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=3.049111\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.619\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00007126\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00007126\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.508, max=0.805, group_baseline=0.621\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.323629, entropy=-2.344277\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.74174102\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 2.546611\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 70):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.02597987 -0.09961065]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: -0.09961064688836901\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.99\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.50927069 0.49072931]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.1676, Std: 1.1848\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.50\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.3831\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 70):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 1.3831147631102705)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 1.3831147631102705}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.13831147631102705}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.638311\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.638311\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000099970909\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 80):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.04441349 -0.06593995]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: -0.06593995080811171\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.98\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.50271464 0.49728536]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.1181, Std: 1.1135\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.49\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.7769\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 80):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -0.776902819024345)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -0.776902819024345}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.0776902819024345}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.577690\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.577690\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000114569338\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 90):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.04864376 -0.0820223 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: -0.0820223016474146\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.98\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.50421544 0.49578456]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.1471, Std: 1.2225\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.49\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.3510\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 90):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -1.350953095071837)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -1.350953095071837}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.1350953095071837}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.635095\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.635095\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000135267926\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 100):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 0.02399475 -0.07300389]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: -0.0730038896609403\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.98\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.51226614 0.48773386]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.1439, Std: 1.1969\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.49\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.7447\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 100):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 0.7446695910866987)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 0.7446695910866987}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.07446695910866988}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.574467\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.574467\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.669, trend=-0.127\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000132120409\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 110):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.07767656 -0.0808544 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: -0.08085440304438204\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.97\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.50040254 0.49959746]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.1630, Std: 1.2395\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.49\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.2489\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 110):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -1.2489018248961548)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -1.2489018248961548}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.12489018248961548}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.624890\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.624890\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.661, trend=+0.048\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 120):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.03856171  0.03074034]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: 0.03074033997673146\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.97\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.49122241 0.50877759]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.1545, Std: 1.2317\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.49\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.6257\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 120):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -1.625724388668583)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -1.625724388668583}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.16257243886685832}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.662572\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.662572\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.670, trend=+0.057\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000149517442\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 10):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=3.404897\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.641\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00014952\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00014952\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.511, max=0.840, group_baseline=0.641\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.302533, entropy=-2.423490\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.72151178\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 2.711731\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 130):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-7.76741097e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.97\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.1701, Std: 1.2494\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.49\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.5945\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 130):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -0.5944568644957757)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -0.5944568644957757}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.059445686449577574}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.559446\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.559446\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.665, trend=-0.363\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000174626251\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 10: reward=0.623, intervention_rate=1.000, scm=collider_3var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 140):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-5.25279363e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.97\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.1842, Std: 1.2846\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.49\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.6769\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 140):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -1.6769013754454267)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -1.6769013754454267}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.16769013754454268}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.667690\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.667690\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.640, trend=-0.015\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000200676409\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 150):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.09664558e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.96\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.1442, Std: 1.2253\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.49\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.1573\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 150):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 0.15727906624913077)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 0.15727906624913077}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.015727906624913076}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.515728\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.515728\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.623, trend=-0.259\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000230968765\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 160):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-8.36679536e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.96\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.1823, Std: 1.3107\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.49\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.0817\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 160):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 0.08170469510983339)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 0.08170469510983339}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.008170469510983339}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.508170\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.508170\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.596, trend=-0.130\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000265586113\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 170):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-5.22396988e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.96\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.1778, Std: 1.3153\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.49\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.8038\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 170):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -0.8038499455367318)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -0.8038499455367318}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.08038499455367319}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.580385\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.580385\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.591, trend=+0.003\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 180):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.30769873e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.96\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2056, Std: 1.2943\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.49\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.4227\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 180):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -1.4227427689558771)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -1.4227427689558771}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.14227427689558772}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.642274\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.642274\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.597, trend=+0.007\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000300317450\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 15):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=1.854759\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.593\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00030032\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00030032\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.514, max=0.685, group_baseline=0.593\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.302904, entropy=-2.469813\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.62633989\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 2.250383\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 190):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-9.44209309e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.96\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.1906, Std: 1.2889\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.49\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -2.0324\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 190):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -2.0323892029197634)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -2.0323892029197634}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.20323892029197635}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.703239\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.703239\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.604, trend=+0.129\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000328753206\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 200):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-5.66957098e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.95\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.1957, Std: 1.3661\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.48\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.6205\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 200):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 0.6205154624322516)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 0.6205154624322516}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.06205154624322517}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.562052\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.562052\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.603, trend=-0.063\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000364344620\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 210):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.02551227e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.95\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2305, Std: 1.3776\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.48\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.0642\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 210):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 3.0641591689402508)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 3.0641591689402508}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3064159168940251}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.806416\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.806416\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.806) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.621, trend=+0.144\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000378604364\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 220):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.10880886e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.95\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.1911, Std: 1.3686\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.48\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.6361\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 220):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 2.6361032794839994)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 2.6361032794839994}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.26361032794839995}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.763610\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.763610\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.631, trend=+0.204\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000392491785\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 230):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-5.7552943e-02 -1.0000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.94\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2402, Std: 1.3869\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.48\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.0559\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 230):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -0.05592524401728685)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -0.05592524401728685}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.005592524401728686}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.505593\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.505593\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.626, trend=-0.162\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 240):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.06656037e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.94\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2033, Std: 1.3899\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.48\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.7975\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 240):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -1.7974632889277595)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -1.7974632889277595}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.17974632889277598}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.679746\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.679746\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.627, trend=+0.164\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000406783602\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 20):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=3.505150\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.669\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00040678\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00040678\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.506, max=0.851, group_baseline=0.665\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.268522, entropy=-2.525042\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.71700744\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 2.830634\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 250):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.06059036 -0.07069249 -0.09811133]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.0981113286589431\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.94\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.3360589  0.33431475 0.32962635]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2343, Std: 1.3853\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.48\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.8589\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 250):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 1.8589277585228665)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 1.8589277585228665}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.18589277585228667}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.685893\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.685893\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.644, trend=+0.178\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000407668890\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 20: reward=0.664, intervention_rate=1.000, scm=fork_4var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 260):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.11937881 -0.0915972  -0.08513471]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.08513471309783825\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.94\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.32978732 0.33454775 0.33566493]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.1831, Std: 1.3869\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.48\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.8715\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 260):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 2.8715364121547924)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 2.8715364121547924}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.28715364121547926}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.787154\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.787154\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.672, trend=+0.207\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000398645744\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 270):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.0952824  -0.10688668 -0.06068022]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.0606802203003945\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.94\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33199864 0.33001415 0.33798722]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2640, Std: 1.4692\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.48\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -2.3501\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 270):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -2.3500516458740974)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -2.3500516458740974}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.23500516458740975}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.735005\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.735005\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.687, trend=+0.093\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000358994575\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 280):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.11931961 -0.06780335 -0.08824056]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.08824056259027604\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.93\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.32859867 0.33747565 0.33392569]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X3 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2570, Std: 1.4574\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.48\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 4.3038\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 280):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 4.303801884021525)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': 4.303801884021525}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.43038018840215253}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.930380\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.930380\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.930) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.716, trend=+0.227\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000356595601\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 290):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.10998455 -0.06296665 -0.11449943]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.11449942917155245\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.93\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33087079 0.33903166 0.33009756]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2362, Std: 1.5269\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.48\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.0235\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 290):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 3.0234699096170363)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 3.0234699096170363}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.30234699096170364}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.802347\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.802347\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.802) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.726, trend=+0.240\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 300):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.09709361 -0.05928079 -0.10998207]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.10998206989308901\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.93\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33188061 0.33844804 0.32967135]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2248, Std: 1.4314\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.48\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.2562\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 300):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 3.256235002630229)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 3.256235002630229}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.32562350026302295}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.825624\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.825624\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.826) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.752, trend=+0.019\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000356800181\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 25):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=6.148391\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.708\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00035680\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00035680\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.559, max=1.000, group_baseline=0.709\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.315202, entropy=-2.994914\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.69027892\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 3.751627\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 310):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-5.40828573e-02 -1.00000000e+09 -5.34141247e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.93\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.49991323 0.         0.50008677]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2550, Std: 1.5138\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.48\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.8696\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 310):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 0.8696038420544803)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 0.8696038420544803}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.08696038420544804}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.586960\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.586960\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.730, trend=-0.177\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000369850989\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 320):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-5.07414270e-02 -1.00000000e+09 -5.45530462e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.92\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.50049532 0.         0.49950468]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2413, Std: 1.3911\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.47\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.6349\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 320):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 3.6349161225862905)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 3.6349161225862905}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3634916122586291}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.863492\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.863492\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.863) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.740, trend=+0.358\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000371997370\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 330):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.57476586e-01 -1.00000000e+09 -5.88491882e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.92\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.48716672 0.         0.51283328]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2219, Std: 1.5747\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.47\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -3.8379\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 330):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -3.837885708482741)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -3.837885708482741}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3837885708482741}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.883789\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.883789\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.884) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.778, trend=+0.204\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000359591699\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 340):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.25154518e-01 -1.00000000e+09 -9.08798717e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.92\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.49553255 0.         0.50446745]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2390, Std: 1.4690\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.47\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -3.6666\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 340):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -3.6666459126465045)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -3.6666459126465045}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.36666459126465045}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.866665\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.866665\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.867) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.797, trend=+0.181\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000342877978\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 350):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-9.25036103e-02 -1.00000000e+09 -6.16111735e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.92\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.49596721 0.         0.50403279]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2150, Std: 1.5427\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.47\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.8506\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 350):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 0.8505911085577988)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 0.8505911085577988}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.08505911085577988}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.585059\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.585059\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.787, trend=-0.202\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 360):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-5.76567688e-02 -1.00000000e+09 -9.39835032e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.92\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.50474215 0.         0.49525785]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2426, Std: 1.5605\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.47\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.7886\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 360):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 1.788554923721871)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 1.788554923721871}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.17885549237218712}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.678855\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.678855\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.776, trend=-0.056\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000326663187\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 30):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=7.257780\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.677\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00032666\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00032666\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.538, max=1.000, group_baseline=0.678\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.324444, entropy=-3.063246\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.65461759\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 578125003.853690\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 370):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.06973715 -0.04164564 -0.16340412]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.1634041228166885\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.91\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33704145 0.34202961 0.32092894]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X3 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2244, Std: 1.5107\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.47\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.3010\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 370):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 1.3010129526734668)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': 1.3010129526734668}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.13010129526734668}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.630101\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.630101\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.765, trend=-0.300\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000295081404\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 30: reward=0.659, intervention_rate=1.000, scm=collider_4var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 380):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.01999829 -0.12929823 -0.03771369]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.03771369111427182\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.91\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.34070133 0.32174411 0.33755456]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X3 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2240, Std: 1.4512\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.47\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.3734\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 380):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -1.373352833360222)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -1.373352833360222}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.1373352833360222}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.637335\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.637335\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.736, trend=-0.165\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000289677894\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 390):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.07290944 -0.00724091 -0.03989863]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.03989863332624704\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.91\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.32759847 0.33908057 0.33332095]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2437, Std: 1.6241\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.47\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.2333\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 390):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 3.2332691203173076)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 3.2332691203173076}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3233269120317308}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.823327\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.823327\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.823) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.738, trend=-0.002\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000268019797\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 400):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.04477857 -0.04389712 -0.08014153]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.08014152909338841\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.90\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33533921 0.33549454 0.32916625]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2319, Std: 1.6182\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.47\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -4.6871\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 400):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -4.687115998923682)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -4.687115998923682}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.4687115998923682}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.968712\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.968712\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.969) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.752, trend=+0.382\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000270862790\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 410):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.06259231 -0.10326255 -0.11954494]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.119544944535335\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.90\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33906327 0.33188407 0.32905266]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X3 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.1883, Std: 1.6154\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.47\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.2088\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 410):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 0.20881664452113777)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': 0.20881664452113777}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.020881664452113778}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.520882\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.520882\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.746, trend=-0.343\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 420):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.01795244  0.00570641 -0.10601479]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.10601479418191169\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.90\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.3370129  0.34123476 0.32175234]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2312, Std: 1.7086\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.47\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.0408\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 420):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 3.0407747863182104)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 3.0407747863182104}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.30407747863182105}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.804077\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.804077\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.804) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.740, trend=-0.080\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000267488103\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 35):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=3.633510\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.621\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00026749\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00026749\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.502, max=0.863, group_baseline=0.618\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.287172, entropy=-3.135541\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.72967820\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 343750002.903131\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 430):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.05716062 -0.13822443 -0.0670612 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.06706120261381955\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.90\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33864174 0.32447889 0.33687937]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2625, Std: 1.6223\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.47\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.6220\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 430):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 1.6219637949121422)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 1.6219637949121422}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.16219637949121424}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.662196\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.662196\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.718, trend=-0.204\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000280324892\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 440):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.08121083 -0.08239443 -0.10996587]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.10996586558712226\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.89\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33508559 0.33487631 0.33003809]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.1660, Std: 1.5948\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.46\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.4875\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 440):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -0.48750701344861835)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -0.48750701344861835}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.04875070134486184}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.548751\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.548751\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.686, trend=-0.036\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000288448223\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 450):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.09562518 -0.08329683 -0.11073877]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.11073877253967411\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.89\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33349111 0.33567171 0.33083718]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X3 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2279, Std: 1.5975\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.46\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.9337\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 450):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -0.9337354282856999)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -0.9337354282856999}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.09337354282857}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.593374\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.593374\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.687, trend=-0.085\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000293321134\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 460):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.05956761 -0.0207409  -0.1288405 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.1288405035424798\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.89\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33503567 0.34199451 0.32296983]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X3 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2381, Std: 1.7904\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.46\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.2720\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 460):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -1.2720040384951192)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -1.2720040384951192}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.12720040384951192}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.627200\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.627200\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.682, trend=-0.003\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000297057300\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 470):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.07929686 -0.09862367 -0.0060084 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.006008399022900626\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.89\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33009477 0.32672893 0.3431763 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2956, Std: 1.8512\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.46\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.9058\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 470):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 2.9057550478838894)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 2.9057550478838894}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.29057550478838895}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.790576\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.790576\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.698, trend=+0.153\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 480):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.09386172 -0.11164626 -0.02486595]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.024865949097442514\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.89\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33026419 0.32716409 0.34257172]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X3 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3063, Std: 1.8503\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.46\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -2.3855\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 480):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -2.385489605002789)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -2.385489605002789}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.2385489605002789}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.738549\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.738549\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.708, trend=-0.085\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000302136005\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 40):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=4.173507\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.687\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00030214\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00030214\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.541, max=0.917, group_baseline=0.684\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.320301, entropy=-3.215300\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.73448242\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 312500003.379686\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 490):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -4.30853547e-02 -1.18448708e-01 -4.39525775e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.88\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.33780326 0.32454904 0.3376477 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2949, Std: 1.7394\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.46\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.0342\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 490):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -0.03424693369886567)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -0.03424693369886567}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.003424693369886567}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.503425\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.503425\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.676, trend=-0.465\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000309660282\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 40: reward=0.677, intervention_rate=1.000, scm=fork_5var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 500):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.39688389e-01 -8.77392268e-02 -9.04951175e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.88\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.32738226 0.33655538 0.33606236]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2909, Std: 1.9220\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.46\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.3474\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 500):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 0.3474061126731773)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 0.3474061126731773}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.03474061126731773}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.534741\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.534741\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.632, trend=+0.014\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000319240720\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 510):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -4.97807848e-02 -1.52443189e-01 -8.33948144e-03]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.88\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.33680271 0.31887559 0.34432169]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2653, Std: 1.8097\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.46\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.3210\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 510):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 2.321011233235249)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 2.321011233235249}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.2321011233235249}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.732101\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.732101\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.653, trend=-0.072\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000335341399\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 520):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.10721306e-01 -9.86051492e-02 -1.12620289e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.87\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.33272628 0.33488443 0.33238929]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2612, Std: 1.8802\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.46\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -2.2473\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 520):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -2.2473361421200604)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -2.2473361421200604}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.22473361421200605}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.724734\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.724734\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.646, trend=+0.063\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000342417184\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 530):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -9.50980742e-02 -1.16903573e-01 -1.39656789e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.87\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.33728168 0.33337386 0.32934446]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.1753, Std: 1.5837\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.46\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.5336\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 530):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 2.533599499462086)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 2.533599499462086}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.25335994994620864}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.753360\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.753360\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.655, trend=+0.205\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 540):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.33708078e-01 -1.06750187e-01 -6.13245045e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.87\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.32744425 0.33219607 0.34035969]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3008, Std: 1.9590\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.46\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 5.1448\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 540):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 5.144794230636636)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 5.144794230636636}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.700, trend=+0.407\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000349617988\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 45):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=5.538972\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.733\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00034962\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00034962\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.514, max=1.000, group_baseline=0.733\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.319331, entropy=-3.590075\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.72026441\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 515625003.923819\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 550):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.24714690e-03 -1.00000000e+09 -1.16246865e-01 -1.54144805e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.87\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.34974444 0.         0.32842547 0.32183009]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3018, Std: 1.9956\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.46\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.8448\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 550):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -0.8447801320245163)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -0.8447801320245163}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.08447801320245163}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.584478\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.584478\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.699, trend=-0.043\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000356292092\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 560):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-5.53436507e-02 -1.00000000e+09 -1.28983527e-01 -8.00107474e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.87\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33919561 0.         0.326065   0.33473939]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3233, Std: 2.0763\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.46\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.9606\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 560):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -0.9606359255679913)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -0.9606359255679913}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.09606359255679914}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.596064\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.596064\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.696, trend=-0.195\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000357816747\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 570):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.36368581e-01 -1.00000000e+09 -1.14251545e-01 -1.24863254e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.86\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33132944 0.         0.33528782 0.33338273]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3411, Std: 2.1203\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.45\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -5.8488\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 570):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -5.848826415459204)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -5.848826415459204}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.717, trend=+0.261\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000350458538\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 580):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.21147361e-01 -1.00000000e+09 -1.43426512e-01 -9.44415919e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.86\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33304959 0.         0.32908278 0.33786762]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2809, Std: 2.0589\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.45\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 4.4831\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 580):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 4.483092234814406)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 4.483092234814406}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.44830922348144064}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.948309\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.948309\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.948) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.738, trend=+0.445\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000340976950\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 590):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-7.89606012e-02 -1.00000000e+09 -1.08323739e-01 -7.58435484e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.86\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33489753 0.         0.32964217 0.33546031]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3406, Std: 1.9302\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.45\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.4324\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 590):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -0.4323871128641506)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -0.4323871128641506}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.043238711286415064}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.543239\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.543239\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.742, trend=+0.008\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 600):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.08383478e-01 -1.00000000e+09 -1.02737523e-01 -1.36577887e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.86\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33467501 0.         0.33569439 0.3296306 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3312, Std: 2.1971\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.45\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.3443\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 600):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 0.344269122320116)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 0.344269122320116}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.0344269122320116}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.534427\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.534427\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.742, trend=-0.198\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000298901961\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 50):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=4.113094\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.695\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00029890\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00029890\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.518, max=0.911, group_baseline=0.696\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.363984, entropy=-3.683014\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.74023931\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 484375003.670463\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 610):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.22576923e-01 -1.54348328e-01 -1.24768987e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.85\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.33536532 0.32966575 0.33496893]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3203, Std: 2.1145\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.45\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.7848\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 610):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 0.7848222778752916)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 0.7848222778752916}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.07848222778752917}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.578482\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.578482\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.726, trend=-0.146\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000248836172\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 50: reward=0.674, intervention_rate=1.000, scm=collider_5var\n",
      "INFO:causal_bayes_opt.training.modular_trainer:Saved checkpoint: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/checkpoints/grpo_training/enriched_grpo_episode_50/checkpoint.pkl\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 620):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.16882840e-01 -1.05924279e-01 -4.07968620e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.85\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.3280936  0.33004223 0.34186417]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2800, Std: 2.0491\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.45\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.0496\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 620):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 3.049623109244446)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 3.049623109244446}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3049623109244446}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.804962\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.804962\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.805) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.734, trend=+0.052\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000219876649\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 630):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.22391206e-01 -9.83444148e-02 -1.49126578e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.85\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.33347405 0.33784249 0.32868346]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2308, Std: 2.0320\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.45\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.6218\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 630):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -1.6218075279213122)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -1.6218075279213122}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.16218075279213123}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.662181\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.662181\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.725, trend=-0.338\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000216711846\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 640):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -7.59951477e-02 -1.35386420e-01 -1.69381755e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.84\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.34258847 0.33173444 0.32567709]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3219, Std: 2.3010\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.45\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.4884\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 640):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -1.488432296130835)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -1.488432296130835}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.1488432296130835}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.648843\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.648843\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.690, trend=+0.064\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000250115139\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 650):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.21314010e-01 -1.52254009e-01 -1.47646137e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.84\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.33679715 0.33118662 0.33201623]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3332, Std: 2.3615\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.45\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.2283\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 650):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 2.2283416162253045)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 2.2283416162253045}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.22283416162253045}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.722834\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.722834\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.704, trend=+0.127\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 660):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.14885863e-01 -1.61755764e-01 -1.25341029e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.84\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.33678962 0.32832716 0.33488322]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3185, Std: 2.1348\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.45\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -5.0724\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 660):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -5.072413013685863)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -5.072413013685863}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.744, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000279596123\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 55):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=6.418925\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.801\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00027960\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00027960\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.582, max=1.000, group_baseline=0.795\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.343789, entropy=-3.782804\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.74023121\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 343750004.150385\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 670):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -8.51906679e-02 -2.92632017e-02 -1.16077691e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.84\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.33176026 0.34200545 0.32623429]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3063, Std: 2.1340\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.45\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.7486\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 670):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 2.7485914042102877)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 2.7485914042102877}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.27485914042102877}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.774859\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.774859\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.722, trend=-0.173\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000314669824\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 680):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.25657707e-01 -1.41797552e-01 -1.12659757e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.84\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.33351651 0.33059739 0.3358861 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3509, Std: 2.4239\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.45\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.8760\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 680):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 1.875985260731932)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 1.875985260731932}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.18759852607319322}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.687599\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.687599\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.696, trend=+0.144\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000345977996\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 690):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.61505690e-01 -1.41616329e-01 -1.39427312e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.83\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.33079422 0.3344031  0.33480269]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3520, Std: 2.4942\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.44\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.9026\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 690):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 1.9025932200665892)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 1.9025932200665892}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.19025932200665893}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.690259\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.690259\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.710, trend=+0.156\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000354454544\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 700):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -9.71499633e-02 -1.12072478e-01 -1.49867545e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.83\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.33744068 0.33470036 0.32785896]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3558, Std: 2.6236\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.44\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 4.2826\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 700):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 4.282581301600775)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 4.282581301600775}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.4282581301600775}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.928258\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.928258\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.928) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.750, trend=+0.350\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000360449256\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 710):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.51281554e-01 -1.25383113e-01 -6.58995330e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.83\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.32657179 0.33123366 0.34219456]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2967, Std: 2.3505\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.44\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -2.7010\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 710):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -2.7009615690956017)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -2.7009615690956017}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.2700961569095602}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.770096\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.770096\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.769, trend=-0.035\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 720):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.44565739e-01 -1.42023793e-01 -5.15318368e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.83\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.32747928 0.32793519 0.34458553]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3266, Std: 2.4743\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.44\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.7860\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 720):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -0.7859901439996493)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -0.7859901439996493}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.07859901439996493}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.578599\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.578599\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.746, trend=-0.084\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000380959872\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 60):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=7.696624\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.830\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00038096\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00038096\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.579, max=1.000, group_baseline=0.826\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.333913, entropy=-3.889250\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.74346323\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 406250004.515277\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 730):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.10769379 -0.13022312 -0.13432067 -0.1342554  -0.07410095]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.07410095077989806\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.82\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.20090948 0.19844348 0.19799824 0.19800532 0.20464348]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3677, Std: 2.7245\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.44\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.6257\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 730):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 3.6257492599418115)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 3.6257492599418115}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3625749259941812}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.862575\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.862575\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.863) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.766, trend=+0.214\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000407102523\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 60: reward=0.819, intervention_rate=1.000, scm=fork_6var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 740):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.13159746 -0.1548124  -0.16939411 -0.08766375 -0.12776593]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.12776592826918676\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.82\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.20026767 0.19773117 0.1961544  0.20515733 0.20068943]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3664, Std: 2.8103\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.44\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 6.1721\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 740):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, 6.172056164189994)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 6.172056164189994}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.802, trend=+0.277\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000425091268\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 750):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.1259308  -0.1367957  -0.16948366 -0.14234002 -0.08185572]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.08185572310545944\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.82\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.20056451 0.19936969 0.19581771 0.19876272 0.20548537]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3685, Std: 2.8181\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.44\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -2.3782\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 750):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, -2.378156141962055)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -2.378156141962055}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.23781561419620553}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.737816\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.737816\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.803, trend=-0.262\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000438966182\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 760):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.10758444 -0.14088873 -0.16929706 -0.16723551 -0.15961548]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.15961548390658933\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.82\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.20459008 0.20087107 0.19775225 0.19797694 0.19880967]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3609, Std: 2.7719\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.44\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -3.7239\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 760):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -3.723912947946174)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -3.723912947946174}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3723912947946174}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.872391\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.872391\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.872) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.790, trend=+0.098\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000442973618\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 770):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.13325024 -0.13741365 -0.11229228 -0.18430724 -0.10050643]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.10050642685598868\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.81\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.20000844 0.19954953 0.20233456 0.19445294 0.20365453]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3522, Std: 2.9408\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.44\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.7955\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 770):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 2.795546307515841)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': 2.795546307515841}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.2795546307515841}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.779555\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.779555\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.791, trend=+0.092\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 780):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.15671545 -0.07606659 -0.16717218 -0.14820841 -0.1414356 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.1414356001487419\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.81\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.19790543 0.20691026 0.19676695 0.19883649 0.19958087]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3740, Std: 2.9525\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.44\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -5.2445\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 780):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -5.244503756827907)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -5.244503756827907}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.822, trend=+0.310\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000444063712\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 65):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=8.901148\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.803\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00044406\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00044406\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.571, max=1.000, group_baseline=0.800\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.308402, entropy=-4.226710\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.74984695\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 171875004.607200\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 790):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.08998766e-01 -1.00000000e+09 -8.44913718e-02 -6.70256243e-02\n",
      " -1.01839581e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.81\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.24745948 0.         0.25083367 0.25326641 0.24844044]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3428, Std: 2.5498\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.44\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -3.2671\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 790):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -3.2670754885233166)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -3.2670754885233166}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.32670754885233166}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.826708\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.826708\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.827) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.836, trend=-0.102\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000449335331\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 800):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.42774284e-01 -1.00000000e+09 -1.58112486e-01 -1.37914221e-01\n",
      " -4.46900126e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.81\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.24691166 0.         0.24482428 0.24757677 0.26068729]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3686, Std: 3.0795\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.44\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -4.3102\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 800):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -4.310221419200412)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -4.310221419200412}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.4310221419200412}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.931022\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.931022\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.931) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.836, trend=+0.161\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000470290847\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 810):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.15170216e-01 -1.00000000e+09 -7.78759201e-02 -1.69260952e-01\n",
      " -1.22345360e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.80\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.25079136 0.         0.25603081 0.24338213 0.2497957 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2803, Std: 2.5191\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.43\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.5997\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 810):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 0.5997441677805335)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 0.5997441677805335}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.059974416778053354}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.559974\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.559974\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.815, trend=-0.019\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000478524030\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 820):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-8.19156361e-02 -1.00000000e+09 -1.67385751e-01 -1.69521133e-01\n",
      " -1.57861848e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.80\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.25874127 0.         0.24674757 0.24645515 0.24805601]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2783, Std: 2.7425\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.43\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -2.8735\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 820):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -2.873515038262956)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -2.873515038262956}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.28735150382629565}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.787352\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.787352\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.836, trend=-0.075\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000460732017\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 830):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.78576687e-01 -1.00000000e+09 -1.37660180e-01 -1.98855822e-02\n",
      " -1.34332661e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.80\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.24153341 0.         0.24709339 0.26382206 0.24755114]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3698, Std: 3.1906\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.43\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 7.0106\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 830):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, 7.010561429523399)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 7.010561429523399}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.849, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 840):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-5.92878690e-02 -1.00000000e+09 -1.24181141e-01 -7.61548259e-02\n",
      " -1.27476916e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.80\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.25523271 0.         0.24618439 0.25284939 0.24573351]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3275, Std: 3.0134\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.43\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.5626\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 840):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 1.5625601728180243)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': 1.5625601728180243}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.15625601728180244}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.656256\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.656256\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.815, trend=-0.082\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000409842549\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 70):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=7.010561\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.758\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00040984\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00040984\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.556, max=1.000, group_baseline=0.763\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.335324, entropy=-4.352811\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.75619021\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 265625004.298086\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 850):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.13307006 -0.10831385 -0.08212984 -0.1100229  -0.12100772]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.12100771532770328\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.79\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.19753709 0.20028046 0.20322354 0.20008986 0.19886906]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3069, Std: 2.7813\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.43\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.4765\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 850):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -0.47647761182891085)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -0.47647761182891085}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.04764776118289109}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.547648\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.547648\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.796, trend=-0.325\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000377242054\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 70: reward=0.853, intervention_rate=1.000, scm=collider_6var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 860):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.11815843 -0.1254473  -0.12034942 -0.10862797 -0.12164652]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.12164652461305278\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.79\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.20007576 0.19926361 0.19983128 0.20114267 0.19968669]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3855, Std: 3.5251\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.43\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -5.1982\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 860):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -5.198204439827014)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -5.198204439827014}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.809, trend=+0.220\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000389457709\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 870):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.13232179 -0.11700851 -0.13857623 -0.10721286 -0.11612836]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.1161283632926408\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.79\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.19887309 0.20058263 0.19817906 0.20168389 0.20068133]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X5 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3715, Std: 3.3744\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.43\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -9.4426\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 870):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -9.442568850144017)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X5': -9.442568850144017}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.831, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000425490111\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 880):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.07238066 -0.16189926 -0.11312489 -0.16826976 -0.11998051]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.11998051012103068\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.79\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.20618574 0.19610667 0.20153559 0.19540847 0.20076353]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3495, Std: 3.3571\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.43\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.0437\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 880):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 3.043746929319404)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 3.043746929319404}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3043746929319404}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.804375\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.804375\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.804) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.811, trend=-0.022\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000439219706\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 890):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.11391233 -0.09154548 -0.11479558 -0.14337482 -0.16875265]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.16875264515730695\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.78\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.20139143 0.2039334  0.2012917  0.19809133 0.19529214]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3664, Std: 3.7265\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.43\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 9.5037\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 890):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 9.503743627648404)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 9.503743627648404}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.829, trend=+0.069\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 900):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.08478362 -0.15879902 -0.09212557 -0.07734093 -0.14254066]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.1425406645592755\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.78\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.20294079 0.19468975 0.20210694 0.20378958 0.19647295]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3677, Std: 3.7643\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.43\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.4047\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 900):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 0.4046507377543117)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 0.4046507377543117}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.040465073775431175}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.540465\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.540465\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.790, trend=-0.020\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000417330929\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 75):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=9.503744\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.791\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00041733\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00041733\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.540, max=1.000, group_baseline=0.797\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.370744, entropy=-4.489478\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.75562277\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 171875004.465053\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 910):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.21183917e-01 -1.53669322e-01 -1.00000000e+09 -1.27479530e-01\n",
      " -1.52136304e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.78\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.25245182 0.247887   0.         0.25156064 0.24810055]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3736, Std: 3.8750\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.43\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.1905\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 910):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 1.1904712619451447)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 1.1904712619451447}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.11904712619451448}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.619047\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.619047\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.796, trend=-0.168\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000373128544\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 920):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.33182232e-01 -1.06309376e-01 -1.00000000e+09 -1.74326042e-01\n",
      " -8.05863683e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.78\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.24860866 0.2523961  0.         0.24291971 0.25607552]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3320, Std: 3.6282\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.43\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 9.3829\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 920):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 9.382930478423457)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': 9.382930478423457}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.817, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000334177087\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 930):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-9.17491665e-02 -1.13725900e-01 -1.00000000e+09 -1.00768575e-01\n",
      " -1.25937895e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.77\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.25229986 0.24919431 0.         0.25102066 0.24748517]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3895, Std: 4.1688\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.42\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.8269\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 930):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, -1.826894585550878)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -1.826894585550878}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.1826894585550878}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.682689\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.682689\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.785, trend=+0.026\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000324881948\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 940):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-8.15457056e-02 -3.57738088e-02 -1.00000000e+09 -1.24242017e-01\n",
      " -5.08690312e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.77\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.24876682 0.25527825 0.         0.24284272 0.25311221]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X5 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3821, Std: 4.2108\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.42\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -8.5163\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 940):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -8.516282354463243)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X5': -8.516282354463243}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.819, trend=+0.452\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000349912542\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 950):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.22314637e-01 -1.20402118e-01 -1.00000000e+09 -3.38686321e-02\n",
      " -1.77842904e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.77\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.24866627 0.24893532 0.         0.26141836 0.24098005]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3319, Std: 3.6045\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.42\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 6.9779\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 950):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 6.977910500879188)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 6.977910500879188}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.865, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 960):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.07103900e-01 -1.37693235e-01 -1.00000000e+09 -1.26153559e-01\n",
      " -1.26405530e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.77\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.25244337 0.24811459 0.         0.24973881 0.24970323]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3237, Std: 3.7836\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.42\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.2699\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 960):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 3.2699391262777353)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 3.2699391262777353}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.32699391262777355}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.826994\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.826994\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.827) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.847, trend=-0.173\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000399650231\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 80):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=9.743234\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.824\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00039965\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00039965\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.573, max=1.000, group_baseline=0.832\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.321578, entropy=-4.636557\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.75837517\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 250000004.645817\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 970):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.43817524e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.77\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3876, Std: 4.3007\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.42\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.5167\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 970):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 1.5167315469218257)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 1.5167315469218257}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.15167315469218257}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.651673\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.651673\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.813, trend=-0.153\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000451472919\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 80: reward=0.839, intervention_rate=1.000, scm=fork_3var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 980):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.50141887e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.76\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3399, Std: 3.7823\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.42\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -3.3666\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 980):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -3.3665591744227736)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -3.3665591744227736}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3366559174422774}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.836656\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.836656\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.837) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.816, trend=-0.163\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000481839135\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 990):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-9.05807424e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.76\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3772, Std: 4.0513\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.42\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -5.7257\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 990):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -5.725702509087345)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -5.725702509087345}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.816, trend=+0.460\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000499254204\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1000):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.04801373e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.76\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2992, Std: 3.7980\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.42\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 8.2118\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1000):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 8.211799802340929)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 8.211799802340929}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.862, trend=+0.381\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000515955903\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1010):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.39204216e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.75\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3936, Std: 4.8781\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.42\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -2.1843\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1010):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -2.18434145553484)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -2.18434145553484}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.218434145553484}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.718434\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.718434\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.872, trend=-0.282\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1020):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.44692319e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.75\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3583, Std: 4.7147\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.42\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 4.8679\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1020):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 4.867934552199612)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 4.867934552199612}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.48679345521996126}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.986793\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.986793\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.987) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.870, trend=+0.304\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000513184073\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 85):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=16.760238\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.832\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00051318\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00051318\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.524, max=1.000, group_baseline=0.836\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.339953, entropy=-3.880214\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.73944173\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 3.922147\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1030):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.17282499 -0.18418885]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: -0.18418884525067514\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.75\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.5016225 0.4983775]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3859, Std: 5.0922\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.42\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.4433\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1030):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 3.4432525649144714)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 3.4432525649144714}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3443252564914472}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.844325\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.844325\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.844) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.886, trend=-0.156\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000534366923\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1040):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.10044274 -0.08808442]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: -0.088084419250206\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.75\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.49823256 0.50176744]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3679, Std: 4.5629\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.42\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 12.9396\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1040):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 12.939571224055213)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 12.939571224055213}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.886, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000487606308\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1050):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.15729747 -0.0079182 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: -0.007918196148188856\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.75\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.47861345 0.52138655]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4135, Std: 5.7305\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.42\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.5913\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1050):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 1.5912503882478566)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 1.5912503882478566}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.15912503882478568}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.659125\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.659125\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.852, trend=-0.168\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000406008031\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1060):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.07350962 -0.14696819]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: -0.14696818942647336\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.74\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.51053958 0.48946042]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3949, Std: 5.7839\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.41\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.5828\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1060):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 1.5828066318888716)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 1.5828066318888716}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.15828066318888717}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.658281\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.658281\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.836, trend=+0.007\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000416985168\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1070):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.1290167  -0.13640629]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: -0.13640628605291033\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.74\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.50106217 0.49893783]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3939, Std: 5.6152\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.41\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.9403\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1070):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 0.940260869064729)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 0.940260869064729}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.0940260869064729}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.594026\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.594026\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.830, trend=-0.243\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1080):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.12009231 -0.08470079]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: -0.0847007923242476\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.74\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.49491302 0.50508698]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4102, Std: 5.6686\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.41\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -3.5642\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1080):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -3.5641663570194155)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -3.5641663570194155}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3564166357019416}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.856417\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.856417\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.856) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.832, trend=-0.144\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000457970388\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 90):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=14.796027\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.875\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00045797\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00045797\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.594, max=1.000, group_baseline=0.874\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.298516, entropy=-4.054751\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.76641041\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 4.022232\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1090):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.4936882e-01 -1.0000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.74\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3742, Std: 5.4436\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.41\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.2342\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1090):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 2.234232592331891)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 2.234232592331891}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.22342325923318912}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.723423\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.723423\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.804, trend=-0.277\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000480620980\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 90: reward=0.835, intervention_rate=1.000, scm=collider_3var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1100):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-3.13564228e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.73\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4070, Std: 4.7325\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.41\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 7.8071\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1100):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 7.8071434826251656)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 7.8071434826251656}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.804, trend=+0.282\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000471139958\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1110):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.50900522e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.73\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3987, Std: 6.2596\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.41\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 17.3966\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1110):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 17.39659434593053)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 17.39659434593053}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.832, trend=+0.013\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000463119698\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1120):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-8.54082019e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.73\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4107, Std: 6.7809\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.41\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 9.1625\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1120):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 9.162460430575193)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 9.162460430575193}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.834, trend=+0.156\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000455260540\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1130):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.02656522e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.72\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4010, Std: 6.1373\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.41\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 16.1972\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1130):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 16.197186428522134)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 16.197186428522134}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.849, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1140):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-8.98808037e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.72\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4256, Std: 7.0397\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.41\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 6.1504\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1140):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 6.150433714260361)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 6.150433714260361}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.849, trend=+0.341\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000436950240\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 95):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=16.197186\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.954\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00043695\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00043695\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.561, max=1.000, group_baseline=0.950\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.247757, entropy=-4.112084\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00112216\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 4.339428\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1150):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.22069494e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.72\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3641, Std: 5.2627\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.41\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -12.1171\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1150):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -12.117113104714056)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -12.117113104714056}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.883, trend=+0.342\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000423639684\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1160):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.3399998e-01 -1.0000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.72\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4380, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.41\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.5778\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1160):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -1.57782433916858)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -1.57782433916858}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.157782433916858}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.657782\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.657782\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.883, trend=+0.064\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000408933814\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1170):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-7.86586393e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.72\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3705, Std: 6.3199\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.41\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.5405\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1170):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 3.540475471474642)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 3.540475471474642}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3540475471474642}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.854048\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.854048\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.854) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.909, trend=-0.002\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000401148604\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1180):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.01393483e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.71\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4386, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.40\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -12.3202\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1180):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -12.320188639388519)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -12.320188639388519}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.924, trend=+0.277\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000399927001\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1190):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.22549579e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.71\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4040, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.40\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.4249\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1190):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -0.4249133001455728)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -0.4249133001455728}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.04249133001455729}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.542491\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.542491\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.905, trend=-0.458\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1200):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.29904195e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.71\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4294, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.40\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 11.7124\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1200):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 11.712436244997647)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 11.712436244997647}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.905, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000391262343\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 100):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=24.402267\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.905\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00039126\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00039126\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.542, max=1.000, group_baseline=0.897\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.335913, entropy=-4.112084\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00164168\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 4.714235\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1210):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.12968893 -0.13241985 -0.12574981]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.12574981437531868\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.71\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33325427 0.33272156 0.33402417]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X3 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4259, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.40\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.6228\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1210):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -0.6228242433658746)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -0.6228242433658746}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.06228242433658746}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.562282\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.562282\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.862, trend=-0.438\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000364481304\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 100: reward=0.961, intervention_rate=1.000, scm=fork_4var\n",
      "INFO:causal_bayes_opt.training.modular_trainer:Saved checkpoint: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/checkpoints/grpo_training/enriched_grpo_episode_100/checkpoint.pkl\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1220):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.08215685 -0.11855512 -0.19143172]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.1914317186466497\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.70\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.34284671 0.33560143 0.32155186]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X3 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4520, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.40\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -5.2279\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1220):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -5.227858484142865)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -5.227858484142865}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.862, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000335711772\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1230):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.0438828  -0.07874848 -0.19781674]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.19781674408931815\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.70\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.34563808 0.3386263  0.31573562]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4366, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.40\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.9086\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1230):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 3.908610540297363)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 3.908610540297363}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.39086105402973637}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.890861\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.890861\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.891) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.851, trend=-0.109\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000311776130\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1240):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.09636626 -0.12314613 -0.08804321]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.08804321336521338\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.70\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33453011 0.32929623 0.33617366]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4019, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.40\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -7.5121\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1240):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -7.5121468826186995)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -7.5121468826186995}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.851, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000292722898\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1250):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.15615714 -0.05422481 -0.19964712]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.19964712125851214\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.70\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.32931096 0.34971847 0.32097056]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4410, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.40\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -2.4737\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1250):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -2.473745776123078)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -2.473745776123078}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.2473745776123078}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.747375\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.747375\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.825, trend=+0.090\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1260):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.13254075 -0.09519931 -0.07407879]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.07407879389159974\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.70\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.32707993 0.33436422 0.33855585]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4407, Std: 6.0635\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.40\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 4.6398\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1260):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 4.639815312319291)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 4.639815312319291}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.4639815312319291}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.963982\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.963982\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.964) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.856, trend=+0.110\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000269765151\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 105):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=15.617270\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.885\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00026977\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00026977\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.532, max=1.000, group_baseline=0.888\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.335834, entropy=-4.517549\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00079102\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 250000004.525452\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1270):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-9.12518496e-02 -1.00000000e+09 -1.08286351e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.69\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.50251633 0.         0.49748367]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3613, Std: 4.7986\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.40\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 6.3423\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1270):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 6.342304368220899)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 6.342304368220899}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.871, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000278402801\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1280):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.61390352e-01 -1.00000000e+09 -8.17345219e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.69\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.48821496 0.         0.51178504]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4498, Std: 7.2764\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.40\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 6.6008\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1280):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 6.600841002091715)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 6.600841002091715}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.871, trend=+0.458\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000302802287\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1290):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.16743419e-01 -1.00000000e+09 -9.33797469e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.69\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.49653677 0.         0.50346323]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4430, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.40\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -3.9016\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1290):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -3.9015888563070527)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -3.9015888563070527}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3901588856307053}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.890159\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.890159\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.890) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.905, trend=-0.110\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000307410317\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1300):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.59576901e-01 -1.00000000e+09 -1.50062445e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.68\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.49858718 0.         0.50141282]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4498, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.39\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -2.0726\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1300):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -2.0725509216516427)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -2.0725509216516427}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.20725509216516427}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.707255\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.707255\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.876, trend=+0.145\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000328285934\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1310):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.48289617e-01 -1.00000000e+09 -1.39399170e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.68\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.49867754 0.         0.50132246]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4458, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.39\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 6.5236\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1310):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 6.523557171014662)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 6.523557171014662}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.920, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1320):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.75630220e-01 -1.00000000e+09 -9.23014309e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.68\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.48760732 0.         0.51239268]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4590, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.39\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 8.2177\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1320):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 8.217692738039352)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 8.217692738039352}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.920, trend=+0.109\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000370262986\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 110):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=16.873498\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.928\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00037026\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00037026\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.535, max=1.000, group_baseline=0.924\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.296758, entropy=-4.517524\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00062533\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 421875004.796232\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1330):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.2956775  -0.13935573 -0.13286047]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.13286046747183655\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.68\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.3125426  0.34306334 0.34439407]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4206, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.39\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -16.8063\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1330):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -16.80630239649727)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -16.80630239649727}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.931, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000344375840\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 110: reward=0.942, intervention_rate=1.000, scm=collider_4var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1340):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.07010339 -0.18730961 -0.05338463]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.05338463203283511\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.67\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33985364 0.31688313 0.34326323]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4718, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.39\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 18.0456\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1340):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 18.045644609003876)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 18.045644609003876}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.931, trend=+0.253\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000302669237\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1350):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.13260427 -0.11394367 -0.23676113]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.2367611338219003\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.67\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33888822 0.3426919  0.31841988]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4596, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.39\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -12.2181\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1350):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -12.21806207861546)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -12.21806207861546}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.956, trend=+0.036\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000246909122\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1360):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.16884313 -0.16375728 -0.10577968]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.10577968315901944\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.67\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.3287785  0.32978193 0.34143956]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X3 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4523, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.39\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -7.2337\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1360):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -7.233727229301399)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -7.233727229301399}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.960, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000217651102\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1370):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.24222244 -0.16003579 -0.17585018]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.1758501835409495\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.67\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.32349777 0.3398565  0.33664573]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4322, Std: 7.2020\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.39\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -9.0279\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1370):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -9.02793259052591)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -9.02793259052591}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.960, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1380):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.14010221 -0.17916419  0.00360101]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: 0.0036010089826790347\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.67\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.32606094 0.31850493 0.35543413]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X3 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4183, Std: 6.7639\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.39\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 19.6266\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1380):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 19.626628758961672)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': 19.626628758961672}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.960, trend=+0.110\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000185347864\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 115):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=19.626629\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.952\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00018535\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00018535\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.698, max=1.000, group_baseline=0.955\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.287633, entropy=-4.517541\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00014352\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 406250005.375267\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1390):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.04446119 -0.22817266 -0.21917173]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.21917172715964012\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.66\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.35769267 0.32028459 0.32202273]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X3 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4349, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.39\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -6.4253\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1390):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -6.425269895869986)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -6.425269895869986}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.971, trend=+0.293\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000141089610\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1400):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.1481129  -0.14463845 -0.14347183]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.14347183308289987\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.66\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33279038 0.33348759 0.33372202]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4385, Std: 7.3605\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.39\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 14.3089\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1400):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 14.308940613907094)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 14.308940613907094}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=1.000, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000107935444\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1410):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.14557266 -0.13711966 -0.2096565 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.2096565007441396\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.66\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33702005 0.33874348 0.32423647]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4141, Std: 7.3704\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.39\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 6.1132\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1410):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 6.113192029622274)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 6.113192029622274}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=1.000, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000100920219\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1420):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.09183262 -0.2206077  -0.19207228]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.19207227579582448\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.65\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.34887993 0.32275226 0.3283678 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4414, Std: 5.7475\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.38\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 8.5187\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1420):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 8.518689686134135)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 8.518689686134135}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=1.000, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000086365707\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1430):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.17962176 -0.12057535 -0.17118421]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.17118421498465913\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.65\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.32878238 0.34075105 0.33046657]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4773, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.38\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 5.1994\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1430):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 5.199377585693577)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 5.199377585693577}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=1.000, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1440):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.10725428 -0.22238873 -0.21848948]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.21848947673155966\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.65\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.34873421 0.32524845 0.32601734]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X3 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4412, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.38\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -7.1811\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1440):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -7.181089955519003)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -7.181089955519003}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=1.000, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000076177899\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 120):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=18.749568\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.930\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00007618\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00007618\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.678, max=1.000, group_baseline=0.929\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.327711, entropy=-4.517543\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00067581\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 234375004.785858\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1450):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -2.53483784e-01 -1.69383822e-01 -1.35427096e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.65\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.31983768 0.33657856 0.34358376]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4462, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.38\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 8.2766\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1450):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 8.276643747183874)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 8.276643747183874}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=1.000, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000046431213\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 120: reward=0.983, intervention_rate=1.000, scm=fork_5var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1460):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.60058501e-01 -8.71199979e-02 -1.07154415e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.65\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.32488672 0.33961153 0.33550175]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4635, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.38\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -14.6137\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1460):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -14.613735327238889)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -14.613735327238889}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=1.000, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000044809945\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1470):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.77063506e-01 -1.86752546e-01 -2.56975917e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.64\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.32355658 0.32165364 0.35478977]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4854, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.38\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 16.5500\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1470):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 16.550001370300265)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 16.550001370300265}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=1.000, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000034146495\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1480):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09  6.22310764e-04 -1.20913916e-01 -1.23835076e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.64\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.35020609 0.32518637 0.32460754]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4646, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.38\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -8.9413\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1480):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -8.941319433690332)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -8.941319433690332}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=1.000, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000039065902\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1490):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.46158156e-01 -9.03546246e-02 -1.29928091e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.64\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.32844517 0.33983652 0.33171831]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4599, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.38\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -9.2842\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1490):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -9.284209273233834)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -9.284209273233834}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=1.000, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1500):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.92082430e-01 -3.00392361e-02 -1.60152762e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.64\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.32012584 0.35344189 0.32643228]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4330, Std: 7.0334\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.38\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 4.4563\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1500):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 4.4563164318817154)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 4.4563164318817154}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.44563164318817156}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.945632\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.945632\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.946) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.995, trend=-0.054\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000050376158\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 125):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=21.358825\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.992\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00005038\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00005038\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.946, max=1.000, group_baseline=0.992\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.297643, entropy=-4.805224\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00066154\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 156250005.623715\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1510):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.76010751e-01 -1.00000000e+09 -1.82507351e-01 -2.28152543e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.63\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33731127 0.         0.33597265 0.32671608]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4425, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.38\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.5000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1510):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 1.500018977357197)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 1.500018977357197}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.1500018977357197}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.650002\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.650002\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.960, trend=-0.350\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000061023963\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1520):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.00398470e-01 -1.00000000e+09 -1.81403621e-01 -8.55483447e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.63\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.32418302 0.         0.3279809  0.34783607]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4197, Std: 6.6166\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.38\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 17.3119\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1520):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 17.311914681507023)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 17.311914681507023}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.960, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000081042775\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1530):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.87721366e-01 -1.00000000e+09 -9.43808919e-02 -2.43768222e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.63\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33055992 0.         0.3500671  0.31937298]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4798, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.38\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.2999\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1530):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -0.29992501642400754)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -0.29992501642400754}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.029992501642400755}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.529993\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.529993\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.913, trend=-0.470\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000084138249\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1540):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-3.38946040e-02 -1.00000000e+09 -9.62133713e-02 -1.37952050e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.62\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.34478623 0.         0.331814   0.32339977]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4656, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.38\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.5707\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1540):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 0.5706760454735538)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': 0.5706760454735538}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.05706760454735538}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.557068\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.557068\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.868, trend=-0.443\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000099500311\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1550):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.57195344e-01 -1.00000000e+09 -2.40682793e-01 -1.04807095e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.62\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33527156 0.         0.3184518  0.34627664]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4309, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.37\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -4.0969\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1550):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -4.096941644839104)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -4.096941644839104}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.40969416448391044}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.909694\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.909694\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.910) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.859, trend=-0.090\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1560):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.27832252e-01 -1.00000000e+09 -1.33637328e-01 -1.12912463e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.62\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33270474 0.         0.33151618 0.33577907]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4505, Std: 6.1750\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.37\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -7.4090\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1560):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -7.409016560820338)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -7.409016560820338}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.859, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000099891678\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 130):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=17.752651\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.921\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00009989\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00009989\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.648, max=1.000, group_baseline=0.916\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.310394, entropy=-4.805210\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00051900\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 343750005.065724\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1570):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.84334429e-01 -1.48929920e-01 -3.26313014e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.62\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.3204789  0.32756374 0.35195736]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4784, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.37\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.5070\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1570):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -0.507046803260709)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -0.507046803260709}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.050704680326070894}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.550705\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.550705\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.814, trend=-0.449\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000101562726\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 130: reward=0.909, intervention_rate=1.000, scm=collider_5var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1580):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -2.03707184e-01 -1.73077653e-01 -1.90474118e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.62\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.31845411 0.32454683 0.35699906]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4815, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.37\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 10.4534\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1580):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 10.453354532702681)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 10.453354532702681}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.814, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000054044109\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1590):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -2.40705847e-01 -1.68685818e-01 -2.66130412e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.61\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.33003111 0.34509815 0.32487074]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4280, Std: 6.4849\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.37\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 4.2674\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1590):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 4.2674348238794355)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 4.2674348238794355}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.4267434823879436}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.926743\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.926743\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.927) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.807, trend=-0.019\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000036030451\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1600):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.27595552e-01 -1.58017790e-01 -2.30938364e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.61\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.34256813 0.33615719 0.32127469]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4491, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.37\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 10.5166\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1600):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 10.516551521323848)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 10.516551521323848}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.812, trend=+0.350\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000060500289\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1610):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -2.19486181e-01 -1.19773675e-01 -1.58343544e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.61\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.32229293 0.34291871 0.33478836]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4965, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.37\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -13.6469\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1610):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -13.646936446212862)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -13.646936446212862}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.847, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1620):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.39040731e-01 -1.09357840e-02 -2.08237570e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.61\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.32885836 0.35613969 0.31500194]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4851, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.37\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -6.1255\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1620):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -6.125511620773924)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -6.125511620773924}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.847, trend=+0.470\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000058102131\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 135):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=22.937676\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.928\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00005810\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00005810\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.598, max=1.000, group_baseline=0.925\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.290588, entropy=-4.805228\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00099222\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 328125005.221223\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1630):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -3.10485754e-01 -1.26293403e-01 -2.51448892e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.60\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.31654317 0.35504961 0.32840722]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4601, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.37\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 4.6721\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1630):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 4.672059153051221)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 4.672059153051221}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.4672059153051222}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.967206\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.967206\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.967) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.891, trend=+0.410\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000067115817\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1640):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.77219787e-01 -1.87953129e-01 -1.55562445e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.60\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.33256454 0.33034322 0.33709224]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4719, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.37\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 11.4560\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1640):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 11.456026840342203)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 11.456026840342203}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.935, trend=+0.090\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000065137852\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1650):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -2.15421839e-01 -2.09283457e-01 -2.34772583e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.60\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.        0.3342452 0.3355311 0.3302237]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4950, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.37\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.0772\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1650):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 1.077154101859288)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 1.077154101859288}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.10771541018592881}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.607715\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.607715\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.905, trend=-0.392\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000074427089\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1660):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -2.18861489e-01 -3.02587964e-01 -2.25067507e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.60\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.33955844 0.32220117 0.33824039]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4773, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.37\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.7460\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1660):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -0.7460490137355034)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -0.7460490137355034}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.07460490137355034}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.574605\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.574605\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.863, trend=+0.024\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000085501878\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1670):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -2.10129681e-01 -2.15783307e-01 -2.25114920e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.59\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.33477369 0.3335875  0.33163882]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4799, Std: 6.3214\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.36\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.3179\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1670):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 0.3178938600311587)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 0.3178938600311587}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.03178938600311587}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.531789\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.531789\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.861, trend=-0.468\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1680):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -2.41389143e-01 -2.56735788e-01 -1.07132956e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.59\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.32484868 0.32173374 0.35341758]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4669, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.36\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 14.1517\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1680):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 14.151737379868313)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 14.151737379868313}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.861, trend=+0.073\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000095252208\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 140):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=14.151737\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.886\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00009525\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00009525\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.505, max=1.000, group_baseline=0.885\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.342471, entropy=-4.805222\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00131965\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 156250004.935991\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1690):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.28996341 -0.28207268 -0.25652795 -0.26951348 -0.2474745 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.24747450347770497\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.59\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.19738425 0.19836634 0.20157933 0.19993957 0.20273051]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4730, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.36\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.6446\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1690):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 1.6445677980935602)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 1.6445677980935602}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.16445677980935602}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.664457\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.664457\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.835, trend=-0.336\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000081896418\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 140: reward=0.822, intervention_rate=1.000, scm=fork_6var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1700):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.26792005 -0.2085244  -0.2196901  -0.14761431 -0.08483063]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.08483063276588078\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.59\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.18975156 0.19698824 0.19560707 0.20469616 0.21295697]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4956, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.36\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 9.7407\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1700):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 9.740693840996052)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 9.740693840996052}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.835, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000047252484\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1710):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.29410964 -0.24218789 -0.05387361 -0.08025757 -0.21082273]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.21082273138909477\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.58\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.18533524 0.19151105 0.21568779 0.2121249  0.19534103]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4102, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.36\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -10.3083\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1710):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -10.308309877994919)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -10.308309877994919}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.835, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000025496433\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1720):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.15640673 -0.24650901 -0.21958447 -0.26685676 -0.19642962]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.19642961531634157\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.58\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.20777223 0.19626263 0.1996335  0.19375296 0.20257868]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4895, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.36\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -6.3282\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1720):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, -6.328166227059782)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -6.328166227059782}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.835, trend=+0.033\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000009862757\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1730):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.37558526 -0.22464635 -0.22261541 -0.2338637  -0.28364029]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.2836402941988479\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.58\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.18670284 0.20544179 0.20570634 0.20424536 0.19790367]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4628, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.36\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -5.8918\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1730):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, -5.891799611138932)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -5.891799611138932}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.838, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1740):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.16669496 -0.20377766 -0.29901189 -0.17472286 -0.2600612 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.2600611981412661\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.58\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.20687531 0.20207083 0.19023723 0.20582561 0.19499102]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4822, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.36\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.1196\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1740):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 1.119622422566951)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 1.119622422566951}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.11196224225669511}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.611962\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.611962\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.799, trend=+0.004\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000025145671\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 145):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=22.175077\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.914\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00002515\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00002515\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.573, max=1.000, group_baseline=0.916\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.327962, entropy=-5.028334\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00014288\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 78125005.532678\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1750):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.99920737e-01 -1.00000000e+09 -1.45185987e-01 -1.97932935e-01\n",
      " -2.72225657e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.58\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.23878633 0.         0.26343357 0.2547583  0.2430218 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4876, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.36\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 4.7357\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1750):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, 4.735707784553457)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 4.735707784553457}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.4735707784553458}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.973571\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.973571\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.974) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.836, trend=+0.399\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000012232251\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1760):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.50749780e-01 -1.00000000e+09 -2.51193801e-01 -3.04645722e-01\n",
      " -2.69039318e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.57\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.26508362 0.         0.24867838 0.24036622 0.24587179]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4244, Std: 6.4461\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.36\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -4.8761\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1760):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -4.876106438577662)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -4.876106438577662}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.48761064385776626}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.987611\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.987611\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.988) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.877, trend=+0.456\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000010572290\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1770):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-3.10101125e-01 -1.00000000e+09 -2.49466930e-01 -2.36748771e-01\n",
      " -2.29407848e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.57\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.24154547 0.         0.25106066 0.25310357 0.25429029]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4537, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.36\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.2310\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1770):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -0.23104395228839258)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -0.23104395228839258}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.02310439522883926}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.523104\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.523104\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.876, trend=-0.477\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000003646612\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1780):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.45714450e-01 -1.00000000e+09 -1.81438634e-01 -2.34090143e-01\n",
      " -1.59785466e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.57\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.24356228 0.         0.25376449 0.24537648 0.25729675]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4665, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.36\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -14.6420\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1780):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -14.641967511661443)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -14.641967511661443}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.876, trend=+0.336\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000011564986\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1790):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.08215398e-01 -1.00000000e+09 -2.60799145e-01 -2.37581132e-01\n",
      " -1.34278905e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.56\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.25020357 0.         0.24192852 0.24554803 0.26231988]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4908, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.35\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.4453\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1790):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 2.4453227506674278)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 2.4453227506674278}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.2445322750667428}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.744532\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.744532\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.884, trend=-0.255\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1800):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.45156298e-01 -1.00000000e+09 -2.13751143e-01 -2.58185719e-01\n",
      " -2.42033487e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.56\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.24912866 0.         0.25418344 0.24706114 0.24962675]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4730, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.35\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 9.9986\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1800):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 9.998606214895618)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 9.998606214895618}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.884, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000018583478\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 150):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=28.228139\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.905\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00001858\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00001858\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.596, max=1.000, group_baseline=0.907\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.343183, entropy=-5.028324\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00127733\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 93750005.500288\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1810):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.25490527 -0.2197312  -0.2103734  -0.21565694 -0.29356944]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.29356943876525726\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.56\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.19791241 0.20242392 0.2036414  0.2029531  0.19306917]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4240, Std: 6.5570\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.35\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -5.5027\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1810):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -5.5027138909103845)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -5.5027138909103845}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.884, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000002270666\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 150: reward=0.902, intervention_rate=1.000, scm=collider_6var\n",
      "INFO:causal_bayes_opt.training.modular_trainer:Saved checkpoint: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/checkpoints/grpo_training/enriched_grpo_episode_150/checkpoint.pkl\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1820):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.19140083 -0.26537761 -0.15897129 -0.24756058 -0.30398118]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.30398118186585454\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.56\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.20535926 0.195834   0.20967965 0.19808694 0.19104015]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.5044, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.35\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -5.3140\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1820):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, -5.3139861239305874)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -5.3139861239305874}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.884, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000048272996\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1830):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.27558142 -0.22604705 -0.23890922 -0.08845753 -0.24123671]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.24123670693017388\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.55\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.19206821 0.19828628 0.19665259 0.21663451 0.19635841]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.5107, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.35\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -6.3642\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1830):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, -6.364230820484974)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -6.364230820484974}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.884, trend=+0.388\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000048133361\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1840):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.26808937 -0.26128056 -0.18178329 -0.24211199 -0.2366146 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.23661460109762947\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.55\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.19611829 0.19698071 0.20733509 0.19942907 0.20013684]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4644, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.35\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.6247\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1840):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -1.6247317258717089)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -1.6247317258717089}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.1624731725871709}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.662473\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.662473\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.889, trend=-0.311\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000044766325\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1850):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.25987529 -0.18849638 -0.21315339 -0.17247247 -0.19724129]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.19724129058419165\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.55\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.19315787 0.20226801 0.19907344 0.2043715  0.20112919]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4992, Std: 6.5592\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.35\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -5.9463\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1850):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -5.946316154856537)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -5.946316154856537}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.892, trend=+0.012\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1860):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.26816699 -0.27837037 -0.21533409 -0.24532477 -0.16553441]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.16553440677808232\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.55\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.19563726 0.19435268 0.20242588 0.19854391 0.20904027]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X5 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4784, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.35\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.4215\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1860):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -1.4215138468119646)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X5': -1.4215138468119646}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.14215138468119645}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.642151\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.642151\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.857, trend=+0.119\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000031267910\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 155):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=19.316745\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.893\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00003127\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00003127\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.637, max=1.000, group_baseline=0.900\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.358914, entropy=-5.028371\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00055742\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 437500005.471939\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1870):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.65669079e-01 -2.57557550e-01 -1.00000000e+09 -3.07739007e-01\n",
      " -2.80263303e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.55\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.2519515  0.253277   0.         0.24518738 0.24958412]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X5 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4837, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.35\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 13.0350\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1870):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 13.035025123570259)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X5': 13.035025123570259}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.905, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000035674185\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1880):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.37364092e-01 -2.23517099e-01 -1.00000000e+09 -2.18676534e-01\n",
      " -2.29227210e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.54\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.24835544 0.25059428 0.         0.25138167 0.24966861]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4477, Std: 6.8860\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.35\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 20.2420\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1880):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, 20.242008246948043)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 20.242008246948043}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.905, trend=+0.255\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000045027037\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1890):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.73001947e-01 -2.02756222e-01 -1.00000000e+09 -1.49141493e-01\n",
      " -2.83898713e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.54\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.24252019 0.25383841 0.         0.26283114 0.24081026]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X5 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.5091, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.35\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -13.1618\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1890):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -13.161800333356172)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X5': -13.161800333356172}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.930, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000053724406\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1900):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.45299085e-01 -1.55998687e-01 -1.00000000e+09 -2.37269624e-01\n",
      " -2.62950600e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.54\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.24669207 0.26144847 0.         0.2479841  0.24387537]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X5 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.5075, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.35\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -19.7671\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1900):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -19.767053162858627)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X5': -19.767053162858627}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.930, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000067217193\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1910):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.24329972e-01 -2.35273449e-01 -1.00000000e+09 -2.61810623e-01\n",
      " -2.54565845e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.53\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.25321311 0.25141334 0.         0.24710196 0.2482716 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4422, Std: 7.1613\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.34\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -8.5092\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1910):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -8.509192362904162)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -8.509192362904162}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.930, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1920):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.63630702e-01 -3.03068351e-01 -1.00000000e+09 -2.63590725e-01\n",
      " -2.25813036e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.53\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.25002475 0.24367951 0.         0.25003126 0.25626447]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4552, Std: 7.3776\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.34\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.1926\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1920):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -0.19260736556895364)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -0.19260736556895364}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.019260736556895364}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.519261\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.519261\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.882, trend=-0.481\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000073833139\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 160):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=13.919245\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.918\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00007383\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00007383\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.519, max=1.000, group_baseline=0.921\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.297942, entropy=-5.028358\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00074072\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 250000005.061898\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1930):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-3.06142313e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.53\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.5163, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.34\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 8.8026\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1930):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 8.8026394805676)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 8.8026394805676}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.882, trend=+0.338\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000068872750\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 160: reward=0.963, intervention_rate=1.000, scm=fork_3var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1940):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.33923863e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.53\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4901, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.34\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -3.9487\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1940):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -3.948722696835901)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -3.948722696835901}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3948722696835901}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.894872\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.894872\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.895) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.906, trend=-0.105\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000061503555\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1950):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.18561974e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.53\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.5050, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.34\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 6.5396\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1950):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 6.539593724370518)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 6.539593724370518}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.906, trend=+0.358\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000087768971\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1960):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.73178634e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.52\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4860, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.34\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 16.2823\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1960):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 16.282298409330675)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 16.282298409330675}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.941, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000103684365\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1970):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.26279017e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.52\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4935, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.34\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -8.5270\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1970):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -8.526994772746786)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -8.526994772746786}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.941, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1980):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.07456101e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.52\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4964, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.34\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.7988\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1980):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -0.7987690870527798)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -0.7987690870527798}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.07987690870527799}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.579877\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.579877\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.899, trend=-0.420\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000132245496\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 165):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=20.529788\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.789\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00013225\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00013225\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.505, max=1.000, group_baseline=0.800\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.366936, entropy=-4.112081\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00110310\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 4.315492\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 1990):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.23551135 -0.22340184]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: -0.22340183874573413\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.52\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.49800385 0.50199615]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4904, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.34\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -6.0405\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1990):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -6.04050497827484)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -6.04050497827484}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.899, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000119504579\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2000):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.17604716 -0.22061059]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: -0.22061058948944826\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.51\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.50735962 0.49264038]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4352, Std: 7.3144\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.34\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -12.5693\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2000):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -12.56932727477798)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -12.56932727477798}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.899, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000114279991\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2010):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.23802012 -0.22890928]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: -0.2289092790822894\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.51\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.49849233 0.50150767]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4795, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.34\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -4.5563\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2010):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -4.556332851073237)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -4.556332851073237}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.4556332851073237}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.955633\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.955633\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.956) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.895, trend=+0.436\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000069689804\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2020):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.25841057 -0.20275401]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: -0.2027540142932301\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.51\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.49077302 0.50922698]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4926, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.34\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -12.0342\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2020):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -12.034185455360333)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -12.034185455360333}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.943, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000086396869\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2030):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.1788366  -0.19946253]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: -0.19946253491275076\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.50\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.50342645 0.49657355]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4807, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.33\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -10.2263\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2030):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -10.226283375208753)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -10.226283375208753}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.943, trend=+0.105\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2040):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.21020578 -0.15399434]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: -0.15399433963594697\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.50\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.49066291 0.50933709]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4248, Std: 7.2343\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.33\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -2.8548\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2040):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -2.854811715234989)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -2.854811715234989}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.2854811715234989}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.785481\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.785481\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.932, trend=-0.215\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000074528000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 170):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=26.186341\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.928\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00007453\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00007453\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.640, max=1.000, group_baseline=0.932\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.328714, entropy=-4.112074\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00044259\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 5.244192\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2050):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.42184563e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.50\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4771, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.33\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 4.0406\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2050):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 4.040635280983998)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 4.040635280983998}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.4040635280983998}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.904064\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.904064\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.904) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.923, trend=-0.096\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000073726841\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 170: reward=0.882, intervention_rate=1.000, scm=collider_3var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2060):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-8.78331238e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.50\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4694, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.33\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 11.1271\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2060):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 11.127141639727386)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 11.127141639727386}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.923, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000090187023\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2070):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.72047727e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.50\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4400, Std: 7.3493\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.33\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 7.4414\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2070):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 7.441394805117309)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 7.441394805117309}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.923, trend=+0.420\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000115678844\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2080):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.65265899e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.49\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4762, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.33\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.2373\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2080):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 3.2373495754410304)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 3.2373495754410304}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3237349575441031}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.823735\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.823735\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.824) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.947, trend=-0.176\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000178984773\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2090):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.71741283e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.49\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4427, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.33\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -20.6796\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2090):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -20.679604313156837)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -20.679604313156837}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.947, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2100):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.26806018e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.49\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4528, Std: 6.1215\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.33\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -2.3552\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2100):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -2.355224422008045)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -2.355224422008045}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.23552244220080454}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.735522\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.735522\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.920, trend=-0.220\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000211336803\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 175):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=21.654966\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.864\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00021134\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00021134\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.554, max=1.000, group_baseline=0.860\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.362952, entropy=-4.112074\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00223590\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 4.827033\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2110):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.54115193e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.49\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4563, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.33\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -5.5853\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2110):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -5.585296256683904)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -5.585296256683904}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.925, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000251540350\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2120):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.44662459e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.48\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4693, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.33\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -9.7651\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2120):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -9.76508816061782)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -9.76508816061782}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.925, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000266528553\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2130):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.5006435e-01 -1.0000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.48\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4603, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.33\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -3.6103\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2130):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -3.6103423160343526)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -3.6103423160343526}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3610342316034353}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.861034\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.861034\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.861) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.911, trend=+0.076\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000346568995\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2140):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.37455804e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.48\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4084, Std: 7.3658\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.33\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -15.1151\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2140):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -15.115116313472997)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -15.115116313472997}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.932, trend=+0.096\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000341166402\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2150):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.06777389e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.48\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4022, Std: 5.2328\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.33\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.1501\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2150):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 1.1501113577580238)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 1.1501113577580238}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.11501113577580238}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.615011\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.615011\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.904, trend=-0.385\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2160):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.34208255e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.48\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3772, Std: 6.8261\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.33\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.0907\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2160):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 2.090749462384445)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 2.090749462384445}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.20907494623844453}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.709075\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.709075\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.874, trend=-0.291\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000367630478\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 180):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=14.820819\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.912\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00036763\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00036763\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.615, max=1.000, group_baseline=0.912\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.337662, entropy=-4.112050\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00089716\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 4.307512\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2170):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.19592246 -0.06801768 -0.16504476]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.16504475665318905\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.47\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.32134449 0.35050215 0.32815336]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4307, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.32\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -2.4193\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2170):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -2.4192632700739187)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -2.4192632700739187}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.2419263270073919}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.741926\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.741926\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.849, trend=-0.082\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000306806998\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 180: reward=0.855, intervention_rate=1.000, scm=fork_4var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2180):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.24329611 -0.29900613 -0.20229341]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.20229341128449477\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.47\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33432568 0.32189023 0.34378408]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4368, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.32\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.2836\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2180):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 0.283576124624997)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 0.283576124624997}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.0283576124624997}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.528358\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.528358\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.819, trend=-0.472\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000224522634\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2190):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.11917557 -0.25667748 -0.18004563]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.18004562755298875\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.47\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.34844815 0.31726788 0.33428396]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4429, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.32\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.9670\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2190):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 3.9670274768905704)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 3.9670274768905704}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.39670274768905706}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.896703\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.896703\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.897) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.809, trend=+0.161\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000188185262\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2200):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.15045486 -0.1706748  -0.08724491]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.0872449102902383\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.46\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.32998855 0.32546185 0.3445496 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X3 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4251, Std: 5.6775\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.32\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 4.1332\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2200):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 4.133164384104511)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': 4.133164384104511}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.41331643841045107}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.913316\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.913316\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.913) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.827, trend=-0.087\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000194897429\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2210):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.09664696 -0.19875    -0.09872636]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.09872636355674394\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.46\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.34117172 0.31814181 0.34068647]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4592, Std: 6.5870\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.32\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -9.0609\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2210):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -9.060891933351453)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -9.060891933351453}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.827, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2220):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.13208875 -0.18861621 -0.23737417]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.23737416804665287\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.46\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.34571991 0.3325986  0.3216815 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4050, Std: 6.8529\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.32\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 8.1816\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2220):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 8.18157154168523)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 8.18157154168523}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.827, trend=+0.139\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000191661448\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 185):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=23.733181\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.956\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00019166\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00019166\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.538, max=1.000, group_baseline=0.959\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.221069, entropy=-4.517532\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00074107\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 234375005.354730\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2230):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-7.10322731e-02 -1.00000000e+09 -1.58017406e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.46\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.51491064 0.         0.48508936]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4571, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.32\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.0288\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2230):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 1.0288381443725414)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 1.0288381443725414}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.10288381443725414}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.602884\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.602884\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.801, trend=-0.397\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000176901482\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2240):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.61785700e-01 -1.00000000e+09 -2.09760916e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.46\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.50824198 0.         0.49175802]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4552, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.32\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 14.4301\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2240):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 14.430068749698465)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 14.430068749698465}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.801, trend=+0.385\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000173008659\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2250):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-8.27034415e-02 -1.00000000e+09 -2.22477444e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.45\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.52404475 0.         0.47595525]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4672, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.32\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.2277\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2250):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 2.2277166879203834)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 2.2277166879203834}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.22277166879203836}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.722772\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.722772\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.812, trend=+0.014\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000116775431\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2260):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.38707954e-01 -1.00000000e+09 -1.31157022e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.45\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.49869742 0.         0.50130258]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4618, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.32\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.0758\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2260):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 0.07584051989798507)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 0.07584051989798507}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.0075840519897985076}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.507584\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.507584\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.791, trend=-0.234\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000191827410\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2270):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.52699958e-01 -1.00000000e+09 -1.26707312e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.45\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.49550713 0.         0.50449287]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4120, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.32\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -4.6964\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2270):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -4.696391255696886)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -4.696391255696886}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.4696391255696886}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.969639\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.969639\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.970) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.814, trend=+0.441\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2280):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.10319137e-01 -1.00000000e+09 -1.31247188e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.45\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.50361748 0.         0.49638252]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4603, Std: 6.6981\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.32\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 12.6095\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2280):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 12.609542998955366)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 12.609542998955366}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.861, trend=+0.103\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000257565165\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 190):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=12.609543\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.933\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00025757\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00025757\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.608, max=1.000, group_baseline=0.930\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.296861, entropy=-4.517483\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00147697\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 250000004.535322\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2290):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.17580657 -0.16032944 -0.17222361]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.17222360584295254\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.44\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33186581 0.33544355 0.33269065]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X3 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4260, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.31\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 5.8646\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2290):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 5.864633311961938)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': 5.864633311961938}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.872, trend=+0.087\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000275632368\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 190: reward=0.873, intervention_rate=1.000, scm=collider_4var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2300):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.03420792 -0.09902363 -0.24274744]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.24274744152455152\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.44\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.35445708 0.33886093 0.30668199]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4439, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.31\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.6983\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2300):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 2.6982501720498226)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 2.6982501720498226}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.26982501720498225}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.769825\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.769825\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.857, trend=-0.230\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000271207826\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2310):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.08611058 -0.09264616 -0.15191377]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.15191376634087378\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.44\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33890038 0.33736307 0.32373655]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4439, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.31\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 13.6610\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2310):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 13.660987121706848)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 13.660987121706848}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.857, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000263275698\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2320):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.19539595 -0.22992439 -0.06856346]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.06856345575804204\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.43\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.32587556 0.31812575 0.35599869]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4179, Std: 7.3174\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.31\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -7.3981\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2320):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -7.3981489979027035)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -7.3981489979027035}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.857, trend=+0.397\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000228043208\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2330):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.23030102 -0.12601806 -0.17483677]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.17483677354906532\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.43\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.32102089 0.34527727 0.33370185]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4581, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.31\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -4.7556\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2330):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -4.755572075630903)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -4.755572075630903}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.47555720756309033}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.975557\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.975557\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.976) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.895, trend=-0.024\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2340):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.11563358 -0.07327641 -0.07156425]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.07156425078686979\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.43\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.32665972 0.33646882 0.33687146]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4367, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.31\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.4915\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2340):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 3.4915181792642898)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 3.4915181792642898}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.349151817926429}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.849152\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.849152\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.849) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.879, trend=+0.126\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000188876699\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 195):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=16.077486\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.915\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00018888\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00018888\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.626, max=1.000, group_baseline=0.916\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.341282, entropy=-4.517529\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00135916\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 328125004.582445\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2350):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.09515937 -0.13392578 -0.16622476]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.166224760921409\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.43\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.34191461 0.33276189 0.32532351]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4581, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.31\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.4632\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2350):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 3.4631719069041074)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 3.4631719069041074}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3463171906904108}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.846317\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.846317\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.846) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.892, trend=+0.339\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000127248175\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2360):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.17344811 -0.19593313 -0.26664892]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.2666489206290629\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.43\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.34233962 0.33698317 0.32067721]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3968, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.31\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -5.5269\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2360):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -5.526864502248382)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -5.526864502248382}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.941, trend=+0.030\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000074812753\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2370):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.06539224 -0.17562844 -0.19847353]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.1984735276773081\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.42\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.35258953 0.32630386 0.32110661]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4344, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.31\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -10.4046\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2370):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -10.404636123486155)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -10.404636123486155}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.944, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000069660349\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2380):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.14974133 -0.21570554 -0.18034565]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.18034565113939105\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.42\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.34091489 0.32543952 0.33364559]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4626, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.31\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -17.7780\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2380):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -17.77800109072229)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -17.77800109072229}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.944, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000036630669\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2390):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.23279419 -0.06001935 -0.14551726]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.14551725537178653\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.42\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.31316496 0.35377487 0.33306017]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4196, Std: 6.9052\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.31\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 6.8150\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2390):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 6.814989290914053)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 6.814989290914053}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.944, trend=+0.230\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2400):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.04697833 -0.11012271 -0.37084081]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.3708408079409714\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.42\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.36335921 0.34752258 0.28911821]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4461, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.31\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -7.9228\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2400):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -7.922778202897735)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -7.922778202897735}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.967, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000045975308\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 200):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=20.043406\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.949\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00004598\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00004598\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.587, max=1.000, group_baseline=0.952\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.270072, entropy=-4.517528\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00068171\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 328125004.899132\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2410):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -2.88315545e-01 -1.88223923e-01 -1.42280096e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.41\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.31425362 0.33730359 0.34844279]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4352, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.30\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -8.0569\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2410):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -8.056856667415133)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -8.056856667415133}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.967, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000090627992\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 200: reward=0.932, intervention_rate=1.000, scm=fork_5var\n",
      "INFO:causal_bayes_opt.training.modular_trainer:Saved checkpoint: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/checkpoints/grpo_training/enriched_grpo_episode_200/checkpoint.pkl\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2420):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -2.38401236e-01 -2.04516533e-01 -2.18069605e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.41\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.32907561 0.33707314 0.33385125]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4541, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.30\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -7.8754\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2420):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -7.875435716343582)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -7.875435716343582}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.967, trend=+0.024\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000069346317\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2430):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -2.30656895e-01 -7.36167004e-02 -3.14243368e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.41\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.3267606  0.36530987 0.30792953]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4030, Std: 7.0398\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.30\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -8.5009\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2430):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -8.500928322455053)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -8.500928322455053}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.970, trend=+0.151\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000014684060\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2440):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.17798272e-02 -2.07048211e-01 -1.45932891e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.41\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.3598133  0.31313402 0.32705268]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4390, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.30\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -4.3102\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2440):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -4.310215971739261)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -4.310215971739261}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.43102159717392613}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.931022\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.931022\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.931) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.978, trend=+0.085\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000045037917\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2450):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.51445077e-01 -2.80135919e-01 -8.54975914e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.40\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.33778462 0.30816646 0.35404892]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4223, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.30\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 9.7741\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2450):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 9.774066021353288)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 9.774066021353288}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.993, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2460):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.87410618e-01 -1.13378737e-01 -1.22366312e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.40\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.32240541 0.33988296 0.33771163]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4440, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.30\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 6.5569\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2460):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 6.556899204585867)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 6.556899204585867}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.993, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000025554600\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 205):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=21.341348\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.935\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00002555\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00002555\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.690, max=1.000, group_baseline=0.935\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.341099, entropy=-4.805224\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00018813\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 468750005.310602\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2470):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.46427317e-01 -1.00000000e+09 -8.45756256e-02 -2.97651150e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.40\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.32397389 0.         0.36369648 0.31232963]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4569, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.30\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -12.4120\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2470):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -12.411961130891235)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -12.411961130891235}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.993, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000052286293\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2480):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.17616177e-01 -1.00000000e+09 -2.30911855e-01 -2.24764641e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.40\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33496141 0.         0.33178743 0.33325116]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4371, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.30\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 6.8558\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2480):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 6.855809723972082)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 6.855809723972082}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.993, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000084770373\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2490):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.65775840e-01 -1.00000000e+09 -1.94573730e-01 -2.58082419e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.39\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.32701565 0.         0.34415836 0.328826  ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4475, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.30\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 7.8064\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2490):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 7.806399836200159)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 7.806399836200159}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.993, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000092063550\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2500):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.65067600e-01 -1.00000000e+09 -9.48683132e-02 -2.70247429e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.39\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33569091 0.         0.35307172 0.31123737]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4368, Std: 5.1495\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.30\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.3411\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2500):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -1.3410817257803098)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -1.3410817257803098}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.13410817257803098}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.634108\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.634108\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.957, trend=-0.366\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000085890696\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2510):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-7.69598165e-02 -1.00000000e+09 -1.94483399e-01 -1.39317996e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.39\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.34784357 0.         0.31959773 0.33255869]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3790, Std: 4.0012\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.30\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.6159\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2510):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 2.6158602337724015)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 2.6158602337724015}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.2615860233772402}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.761586\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.761586\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.933, trend=-0.238\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2520):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.50682249e-01 -1.00000000e+09 -1.65734127e-01 -2.12611581e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.39\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33949337 0.         0.33583089 0.32467574]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4228, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.30\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -5.5917\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2520):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -5.591683049735693)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -5.591683049735693}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.933, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000088907794\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 210):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=15.769279\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.871\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00008891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00008891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.526, max=1.000, group_baseline=0.861\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.356955, entropy=-4.805130\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00052955\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 578125004.697988\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2530):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.00244669e-01 -1.11175995e-01 -1.61933843e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.38\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.33914787 0.33648118 0.32437095]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3892, Std: 7.1886\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.29\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 6.1416\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2530):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 6.141583217579269)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 6.141583217579269}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.933, trend=+0.069\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000075946345\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 210: reward=0.903, intervention_rate=1.000, scm=collider_5var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2540):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -2.24003809e-01 -1.58950333e-01 -2.42846307e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.38\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.32952621 0.34541046 0.32506333]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4425, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.29\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -4.3051\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2540):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -4.305115711620699)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -4.305115711620699}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.43051157116206995}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.930512\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.930512\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.931) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.933, trend=-0.069\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000054465502\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2550):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -8.96743789e-02 -1.07234043e-01 -1.58721349e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.38\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.34030904 0.33600285 0.32368811]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4209, Std: 7.1985\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.29\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -5.3717\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2550):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -5.371695475201439)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -5.371695475201439}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.933, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000046658152\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2560):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -2.78500783e-01 -1.83178291e-01 -5.98496854e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.38\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.30826519 0.33037774 0.36135706]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4461, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.29\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 22.2056\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2560):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 22.205613565126647)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 22.205613565126647}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.933, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000031819098\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2570):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -2.59621924e-01 -2.33885711e-01 -1.46324546e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.37\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.32206784 0.32816157 0.3497706 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4610, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.29\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -6.5995\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2570):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -6.599482431069771)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -6.599482431069771}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.933, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2580):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -2.06382779e-01 -2.63170969e-01 -2.40824263e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.37\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.34074889 0.32694324 0.33230787]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3745, Std: 6.1229\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.29\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -8.7755\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2580):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -8.77552564636433)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -8.77552564636433}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.933, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000021704629\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 215):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=22.178916\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.899\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00002170\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00002170\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.623, max=1.000, group_baseline=0.905\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.364087, entropy=-4.805154\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00106838\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 578125005.417871\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2590):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -2.26351021e-01 -2.21064454e-01 -3.05870361e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.37\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.33927291 0.34058451 0.32014258]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4178, Std: 6.8588\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.29\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.8483\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2590):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 0.8482606219953853)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 0.8482606219953853}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.08482606219953853}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.584826\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.584826\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.891, trend=-0.049\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000030925903\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2600):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -2.11191811e-01 -1.73024091e-01 -1.44024684e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.37\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.32481611 0.33401175 0.34117214]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4443, Std: 6.1151\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.29\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -2.3391\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2600):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -2.339138344996213)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -2.339138344996213}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.23391383449962133}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.733914\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.733914\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.901, trend=-0.028\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000009899802\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2610):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.17377197e-01 -1.86479053e-01 -1.84879932e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.36\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.34455022 0.32753282 0.32791696]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4321, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.29\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 4.6199\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2610):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 4.619945636179541)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 4.619945636179541}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.4619945636179541}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.961995\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.961995\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.962) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.921, trend=-0.038\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000055711091\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2620):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -2.45566982e-01  3.85800822e-02 -3.19479096e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.36\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.3145383  0.38754566 0.29791605]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4502, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.29\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -2.4524\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2620):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -2.4524215330875343)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -2.4524215330875343}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.24524215330875343}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.745242\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.745242\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.896, trend=-0.255\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000062189483\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2630):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -2.75924293e-01 -1.50838397e-01 -1.90162514e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.36\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.31629292 0.34680134 0.33690575]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4440, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.29\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -9.1194\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2630):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -9.119433487932566)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -9.119433487932566}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.896, trend=+0.069\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2640):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.79361643e-01 -1.33335608e-01 -1.42210475e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.36\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.32656369 0.3378181  0.33561821]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4065, Std: 6.6496\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.29\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.5118\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2640):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -1.5117803900807785)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -1.5117803900807785}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.15117803900807786}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.651178\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.651178\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.868, trend=-0.349\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000062608818\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 220):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=13.341550\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.859\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00006261\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00006261\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.502, max=1.000, group_baseline=0.859\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.363878, entropy=-4.805215\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00176791\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 421875004.708265\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2650):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.33504074 -0.25323516 -0.26036299 -0.14118022 -0.23735439]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.2373543874118379\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.36\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.18700911 0.19864307 0.19760123 0.21576252 0.20098407]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4467, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.29\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 9.6758\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2650):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 9.675755208377105)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': 9.675755208377105}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.868, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000053115800\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 220: reward=0.903, intervention_rate=1.000, scm=fork_6var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2660):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.12776079 -0.2959055  -0.24073244 -0.23651958 -0.2927803 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.29278029930445526\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.35\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.21687995 0.19152649 0.19950082 0.20012319 0.19196955]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4642, Std: 6.9809\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.28\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -5.0302\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2660):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, -5.0302005794839415)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -5.0302005794839415}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.868, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000040550797\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2670):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.30301085 -0.17215227 -0.13846727 -0.22280933 -0.37159758]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.3715975755905191\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.35\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.1907248  0.21014376 0.21545476 0.20240229 0.18127439]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X5 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4264, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.28\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 9.6415\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2670):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 9.641503940842684)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X5': 9.641503940842684}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.868, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000025463156\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2680):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.13707551 -0.13650227 -0.16059329 -0.07194244 -0.20388125]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.20388125019580122\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.35\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.20063115 0.20071657 0.19715784 0.2105733  0.19092113]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4479, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.28\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -16.7212\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2680):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -16.721237956860424)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -16.721237956860424}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.868, trend=+0.415\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000028786925\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2690):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.16413861 -0.25751092 -0.26662338 -0.22026228 -0.3063316 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.30633160070779375\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.34\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.21194869 0.19772118 0.1963849  0.20327866 0.19066657]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4328, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.28\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -3.2744\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2690):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, -3.274427126923648)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -3.274427126923648}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3274427126923648}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.827443\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.827443\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.827) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.892, trend=+0.094\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2700):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.3236829  -0.19974143 -0.31864828 -0.17824757 -0.20597635]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.2059763536469926\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.34\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.18845777 0.20666714 0.18916519 0.20999945 0.20571044]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4365, Std: 6.1640\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.28\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.5928\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2700):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -0.5928415330095727)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.5928415330095727}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.059284153300957265}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.559284\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.559284\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.875, trend=-0.403\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000019655870\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 225):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=20.819391\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.910\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00001966\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00001966\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.559, max=1.000, group_baseline=0.912\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.330000, entropy=-5.028302\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00050329\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 78125005.449714\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2710):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-3.15886406e-01 -1.00000000e+09 -1.23396453e-01 -1.60421440e-01\n",
      " -1.27590418e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.34\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.22583115 0.         0.26069442 0.25359417 0.25988026]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4371, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.28\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -4.7528\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2710):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -4.752761275685996)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -4.752761275685996}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.47527612756859966}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.975276\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.975276\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.975) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.876, trend=+0.230\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000020239289\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2720):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.59608720e-01 -1.00000000e+09 -2.27967120e-01 -1.96739096e-01\n",
      " -3.13118033e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.34\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.26216333 0.         0.24910477 0.25498757 0.23374433]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4306, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.28\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -36.3361\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2720):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -36.336105084666876)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -36.336105084666876}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.901, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000064362600\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2730):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.61929807e-01 -1.00000000e+09 -2.48508866e-01 -1.38816954e-01\n",
      " -2.11392512e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.33\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.25521313 0.         0.23918657 0.25967024 0.24593006]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4457, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.28\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -7.3480\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2730):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -7.3480059790705115)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -7.3480059790705115}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.901, trend=+0.349\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000107010069\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2740):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.23140000e-01 -1.00000000e+09 -1.90645485e-01 -1.42657319e-01\n",
      " -2.06358254e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.33\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.25803285 0.         0.24528194 0.25427964 0.24240557]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4510, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.28\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -6.3745\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2740):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, -6.374540679095815)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -6.374540679095815}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.936, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000142158200\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2750):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.13323282e-01 -1.00000000e+09 -8.26851532e-03 -1.68183884e-01\n",
      " -1.53019181e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.33\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.24922811 0.         0.26972706 0.23915028 0.24189455]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4181, Std: 7.2093\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.28\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.3160\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2750):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 1.3160426781980683)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 1.3160426781980683}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.13160426781980683}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.631604\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.631604\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.899, trend=-0.368\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2760):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.16057210e-01 -1.00000000e+09 -2.65221892e-01 -2.64777198e-01\n",
      " -7.86684667e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.33\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.24773364 0.         0.23873717 0.23881706 0.27471214]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4337, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.28\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.2163\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2760):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 0.2163124184276216)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 0.2163124184276216}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.02163124184276216}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.521631\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.521631\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.852, trend=-0.478\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000168461509\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 230):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=16.263976\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.840\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00016846\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00016846\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.522, max=1.000, group_baseline=0.835\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.370008, entropy=-5.028343\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00030502\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 78125005.118415\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2770):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.06360945 -0.1318512  -0.04151512 -0.10742166 -0.19839608]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.19839608326489744\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.33\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.20671812 0.19634994 0.21019094 0.20000044 0.18674056]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4385, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.28\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 6.8525\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2770):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 6.852465340441123)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 6.852465340441123}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.852, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000176006193\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 230: reward=0.859, intervention_rate=1.000, scm=collider_6var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2780):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.12562532 -0.12687726 -0.23529407 -0.15047836 -0.20239885]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.2023988526248158\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.32\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.20641786 0.20622265 0.18999993 0.20257711 0.19478245]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4421, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.27\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -14.0677\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2780):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -14.067735572579435)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -14.067735572579435}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.852, trend=+0.173\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000161888816\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2790):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.12869727 -0.14681546 -0.23577876 -0.12525988 -0.15971087]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.1597108680047914\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.32\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.20458848 0.20180016 0.18865075 0.20512182 0.19983879]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X5 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4582, Std: 7.2514\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.27\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -6.7096\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2790):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -6.709569112281989)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X5': -6.709569112281989}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.869, trend=+0.441\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000149443560\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2800):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.00381181 -0.09241316 -0.15678351 -0.03855695 -0.16352221]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.16352220857351668\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.32\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.21344151 0.19955846 0.19004197 0.20788571 0.18907235]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4525, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.27\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 5.9698\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2800):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, 5.969779512521372)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 5.969779512521372}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.913, trend=+0.025\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000135193961\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2810):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.15064061 -0.17541995 -0.16023356 -0.06333984 -0.04028725]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.04028725045356352\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.31\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.19492024 0.19128013 0.19350288 0.20830565 0.2119911 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4377, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.27\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 5.0032\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2810):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 5.003182409856054)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 5.003182409856054}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.915, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2820):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.20365531 -0.09369565 -0.11500736 -0.27703147 -0.12278565]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.12278565303083272\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.31\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.19356653 0.21045579 0.2070711  0.18305721 0.20584937]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4322, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.27\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 5.9452\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2820):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 5.945179246626265)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': 5.945179246626265}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.915, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000126182453\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 235):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=18.477502\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.876\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00012618\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00012618\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.502, max=1.000, group_baseline=0.880\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.344330, entropy=-5.028338\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00022196\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 5.385519\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2830):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-5.51321039e-02 -1.45129880e-01 -1.00000000e+09 -1.16333410e-01\n",
      " -1.62980674e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.31\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.26252596 0.24511541 0.         0.25055681 0.24180182]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4499, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.27\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -3.0077\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2830):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -3.0076814913501386)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -3.0076814913501386}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3007681491350139}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.800768\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.800768\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.801) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.895, trend=-0.199\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000131717457\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2840):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.57670848e-01 -1.22885200e-01 -1.00000000e+09 -5.29933761e-02\n",
      " -1.53978711e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.31\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.24312898 0.24967862 0.         0.26337647 0.24381593]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4278, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.27\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 20.6159\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2840):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 20.61593419129149)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': 20.61593419129149}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.895, trend=+0.368\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000119619538\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2850):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.14223544e-01 -8.20079261e-02 -1.00000000e+09 -1.29709186e-01\n",
      " -6.50956373e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.31\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.2468201  0.25298582 0.         0.24391001 0.25628407]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3928, Std: 6.8920\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.27\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -14.3908\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2850):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, -14.3907722329025)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -14.3907722329025}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.932, trend=+0.478\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000094026336\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2860):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.78207728e-01 -7.00501503e-02 -1.00000000e+09 -2.54793740e-01\n",
      " -2.52947615e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.30\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.25165358 0.27343857 0.         0.23728568 0.23762218]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4571, Std: 6.7720\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.27\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -6.2060\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2860):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -6.205977923261425)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -6.205977923261425}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.980, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000080073510\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2870):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-9.35856643e-02 -7.60496232e-02 -1.00000000e+09 -7.15281972e-02\n",
      " -1.43190953e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.30\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.25042242 0.25382383 0.         0.2547083  0.24104545]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3853, Std: 6.6965\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.27\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 6.2330\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2870):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 6.23296896121437)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 6.23296896121437}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.980, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2880):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.89803165e-01 -5.27860540e-02 -1.00000000e+09 -5.65581520e-02\n",
      " -1.11391475e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.30\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.23357377 0.25954019 0.         0.25878808 0.24809797]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4111, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.27\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.1029\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2880):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 3.1028548005118908)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 3.1028548005118908}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3102854800511891}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.810285\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.810285\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.810) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.961, trend=-0.190\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000046535678\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 240):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=20.536765\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.906\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00004654\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00004654\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.546, max=1.000, group_baseline=0.909\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.324052, entropy=-5.028365\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00067865\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 250000005.105629\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2890):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.19802135e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.30\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4459, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.27\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -3.3990\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2890):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -3.3989917235645972)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -3.3989917235645972}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3398991723564597}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.839899\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.839899\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.840) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.945, trend=-0.160\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000008385717\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 240: reward=0.906, intervention_rate=1.000, scm=fork_3var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2900):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.35961457e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.29\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4255, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.26\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -6.2401\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2900):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -6.240122617606046)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -6.240122617606046}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.945, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000041122568\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2910):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.03172031e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.29\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4363, Std: 6.6163\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.26\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -16.3622\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2910):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -16.362165376584954)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -16.362165376584954}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.945, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000062780356\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2920):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.72357802e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.29\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4594, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.26\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.1190\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2920):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 2.1189891417465057)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 2.1189891417465057}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.21189891417465057}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.711899\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.711899\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.916, trend=-0.089\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000082126238\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2930):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.90415336e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.29\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4200, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.26\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -8.1722\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2930):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -8.172238841147983)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -8.172238841147983}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.936, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2940):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.75847908e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.29\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4249, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.26\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 21.8500\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2940):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 21.850014849518157)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 21.850014849518157}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.936, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000086790012\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 245):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=21.850015\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.860\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00008679\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00008679\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.526, max=1.000, group_baseline=0.855\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.372483, entropy=-4.112076\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00036225\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 4.435548\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2950):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.03176953 -0.19955018]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: -0.19955017581657128\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.28\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.53266616 0.46733384]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4520, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.26\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -11.5424\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2950):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -11.542361554297315)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -11.542361554297315}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.936, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000069483902\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2960):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.10699789 -0.01180711]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: -0.011807108519923983\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.28\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.48140641 0.51859359]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4283, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.26\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -23.7190\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2960):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -23.718968726090697)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -23.718968726090697}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.936, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000061363057\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2970):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.08936237 -0.17270849]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: -0.17270848745955522\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.28\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.51631907 0.48368093]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4342, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.26\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 12.2782\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2970):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 12.278217095016341)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 12.278217095016341}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.936, trend=+0.190\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000048065668\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2980):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.09994421 -0.07722321]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: -0.07722321122767675\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.27\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.49553955 0.50446045]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4118, Std: 7.1935\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.26\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 21.2053\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2980):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 21.205347879742057)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 21.205347879742057}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.955, trend=+0.160\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000041431568\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 2990):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.16343345 -0.12163643]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: -0.12163642928793905\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.27\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.49177627 0.50822373]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3712, Std: 6.6154\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.26\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.2132\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 2990):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 0.2132123630852836)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 0.2132123630852836}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.021321236308528363}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.521321\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.521321\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.923, trend=-0.479\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3000):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.00834878 -0.08302666]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: -0.08302665921614397\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.27\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.51469027 0.48530973]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4600, Std: 6.8799\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.26\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -21.9710\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3000):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -21.971018731097047)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -21.971018731097047}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.923, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000035859055\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 250):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=24.311781\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.757\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00003586\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00003586\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.521, max=1.000, group_baseline=0.751\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.378787, entropy=-4.112060\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00409259\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 4.626573\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3010):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.0671723e-01 -1.0000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.27\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4391, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.26\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 7.2818\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3010):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 7.281779241885811)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 7.281779241885811}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.923, trend=+0.288\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000026376524\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 250: reward=0.854, intervention_rate=1.000, scm=collider_3var\n",
      "INFO:causal_bayes_opt.training.modular_trainer:Saved checkpoint: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/checkpoints/grpo_training/enriched_grpo_episode_250/checkpoint.pkl\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3020):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.14584222e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.26\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4359, Std: 6.2711\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.25\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.6993\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3020):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 2.6992769457837893)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 2.6992769457837893}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.26992769457837895}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.769928\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.769928\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.929, trend=-0.230\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000012048846\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3030):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-8.26884306e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.26\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3772, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.25\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -9.5695\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3030):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -9.569457116405378)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -9.569457116405378}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.929, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000001621905\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3040):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.46199227e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.26\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3724, Std: 6.4179\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.25\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.5228\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3040):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -1.5227861289743407)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -1.5227861289743407}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.15227861289743408}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.652279\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.652279\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.894, trend=-0.348\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000030975577\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3050):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-6.7440822e-02 -1.0000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.26\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4263, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.25\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.0860\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3050):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 1.0860230902062111)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 1.0860230902062111}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.10860230902062112}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.608602\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.608602\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.855, trend=-0.391\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3060):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-7.27355232e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.26\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3936, Std: 6.8962\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.25\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -2.3488\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3060):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -2.3487764533333477)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -2.3487764533333477}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.23487764533333477}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.734878\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.734878\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.829, trend=-0.265\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000103866823\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 255):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=19.643668\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.866\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00010387\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00010387\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.529, max=1.000, group_baseline=0.867\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.323277, entropy=-4.112050\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00056773\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 4.108096\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3070):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.14976158e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.25\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3579, Std: 6.0402\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.25\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -13.2198\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3070):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -13.21979461544893)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -13.21979461544893}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.829, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000149217256\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3080):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 2.77208515e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.25\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3627, Std: 6.6733\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.25\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.7828\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3080):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 1.7828042477450736)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 1.7828042477450736}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.17828042477450737}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.678280\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.678280\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.797, trend=+0.157\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000218207902\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3090):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.56678302e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.25\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4376, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.25\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -21.1011\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3090):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -21.10108979753693)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -21.10108979753693}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.844, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000227694170\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3100):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-5.40147636e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.24\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3793, Std: 7.1197\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.25\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -5.0156\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3100):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -5.015577221846509)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -5.015577221846509}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.844, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000352419569\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3110):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 6.86834606e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.24\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3755, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.25\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -2.1489\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3110):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -2.1488587584485863)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -2.1488587584485863}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.21488587584485863}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.714886\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.714886\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.816, trend=-0.055\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3120):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.9058546e-01 -1.0000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.24\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4123, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.25\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.1052\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3120):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 2.1051581133932444)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 2.1051581133932444}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.21051581133932445}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.710516\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.710516\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.810, trend=-0.289\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000477993150\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 260):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=13.042018\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.859\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00047799\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00047799\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.534, max=1.000, group_baseline=0.857\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.368122, entropy=-4.111939\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00097738\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 4.114350\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3130):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.09690068 -0.00229475 -0.22689166]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.22689166265422236\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.24\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33559968 0.36224473 0.30215559]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4202, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.25\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -7.6259\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3130):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -7.625926895695002)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -7.625926895695002}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.810, trend=+0.348\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000454790507\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 260: reward=0.899, intervention_rate=1.000, scm=fork_4var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3140):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.08646148 -0.2759083  -0.06663192]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.06663192092722887\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.24\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.34794629 0.2984772  0.35357651]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3799, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.25\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.9898\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3140):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -0.9897955130716438)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -0.9897955130716438}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.09897955130716439}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.598980\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.598980\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.805, trend=-0.010\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000347954532\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3150):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.00510392 -0.02922804  0.01758107]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: 0.01758106975709446\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.23\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33342302 0.32695987 0.33961711]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4175, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.24\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 13.0499\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3150):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 13.049942026879766)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 13.049942026879766}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.844, trend=+0.265\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000244802688\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3160):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.04755589 -0.24252412 -0.19387109]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.1938710913360677\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.23\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.36480884 0.31131251 0.32387865]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3812, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.24\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.0444\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3160):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 2.0443928121948978)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 2.0443928121948978}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.2044392812194898}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.704439\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.704439\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.841, trend=-0.296\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000222165578\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3170):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.05740856  0.07968509 -0.16727583]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.16727582955203346\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.23\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.32975249 0.36874781 0.3014997 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3873, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.24\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 14.0448\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3170):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 14.044798059532864)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 14.044798059532864}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.841, trend=+0.322\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3180):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.03793616 -0.06316457 -0.23081321]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.2308132089229888\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.23\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.35284171 0.34565845 0.30149983]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X3 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3965, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.24\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 26.4895\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3180):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 26.48950251160681)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': 26.48950251160681}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.873, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000204273592\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 265):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=26.489503\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.881\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00020427\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00020427\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.548, max=1.000, group_baseline=0.882\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.341222, entropy=-4.517405\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00042203\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 578125005.126049\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3190):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.02622650e-01 -1.00000000e+09 -9.96697354e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.22\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.47897813 0.         0.52102187]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3751, Std: 7.0046\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.24\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.4139\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3190):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 3.4138922653895145)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 3.4138922653895145}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3413892265389515}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.841389\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.841389\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.841) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.857, trend=-0.159\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000110142181\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3200):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-9.52825462e-02 -1.00000000e+09 -3.21173629e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.22\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.48706666 0.         0.51293334]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4111, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.24\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 21.7247\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3200):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 21.72466952844036)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 21.72466952844036}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.857, trend=+0.285\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000060233228\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3210):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-4.83523298e-03 -1.00000000e+09 -1.02457899e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.22\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.5200305 0.        0.4799695]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3720, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.24\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 4.3427\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3210):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 4.342711984531586)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 4.342711984531586}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.4342711984531586}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.934271\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.934271\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.934) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.879, trend=+0.224\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000079530353\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3220):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-4.81010719e-02 -1.00000000e+09 -2.55276803e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.21\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.54253121 0.         0.45746879]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3711, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.24\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -21.7866\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3220):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -21.78658986707974)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -21.78658986707974}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.908, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000157377981\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3230):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.14439092e-02 -1.00000000e+09  6.40935709e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.21\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.48442277 0.         0.51557723]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4232, Std: 6.0714\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.24\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -6.2922\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3230):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -6.292170856505461)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -6.292170856505461}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.908, trend=+0.401\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3240):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-3.20421704e-02 -1.00000000e+09  6.79037879e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.21\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.4793943 0.        0.5206057]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4043, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.24\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -9.4493\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3240):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -9.44930099847016)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -9.44930099847016}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.948, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000222349928\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 270):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=12.899347\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.767\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00022235\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00022235\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.511, max=1.000, group_baseline=0.768\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.391048, entropy=-4.517428\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00254972\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 515625004.447781\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3250):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 0.00066552 -0.06069586 -0.08083337]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.08083337325602279\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.21\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.34658166 0.32943003 0.32398831]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3657, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.24\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 4.7604\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3250):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 4.760438262422378)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 4.760438262422378}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.4760438262422378}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.976044\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.976044\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.976) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.946, trend=+0.272\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000251282648\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 270: reward=0.957, intervention_rate=1.000, scm=collider_4var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3260):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [0.08783692 0.28549887 0.01369375]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: 0.013693753636522109\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.21\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.32067089 0.37777799 0.30155112]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X3 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2784, Std: 5.1635\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.24\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -4.9921\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3260):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -4.9921189124184755)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -4.9921189124184755}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.49921189124184756}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.999212\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.999212\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.999) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.975, trend=-0.001\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000256125778\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3270):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 0.2118543  -0.00224469  0.0789043 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: 0.07890429691949073\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.20\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.3659833  0.30632153 0.32769517]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3909, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.23\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 10.8357\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3270):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 10.835714777352639)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 10.835714777352639}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.975, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000255127824\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3280):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.02254779  0.06523664  0.1689493 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: 0.16894930435277358\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.20\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.30779916 0.3311559  0.36104494]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3859, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.23\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -3.9549\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3280):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -3.9548554764922663)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -3.9548554764922663}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.39548554764922667}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.895486\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.895486\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.895) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.965, trend=+0.054\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000247970762\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3290):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 0.1289833   0.14645836 -0.06629713]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.06629713090762798\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.20\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.34913708 0.35427039 0.29659254]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X3 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3928, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.23\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.6532\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3290):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 2.6531725845622955)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': 2.6531725845622955}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.26531725845622955}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.765317\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.765317\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.957, trend=-0.235\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3300):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 0.05804439  0.11930188 -0.01503084]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.015030835927638922\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.20\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33408098 0.3516189  0.31430012]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3910, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.23\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.3645\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3300):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 2.3644848056566734)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 2.3644848056566734}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.23644848056566736}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.736448\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.736448\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.931, trend=-0.198\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000198444643\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 275):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=12.011422\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.839\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00019844\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00019844\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.524, max=1.000, group_baseline=0.835\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.367389, entropy=-4.517511\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00191095\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 250000004.329214\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3310):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [0.15700052 0.17125917 0.04837074]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: 0.04837073558219721\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.19\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.3418722  0.34597812 0.31214969]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4137, Std: 6.6338\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.23\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 4.3437\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3310):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 4.343692529967934)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 4.343692529967934}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.43436925299679346}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.934369\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.934369\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.934) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.931, trend=-0.066\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000187896853\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3320):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [0.14401137 0.02359053 0.07593192]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: 0.07593192316210153\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.19\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.35108347 0.31733229 0.33158424]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3994, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.23\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -15.1708\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3320):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -15.17084556935702)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -15.17084556935702}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.931, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000171056548\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3330):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [0.11628304 0.11750111 0.07174259]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: 0.07174258547176592\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.19\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33735437 0.3377003  0.32494534]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3803, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.23\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.3460\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3330):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 0.34595683130418076)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 0.34595683130418076}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.034595683130418074}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.534596\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.534596\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.884, trend=-0.465\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000162532432\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3340):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 0.1725736  -0.10816657 -0.04641126]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.046411260872995984\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.19\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.38160789 0.30114484 0.31724727]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3836, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.23\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.7639\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3340):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -1.7638681794647955)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -1.7638681794647955}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.17638681794647956}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.676387\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.676387\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.852, trend=-0.300\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000113711097\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3350):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [0.16926713 0.19819448 0.12763144]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: 0.12763144482263655\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.18\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33442935 0.34271051 0.32286015]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X3 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3255, Std: 6.4215\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.23\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.7423\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3350):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 3.7422939149337022)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': 3.7422939149337022}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.37422939149337026}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.874229\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.874229\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.874) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.842, trend=-0.125\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3360):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [0.19991377 0.1161293  0.05068209]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: 0.05068209446465693\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.18\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.35548551 0.33117199 0.3133425 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X3 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3633, Std: 6.6724\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.23\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.1556\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3360):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -1.1556308627586265)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -1.1556308627586265}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.11556308627586265}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.615563\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.615563\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.803, trend=-0.384\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000101864580\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 280):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=15.284136\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.925\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00010186\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00010186\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.616, max=1.000, group_baseline=0.928\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.305840, entropy=-4.517516\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00145351\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 671875004.844491\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3370):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -2.68679161e-02  1.94159974e-01  3.07229943e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.18\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.2830099  0.34132778 0.37566232]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3562, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.23\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 17.3757\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3370):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 17.375672224941106)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 17.375672224941106}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.803, trend=+0.105\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000076793974\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 280: reward=0.869, intervention_rate=1.000, scm=fork_5var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3380):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -4.76282352e-02  3.17300222e-02  6.46771213e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.18\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.3154671  0.33747534 0.34705756]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3687, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.23\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 9.7085\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3380):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 9.708536742823926)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 9.708536742823926}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.814, trend=+0.235\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000039664929\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3390):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09  6.83760014e-02  1.07379084e-01  1.30113275e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.17\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.32385644 0.33479807 0.34134549]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3916, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.22\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 5.8526\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3390):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 5.852627156144751)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 5.852627156144751}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.837, trend=+0.264\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000019823320\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3400):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09  1.20465831e-01  1.51580653e-01  1.30926656e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.17\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.32939121 0.33826161 0.33234718]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3921, Std: 6.4231\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.22\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -3.1528\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3400):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -3.152794465648623)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -3.152794465648623}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3152794465648623}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.815279\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.815279\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.815) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.845, trend=-0.119\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000033148584\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3410):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09  8.65678853e-02  1.87456943e-02  6.04825256e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.17\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.34229005 0.32297986 0.33473009]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3843, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.22\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.9292\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3410):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 1.9291982694228214)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 1.9291982694228214}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.19291982694228216}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.692920\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.692920\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.821, trend=-0.307\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3420):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09  1.78189274e-01  3.89693738e-02 -7.51257505e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.17\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.37138077 0.32964937 0.29896986]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3470, Std: 6.7885\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.22\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.4072\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3420):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 2.40716282795592)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 2.40716282795592}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.24071628279559198}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.740716\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.740716\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.795, trend=+0.206\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000047602018\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 285):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=14.598027\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.893\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00004760\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00004760\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.662, max=1.000, group_baseline=0.889\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.349360, entropy=-4.805225\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00045192\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 500000004.847502\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3430):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-3.91424853e-02 -1.00000000e+09  9.50071747e-02  2.25892358e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.17\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.31481655 0.         0.35323592 0.33194753]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3766, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.22\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.8539\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3430):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 3.8538624714835996)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': 3.8538624714835996}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.38538624714836}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.885386\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.885386\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.885) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.830, trend=+0.209\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000057550999\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3440):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 2.73918655e-02 -1.00000000e+09  1.03993545e-01 -2.59454641e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.16\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33076687 0.         0.35330435 0.31592878]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3332, Std: 6.8889\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.22\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 4.0935\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3440):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 4.093478580229799)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': 4.093478580229799}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.4093478580229799}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.909348\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.909348\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.909) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.853, trend=+0.035\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000071289345\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3450):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.07284416e-01 -1.00000000e+09  6.36712266e-02  7.01700244e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.16\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.30081201 0.         0.34861402 0.35057397]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3667, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.22\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 15.1399\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3450):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 15.139893992837566)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': 15.139893992837566}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.866, trend=+0.384\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000066762839\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3460):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 8.08363158e-02 -1.00000000e+09 -8.80907303e-03  1.40754304e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.16\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33572984 0.         0.31068379 0.35358636]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3816, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.22\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -16.6179\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3460):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -16.61786901517464)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -16.61786901517464}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.904, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000069140758\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3470):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 9.86066213e-02 -1.00000000e+09 -9.29222094e-02  5.03340933e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.15\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.35637947 0.         0.30184956 0.34177097]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3206, Std: 4.2878\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.22\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.4245\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3470):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -1.4245428614596618)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -1.4245428614596618}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.1424542861459662}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.642454\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.642454\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.869, trend=-0.358\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3480):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.77793241e-02 -1.00000000e+09 -6.40492132e-02  1.74085235e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.15\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.31642346 0.         0.30662734 0.3769492 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3390, Std: 6.2579\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.22\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -3.0982\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3480):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -3.0981788406085724)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -3.0981788406085724}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.30981788406085725}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.809818\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.809818\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.810) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.850, trend=-0.190\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000072829963\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 290):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=14.957883\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.929\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00007283\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00007283\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.642, max=1.000, group_baseline=0.926\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.310101, entropy=-4.805087\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00114704\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 343750004.944977\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3490):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -4.33399013e-02  3.81166397e-03  8.11356861e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.15\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.31684545 0.33010196 0.35305259]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3835, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.22\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 11.0289\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3490):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 11.028902764827354)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 11.028902764827354}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.850, trend=+0.185\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000061886761\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 290: reward=0.896, intervention_rate=1.000, scm=collider_5var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3500):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09  1.44183153e-01  9.21429667e-02  2.21289916e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.15\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.35029294 0.33476116 0.3149459 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3480, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.22\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 4.5687\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3500):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 4.568717428449968)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 4.568717428449968}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.4568717428449969}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.956872\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.956872\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.957) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.864, trend=+0.264\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000074561792\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3510):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09  5.87893528e-02  1.13131729e-01  4.51737687e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.14\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.32929404 0.34530605 0.3253999 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3514, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.21\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 9.7934\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3510):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 9.793417598379719)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 9.793417598379719}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.894, trend=+0.259\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000049233878\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3520):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09  8.62440316e-02  7.81786165e-02  1.50093465e-03]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.14\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.34229972 0.33988989 0.31781039]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3944, Std: 6.7896\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.21\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.5584\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3520):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 0.5583849079109673)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 0.5583849079109673}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.055838490791096734}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.555838\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.555838\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.876, trend=-0.330\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000039472534\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3530):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09  8.33018266e-02  1.31759915e-01  2.17201124e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.14\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.31563057 0.32935267 0.35501675]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3260, Std: 6.4676\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.21\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.7237\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3530):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 3.7236876076510312)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 3.7236876076510312}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.37236876076510317}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.872369\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.872369\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.872) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.875, trend=-0.037\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3540):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -4.33529789e-02  6.56271610e-02  1.34333172e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.14\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.30587412 0.33659545 0.35753043]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4018, Std: 6.3685\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.21\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -8.5590\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3540):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -8.558981089297708)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -8.558981089297708}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.884, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000016012379\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 295):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=12.888326\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.875\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00001601\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00001601\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.563, max=1.000, group_baseline=0.867\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.331387, entropy=-4.805201\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00063347\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 437500004.755970\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3550):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09  1.13039878e-01 -1.73227779e-02 -1.55650060e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.14\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.37301101 0.3325619  0.29442709]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3625, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.21\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.6657\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3550):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -0.6657163061388296)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -0.6657163061388296}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.06657163061388296}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.566572\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.566572\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.840, trend=-0.433\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000023455573\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3560):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09  2.04381787e-02  1.24913986e-01 -2.99441260e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.13\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.32753458 0.35917889 0.31328654]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3649, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.21\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 9.5667\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3560):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 9.566686606139058)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 9.566686606139058}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.840, trend=+0.358\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000009258021\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3570):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09  1.71662829e-02  5.35250381e-02  3.70072340e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.13\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.32782394 0.33854463 0.33363143]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3527, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.21\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 6.8678\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3570):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 6.867845516951652)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 6.867845516951652}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.876, trend=+0.190\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000032771139\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3580):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09  1.88979156e-01  6.30072115e-02  5.29699437e-03]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.13\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.36445278 0.32590828 0.30963894]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3704, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.21\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.4574\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3580):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 3.457361364246335)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 3.457361364246335}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3457361364246335}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.845736\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.845736\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.846) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.880, trend=-0.154\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000038326057\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3590):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -3.13657140e-02  2.06108876e-01  1.24109286e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.12\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.30534697 0.37717929 0.31747374]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3110, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.21\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -10.7032\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3590):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -10.703225092710781)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -10.703225092710781}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.880, trend=+0.043\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3600):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09  4.58831958e-02 -5.23873616e-02  1.18872305e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.12\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.33519078 0.30713039 0.35767883]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3440, Std: 6.5834\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.21\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -11.7273\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3600):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -11.727256963202958)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -11.727256963202958}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.884, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000042445708\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 300):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=20.099413\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.906\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00004245\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00004245\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.537, max=1.000, group_baseline=0.912\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.332088, entropy=-4.805220\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00142592\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 500000005.356018\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3610):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.0328487   0.11772858  0.18558894  0.12678961  0.0694222 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: 0.06942220351795773\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.12\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.1783352  0.20397099 0.21669878 0.20562622 0.19536882]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3676, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.21\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -15.8198\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3610):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, -15.819814940004992)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -15.819814940004992}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.884, trend=+0.444\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000033607368\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 300: reward=0.933, intervention_rate=1.000, scm=fork_6var\n",
      "INFO:causal_bayes_opt.training.modular_trainer:Saved checkpoint: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/checkpoints/grpo_training/enriched_grpo_episode_300/checkpoint.pkl\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3620):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 0.08646747 -0.0141182  -0.07364255 -0.04417975  0.15700807]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: 0.1570080669093926\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.12\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.21117514 0.19300802 0.18300212 0.18788818 0.22492655]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3441, Std: 6.3647\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.21\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -10.4713\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3620):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -10.471297077678406)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -10.471297077678406}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.928, trend=+0.128\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000025539835\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3630):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [0.15947065 0.09676324 0.07001035 0.03599778 0.05544163]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: 0.055441633844556325\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.12\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.21393246 0.20223539 0.19744178 0.19151107 0.1948793 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X5 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3861, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.21\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 4.4740\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3630):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 4.473996247373471)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X5': 4.473996247373471}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.44739962473734707}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.947400\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.947400\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.947) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.936, trend=-0.053\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000017428449\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3640):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.00158254  0.26869157 -0.00291479  0.09553367  0.0850451 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: 0.08504510091432696\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.11\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.18361819 0.23412245 0.1833984  0.20037074 0.19849021]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3950, Std: 5.9322\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.20\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 12.5456\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3640):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 12.545564454576898)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 12.545564454576898}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.936, trend=+0.433\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000012802434\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3650):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 0.03953498 -0.02331008  0.01192789 -0.00473734  0.04593488]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: 0.04593488247580284\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.11\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.20462404 0.19335449 0.19959475 0.19661881 0.20580791]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3858, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.20\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -7.8553\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3650):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -7.855253564374983)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -7.855253564374983}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.979, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3660):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 0.09262732  0.16762823 -0.01170919 -0.07974562 -0.01265478]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.012654779339704585\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.11\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.21071553 0.22545385 0.19180116 0.1803917  0.19163775]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3300, Std: 6.8011\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.20\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.8424\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3660):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 0.8423893743210666)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 0.8423893743210666}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.08423893743210667}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.584239\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.584239\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.938, trend=-0.416\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000006113446\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 305):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=12.046386\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.915\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00000611\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00000611\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.584, max=1.000, group_baseline=0.920\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.321048, entropy=-5.028322\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00088033\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 250000005.029292\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3670):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 7.35682617e-02 -1.00000000e+09  4.00888939e-02  6.03838867e-02\n",
      " -1.23347795e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.11\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.26348271 0.         0.25562953 0.26036169 0.22052608]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3826, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.20\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 11.0936\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3670):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, 11.093605430334444)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 11.093605430334444}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.938, trend=+0.154\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000013376457\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3680):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-5.88781528e-02 -1.00000000e+09  2.45481117e-01  3.32856876e-02\n",
      "  1.19131222e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.10\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.21835245 0.         0.28770029 0.23737209 0.25657517]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3808, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.20\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 10.9893\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3680):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 10.989308491466854)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 10.989308491466854}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.953, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000018277266\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3690):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 7.85869998e-02 -1.00000000e+09  5.79200923e-02  6.74905627e-02\n",
      " -1.08065988e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.10\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.26209759 0.         0.25722182 0.25946832 0.22121227]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3478, Std: 6.6935\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.20\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 10.1043\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3690):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 10.104346867082278)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 10.104346867082278}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.953, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000027350667\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3700):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 5.38020700e-02 -1.00000000e+09  1.87103939e-01 -2.73131377e-02\n",
      "  9.69498803e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.10\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.24402255 0.         0.27553176 0.22663982 0.25380587]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3907, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.20\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 10.9188\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3700):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 10.91879284344154)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 10.91879284344154}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.953, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000046751368\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3710):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.50024961e-01 -1.00000000e+09 -5.50169088e-03 -1.51078334e-01\n",
      "  1.21042755e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.09\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.277703   0.         0.24092441 0.21092515 0.27044745]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3867, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.20\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 13.9427\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3710):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 13.94266032177533)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 13.94266032177533}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.953, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3720):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 5.37898207e-02 -1.00000000e+09 -9.79474050e-02  7.88965505e-03\n",
      "  5.87812549e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.09\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.26081889 0.         0.22706103 0.25010925 0.26201082]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3891, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.20\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -8.1202\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3720):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, -8.12020521910065)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -8.12020521910065}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.953, trend=+0.053\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000056949346\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 310):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=13.942660\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.961\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00005695\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00005695\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.684, max=1.000, group_baseline=0.959\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.281483, entropy=-5.028319\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00020974\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 234375005.512636\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3730):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [0.05645234 0.02083603 0.04966542 0.09950251 0.09975917]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: 0.09975916558818088\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.09\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.19831871 0.19195359 0.19708972 0.20629474 0.20634324]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3656, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.20\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -13.8429\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3730):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -13.842912670039388)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -13.842912670039388}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.958, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000054692064\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 310: reward=0.871, intervention_rate=1.000, scm=collider_6var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3740):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.0116381   0.21989907  0.08506967  0.08149981  0.05059155]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: 0.050591545130189215\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.09\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.18255054 0.22580402 0.19950556 0.19885255 0.19328734]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4126, Std: 7.0333\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.20\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.4231\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3740):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, 1.4230890790173092)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 1.4230890790173092}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.14230890790173092}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.642309\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.642309\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.923, trend=-0.358\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000049753286\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3750):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.16766744  0.00968765  0.15593115  0.12676947  0.01269213]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: 0.0126921297568801\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.09\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.16620433 0.19569117 0.2239019  0.21796927 0.19623334]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X5 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2903, Std: 6.0655\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.20\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.3603\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3750):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -1.360306555492401)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X5': -1.360306555492401}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.1360306555492401}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.636031\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.636031\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.886, trend=+0.052\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000039698895\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3760):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 0.23243276  0.00970251  0.0706659  -0.01013477  0.05819896]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: 0.05819895744543228\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.08\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.23115552 0.18818618 0.19908315 0.18477058 0.19680457]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X5 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3778, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.19\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 15.3207\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3760):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 15.320670603687208)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X5': 15.320670603687208}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.928, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000040663354\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3770):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [0.06855049 0.0318966  0.07392085 0.06883069 0.16971118]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: 0.1697111787589151\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.08\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.19723617 0.190655   0.19821931 0.19728735 0.21660217]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3873, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.19\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.7196\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3770):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 0.7196121793338606)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': 0.7196121793338606}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.07196121793338606}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.571961\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.571961\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.885, trend=-0.428\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3780):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 0.19598141  0.15216665  0.14746897  0.02177153 -0.20928355]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.2092835501457185\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.08\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.22449184 0.21556728 0.21463173 0.19105199 0.15425717]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3849, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.19\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -15.4021\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3780):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -15.40209299279994)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -15.40209299279994}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.885, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000042961696\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 315):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=15.402093\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.861\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00004296\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00004296\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.572, max=1.000, group_baseline=0.863\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.371677, entropy=-5.028362\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00017835\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 171875005.288728\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3790):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.46732728e-01  1.48186783e-01 -1.00000000e+09  4.17900952e-02\n",
      "  4.17862609e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.08\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.26207608 0.2624301  0.         0.23774734 0.23774649]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3902, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.19\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -5.7334\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3790):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -5.733424674843095)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -5.733424674843095}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.885, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000053522772\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3800):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 9.96807192e-02  1.68679143e-01 -1.00000000e+09  2.84298113e-02\n",
      "  5.51419680e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.07\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.25242651 0.26917223 0.         0.23622673 0.24217453]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3937, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.19\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 11.0697\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3800):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 11.06966734270479)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 11.06966734270479}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.885, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000062407660\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3810):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 6.83196323e-02 -2.31444836e-02 -1.00000000e+09 -8.83391472e-02\n",
      "  6.83366815e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.07\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.26440079 0.24276368 0.         0.22843054 0.26440499]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3856, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.19\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 9.4376\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3810):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, 9.437592452563356)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 9.437592452563356}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.885, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000057489368\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3820):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 9.07710857e-02  6.35110985e-02 -1.00000000e+09  6.61352875e-02\n",
      "  8.30725672e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.07\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.25349626 0.24710994 0.         0.24771765 0.25167615]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3542, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.19\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 6.2047\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3820):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 6.204672761705017)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': 6.204672761705017}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.885, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000053137399\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3830):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.00632200e-01  1.12880651e-01 -1.00000000e+09  3.11925289e-02\n",
      "  9.44699907e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.07\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.25363338 0.25656604 0.         0.23762993 0.25217065]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3754, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.19\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -17.3529\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3830):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -17.35288583969382)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -17.35288583969382}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.885, trend=+0.358\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3840):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 9.33046471e-02  1.85999565e-01 -1.00000000e+09 -6.97946819e-03\n",
      "  9.00385116e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.07\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.25012463 0.27286078 0.         0.22765556 0.24935903]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3709, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.19\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -6.7188\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3840):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -6.718825944570221)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -6.718825944570221}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.921, trend=+0.364\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000067560710\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 320):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=24.779083\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.946\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00006756\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00006756\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.516, max=1.000, group_baseline=0.949\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.256061, entropy=-5.028334\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00065140\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 500000005.964609\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3850):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-7.55276485e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.06\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3764, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.19\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 4.0489\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3850):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 4.048897456480555)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 4.048897456480555}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.4048897456480555}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.904890\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.904890\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.905) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.948, trend=-0.095\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000046274252\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 320: reward=0.913, intervention_rate=1.000, scm=fork_3var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3860):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-5.0904032e-02 -1.0000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.06\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3707, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.19\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -5.1841\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3860):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -5.184089692568616)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -5.184089692568616}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.948, trend=+0.428\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000027187689\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3870):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 8.95558385e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.06\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3865, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.19\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 16.3955\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3870):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 16.39551160469679)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 16.39551160469679}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.990, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000000956133\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3880):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.61977209e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.05\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3772, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.18\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.2499\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3880):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 3.249921023644078)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 3.249921023644078}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3249921023644078}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.824992\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.824992\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.825) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.973, trend=-0.175\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000015355067\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3890):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.67245792e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.05\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3493, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.18\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 15.3407\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3890):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 15.340669985183826)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 15.340669985183826}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.973, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3900):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-6.92278705e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.05\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4002, Std: 6.1213\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.18\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -5.0960\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3900):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -5.095953592829167)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -5.095953592829167}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.973, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000042642232\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 325):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=15.340670\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.855\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00004264\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00004264\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.541, max=1.000, group_baseline=0.864\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.350546, entropy=-4.112072\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00206154\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 4.078418\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3910):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.01465841  0.17074817]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: 0.1707481679203906\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.05\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.45588011 0.54411989]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3840, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.18\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -11.0450\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3910):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -11.044961110552393)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -11.044961110552393}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.973, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000021738620\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3920):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [0.11598263 0.10201061]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: 0.10201061250110209\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.04\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.50334279 0.49665721]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4167, Std: 6.7895\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.18\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -10.0002\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3920):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -10.000173027822665)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -10.000173027822665}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.973, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000000930664\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3930):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [0.08300009 0.09420284]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: 0.09420283653586763\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.04\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.49731221 0.50268779]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3894, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.18\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -4.3831\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3930):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -4.383072040828936)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -4.383072040828936}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.43830720408289364}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.938307\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.938307\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.938) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.967, trend=-0.062\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000023840257\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3940):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [0.12775918 0.06756501]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: 0.06756501444021999\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.04\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.51447876 0.48552124]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3955, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.18\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 16.0634\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3940):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 16.063421174615378)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 16.063421174615378}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.967, trend=+0.095\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000006627836\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3950):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [0.02244249 0.13866168]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: 0.13866168257797118\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.04\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.47198779 0.52801221]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3370, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.18\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -14.9920\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3950):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -14.99197776941364)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -14.99197776941364}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.976, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3960):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [0.07765349 0.05340713]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: 0.05340712843364682\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.04\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.50584994 0.49415006]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3726, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.18\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -3.9787\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3960):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -3.978707825406694)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -3.978707825406694}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.39787078254066943}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.897871\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.897871\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.898) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.966, trend=-0.102\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000017550996\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 330):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=16.035248\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.906\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00001755\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00001755\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.508, max=1.000, group_baseline=0.904\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.312270, entropy=-4.112061\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00310818\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 4.605713\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3970):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.22338607e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.03\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3985, Std: 6.3057\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.18\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.2933\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3970):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 3.293280153024299)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 3.293280153024299}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.32932801530242994}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.829328\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.829328\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.829) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.949, trend=+0.004\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000012266075\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 330: reward=0.885, intervention_rate=1.000, scm=collider_3var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3980):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.13855458e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.03\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3769, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.18\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 9.3801\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3980):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 9.38011202789466)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 9.38011202789466}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.967, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000000486866\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 3990):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.57348795e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.03\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3398, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.18\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -3.2354\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 3990):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -3.2354233440107345)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -3.2354233440107345}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3235423344010735}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.823542\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.823542\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.824) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.949, trend=-0.176\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000003105372\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4000):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.18711293e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.02\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3419, Std: 7.0617\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.17\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -3.6514\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4000):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -3.651357139993788)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -3.651357139993788}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.36513571399937883}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.865136\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.865136\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.865) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.935, trend=-0.135\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000006993578\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4010):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-5.15147063e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.02\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3551, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.17\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.4926\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4010):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 2.4925852877444497)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 2.4925852877444497}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.249258528774445}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.749259\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.749259\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.910, trend=-0.251\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4020):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.1830554e-01 -1.0000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.02\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3557, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.17\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.2993\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4020):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 2.2993243679830764)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 2.2993243679830764}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.22993243679830766}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.729932\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.729932\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.883, trend=-0.208\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000007946189\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 335):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=13.186292\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.808\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00000795\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00000795\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.583, max=1.000, group_baseline=0.806\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.370309, entropy=-4.112064\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00033709\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 4.004116\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4030):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 9.45494471e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.02\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3319, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.17\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -7.2187\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4030):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -7.218721194037342)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -7.218721194037342}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.890, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000030282353\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4040):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.32580451e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.02\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3333, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.17\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -7.6836\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4040):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -7.683571231363649)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -7.683571231363649}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.890, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000044618893\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4050):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 4.1054018e-02 -1.0000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.01\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3413, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.17\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.0222\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4050):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 3.022169266218434)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 3.022169266218434}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3022169266218434}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.802217\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.802217\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.802) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.870, trend=-0.096\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000068673625\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4060):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.37799127e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.01\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3229, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.17\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.0337\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4060):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 1.0337280467687708)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 1.0337280467687708}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.1033728046768771}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.603373\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.603373\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.840, trend=-0.226\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000086564638\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4070):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.86277359e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.01\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3067, Std: 6.9340\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.17\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -7.2591\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4070):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -7.259123306848613)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -7.259123306848613}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.857, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4080):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 3.43997022e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.01\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3320, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.17\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.7435\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4080):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -0.7435458310822285)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -0.7435458310822285}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.07435458310822285}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.574355\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.574355\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.815, trend=-0.249\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000144354750\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 340):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=13.142675\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.867\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00014435\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00014435\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.574, max=1.000, group_baseline=0.875\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.363363, entropy=-4.112036\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00043624\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 4.130843\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4090):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [0.02705709 0.12167719 0.0744575 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: 0.07445750130438215\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.00\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.31774428 0.34914902 0.3331067 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2917, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.17\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 17.7049\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4090):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 17.704921845218518)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 17.704921845218518}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.832, trend=+0.135\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000151046616\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 340: reward=0.906, intervention_rate=1.000, scm=fork_4var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4100):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.10027573 -0.05318859  0.01367512]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: 0.013675117135506459\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.00\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.31558308 0.33078321 0.35363371]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3331, Std: 6.2784\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.17\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -15.8270\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4100):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -15.827036489843842)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -15.827036489843842}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.846, trend=+0.251\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000148856012\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4110):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [0.09048293 0.15026877 0.0104169 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: 0.010416901377898129\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.00\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33504832 0.35573198 0.3092197 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3067, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.17\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 15.6794\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4110):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 15.679407911954424)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 15.679407911954424}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.871, trend=+0.270\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000143651693\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4120):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.22611523 -0.1560407   0.09119366]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: 0.09119365807796916\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.00\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.28997915 0.31113516 0.39888569]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2976, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.17\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -4.8896\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4120):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -4.889587954916783)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -4.889587954916783}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.4889587954916783}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.988959\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.988959\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.989) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.897, trend=-0.011\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000160992832\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4130):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.09283392  0.01151934 -0.15170143]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.15170142771297543\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.99\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.32751453 0.3638375  0.30864797]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2875, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.16\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -4.8954\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4130):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -4.895353213083847)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -4.895353213083847}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.4895353213083847}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.989535\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.989535\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.990) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.896, trend=-0.010\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4140):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 0.0148336  -0.09093257 -0.02182474]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.02182474392621243\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.99\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.34933115 0.31400891 0.33665994]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2962, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.16\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -5.2988\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4140):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -5.29883503090119)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -5.29883503090119}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.896, trend=+0.198\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000166130407\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 345):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=8.796862\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.932\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00016613\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00016613\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.700, max=1.000, group_baseline=0.929\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.336562, entropy=-4.517508\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00299647\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 328125004.326140\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4150):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-5.91899802e-03 -1.00000000e+09 -9.70949864e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.99\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.52302522 0.         0.47697478]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2664, Std: 7.1167\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.16\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -3.9616\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4150):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -3.961614260645803)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -3.961614260645803}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3961614260645803}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.896161\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.896161\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.896) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.905, trend=+0.293\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000066425349\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4160):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 2.45763224e-02 -1.00000000e+09 -1.00521197e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.99\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.53166545 0.         0.46833455]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2907, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.16\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -5.4809\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4160):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -5.480861912418821)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -5.480861912418821}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.945, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000041766161\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4170):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.87137348e-01 -1.00000000e+09 -6.57884717e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.98\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.46918972 0.         0.53081028]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2794, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.16\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -6.6360\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4170):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -6.636033133261034)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -6.636033133261034}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.945, trend=+0.426\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000013115240\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4180):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 4.98478294e-03 -1.00000000e+09 -1.06698961e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.98\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.52844638 0.         0.47155362]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2770, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.16\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -5.3173\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4180):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -5.317302683345661)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -5.317302683345661}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.987, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000067732384\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4190):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-8.52662766e-02 -1.00000000e+09 -2.49221081e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.98\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.54183248 0.         0.45816752]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2505, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.16\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -4.2208\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4190):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -4.220848996297992)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -4.220848996297992}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.4220848996297992}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.922085\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.922085\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.922) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.980, trend=-0.078\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4200):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.18982328e-02 -1.00000000e+09  4.83081112e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.98\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.49068946 0.         0.50931054]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2688, Std: 6.9276\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.16\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.7442\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4200):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -0.7442020622660621)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -0.7442020622660621}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.07442020622660621}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.574420\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.574420\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.937, trend=-0.426\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000088657937\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 350):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=10.759691\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.816\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00008866\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00008866\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.574, max=1.000, group_baseline=0.814\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.360332, entropy=-4.517291\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00214404\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 421875004.269409\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4210):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.06371237 -0.2900346  -0.19734543]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.19734543165625576\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.97\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.37528474 0.2975156  0.32719966]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2645, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.16\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.5185\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4210):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 1.5185408581461448)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 1.5185408581461448}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.1518540858146145}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.651854\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.651854\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.902, trend=-0.337\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000058930357\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 350: reward=0.863, intervention_rate=1.000, scm=collider_4var\n",
      "INFO:causal_bayes_opt.training.modular_trainer:Saved checkpoint: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/checkpoints/grpo_training/enriched_grpo_episode_350/checkpoint.pkl\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4220):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 0.08291745 -0.23945554  0.13710009]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: 0.13710009114816837\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.97\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.36036048 0.25861386 0.38102565]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X3 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3171, Std: 6.8382\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.16\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -3.2404\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4220):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -3.2403887677284056)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -3.2403887677284056}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3240388767728406}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.824039\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.824039\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.824) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.886, trend=-0.165\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000053638576\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4230):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.01607639 -0.29721845 -0.30113686]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.3011368644949634\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.97\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.40109236 0.30005944 0.2988482 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X3 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2526, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.16\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.7777\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4230):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 2.777690761433408)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': 2.777690761433408}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.27776907614334084}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.777769\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.777769\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.865, trend=-0.222\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000062364141\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4240):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.06324194 -0.12883454 -0.17004305]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.17004304760375802\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.97\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.35339997 0.33019606 0.31640396]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2474, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.16\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 18.3070\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4240):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 18.306998262017405)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 18.306998262017405}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.865, trend=+0.104\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000026081025\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4250):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.23155757 -0.25679381 -0.07655648]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.07655647782304825\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.96\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.31758262 0.30936727 0.37305011]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2376, Std: 7.3846\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.15\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.2377\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4250):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 3.237692441630314)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 3.237692441630314}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.32376924416303143}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.823769\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.823769\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.824) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.857, trend=-0.176\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4260):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.17098952  0.12348667 -0.11780891]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.11780891295706836\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.96\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.29286618 0.39763757 0.30949625]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2528, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.15\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 7.6397\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4260):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 7.6397044905705895)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 7.6397044905705895}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.857, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000020986166\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 355):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=20.261303\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.905\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00002099\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00002099\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.695, max=1.000, group_baseline=0.898\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.372256, entropy=-4.517453\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00081593\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 406250004.930155\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4270):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.1237129  -0.3137304  -0.19124024]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.19124024352606023\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.96\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.36330741 0.29806345 0.33862913]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2991, Std: 6.7372\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.15\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.7985\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4270):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 3.798493743880877)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 3.798493743880877}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.37984937438808775}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.879849\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.879849\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.880) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.845, trend=-0.120\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000007548239\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4280):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.11877716 -0.28768561 -0.35210511]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.35210511161895175\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.96\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.38141055 0.31970039 0.29888906]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2247, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.15\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -6.6046\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4280):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -6.604632164341598)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -6.604632164341598}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.845, trend=+0.078\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000003610063\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4290):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.06262768 -0.24214701 -0.16550487]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.16550487147316464\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.95\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.36680159 0.30388997 0.32930844]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2477, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.15\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 14.3974\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4290):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 14.397446162815557)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 14.397446162815557}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.853, trend=+0.426\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000017703176\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4300):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.0626031  -0.11733395  0.00821779]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: 0.008217793142437872\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.95\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33097435 0.3124675  0.35655815]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2369, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.15\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.5433\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4300):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -1.5433398714067137)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -1.5433398714067137}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.15433398714067137}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.654334\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.654334\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.861, trend=+0.002\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000014932759\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4310):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.15841372 -0.24260605 -0.16928922]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.1692892215481535\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.95\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.34439577 0.31513581 0.34046842]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2166, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.15\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.6126\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4310):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -0.6125704108190401)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -0.6125704108190401}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.06125704108190401}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.561257\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.561257\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.852, trend=-0.263\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4320):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.24221844 -0.1715833  -0.09623739]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.0962373855957573\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.95\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.30828357 0.33212475 0.35959168]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2368, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.15\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.1761\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4320):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 1.1761025996764496)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 1.1761025996764496}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.11761025996764496}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.617610\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.617610\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.831, trend=-0.160\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000001689346\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 360):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=13.842732\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.815\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00000169\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00000169\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.503, max=1.000, group_baseline=0.805\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.391870, entropy=-4.517452\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00022216\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 406250004.405569\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4330):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -2.21641189e-01 -1.51593373e-01 -1.91275818e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.95\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.32158909 0.34632401 0.33208689]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2315, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.15\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 16.6057\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4330):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 16.605733097213545)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 16.605733097213545}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.854, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000005451965\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 360: reward=0.815, intervention_rate=1.000, scm=fork_5var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4340):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -2.16915552e-01 -2.44439758e-01 -2.39232243e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.94\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.33923461 0.32946987 0.33129552]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2113, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.15\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 10.0403\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4340):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 10.040294265324201)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 10.040294265324201}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.854, trend=+0.176\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000028099413\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4350):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.59124748e-01 -1.34781164e-01 -1.72207114e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.94\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.33195879 0.34067309 0.32736813]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2397, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.15\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 6.6801\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4350):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 6.680118257133271)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 6.680118257133271}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.871, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000015174500\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4360):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -2.39403760e-01 -2.88974703e-01  3.88142706e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.94\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.30354888 0.28789961 0.40855151]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2080, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.15\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.5985\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4360):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 1.5985359959600678)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 1.5985359959600678}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.15985359959600678}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.659854\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.659854\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.837, trend=-0.220\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000042412387\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4370):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -3.58639151e-01 -8.43222645e-02  8.82415127e-03]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.93\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.26151563 0.35083745 0.38764692]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2412, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.14\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 9.1808\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4370):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 9.180832460515628)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 9.180832460515628}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.849, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4380):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -2.78799684e-01 -1.43021896e-01 -2.54301719e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.93\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.31415608 0.36333511 0.32250881]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2349, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.14\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 11.8578\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4380):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 11.857768281021603)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 11.857768281021603}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.849, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000041717494\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 365):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=11.857768\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.836\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00004172\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00004172\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.503, max=1.000, group_baseline=0.836\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.342188, entropy=-4.805208\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00120696\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 578125004.616564\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4390):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.97836760e-01 -1.00000000e+09 -1.57148527e-01 -1.65312567e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.93\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.3246485  0.         0.33915683 0.33619467]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.1693, Std: 5.7757\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.14\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -7.4551\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4390):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -7.45512178393412)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -7.45512178393412}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.849, trend=+0.346\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000023909215\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4400):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-3.27789783e-01 -1.00000000e+09 -1.22977556e-01 -1.64348783e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.93\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.29072514 0.         0.36254344 0.34673142]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.1910, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.14\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -8.5416\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4400):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -8.541645100231017)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -8.541645100231017}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.884, trend=+0.439\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000016809662\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4410):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-9.94279558e-02 -1.00000000e+09 -2.39132883e-01 -2.00047381e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.92\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33904406 0.         0.29150752 0.36944842]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2082, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.14\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -3.4168\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4410):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -3.4167545647131474)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -3.4167545647131474}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.34167545647131475}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.841675\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.841675\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.842) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.912, trend=+0.224\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000009083631\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4420):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.16374235e-01 -1.00000000e+09 -6.09901151e-02 -1.47553666e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.92\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33017871 0.         0.35062306 0.31919823]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2420, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.14\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 7.5350\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4420):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 7.53497151870704)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': 7.53497151870704}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.950, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000022268921\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4430):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.41018360e-01 -1.00000000e+09  2.18788214e-03 -1.43104621e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.92\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.29278985 0.         0.38150087 0.32570929]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2252, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.14\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 4.7625\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4430):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 4.762523071270232)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': 4.762523071270232}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.47625230712702327}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.976252\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.976252\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.976) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.948, trend=-0.024\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4440):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 9.49811310e-02 -1.00000000e+09  1.58621849e-02 -1.71989933e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.92\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.37518102 0.         0.34423035 0.28058863]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2398, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.14\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.2141\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4440):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 2.2141261490759025)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 2.2141261490759025}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.22141261490759026}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.721413\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.721413\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.920, trend=-0.279\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000009423620\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 370):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=15.710820\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.828\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00000942\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00000942\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.529, max=1.000, group_baseline=0.834\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.360508, entropy=-4.804990\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00291905\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 93750004.658197\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4450):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09  3.90400383e-02  3.36792032e-02  2.11625175e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.92\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.31235443 0.31053176 0.37711381]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2075, Std: 6.9598\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.14\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -2.4756\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4450):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -2.4755793694554216)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -2.4755793694554216}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.24755793694554218}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.747558\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.747558\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.895, trend=+0.088\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000095466936\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 370: reward=0.886, intervention_rate=1.000, scm=collider_5var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4460):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.55750209e-01 -9.32766767e-02 -1.76324720e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.91\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.3280265  0.35125575 0.32071775]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2327, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.14\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -8.6391\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4460):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -8.639056426484778)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -8.639056426484778}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.929, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000089130233\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4470):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09  5.40650460e-02 -3.11595286e-01 -9.14394661e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.91\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.39660492 0.26538592 0.33800916]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2258, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.14\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -7.2103\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4470):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -7.210301430782556)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -7.210301430782556}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.929, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000097116275\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4480):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -2.48959465e-01 -1.02534807e-01 -4.41763671e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.91\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.29168271 0.34277173 0.36554556]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2110, Std: 6.7260\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.14\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -2.8202\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4480):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -2.820203822339484)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -2.820203822339484}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.2820203822339484}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.782020\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.782020\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.907, trend=-0.218\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000118173782\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4490):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -3.25681475e-02 -7.90975559e-02 -3.58430424e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.90\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.37774612 0.35880126 0.26345262]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2000, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.13\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -11.4393\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4490):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -11.439324254324537)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -11.439324254324537}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.907, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4500):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.69486871e-01 -2.34915817e-01 -1.43008146e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.90\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.33784742 0.31426639 0.34788619]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2338, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.13\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 8.5455\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4500):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 8.545534595238319)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 8.545534595238319}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.907, trend=+0.158\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000098009398\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 375):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=19.827024\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.948\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00009801\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00009801\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.604, max=1.000, group_baseline=0.952\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.276978, entropy=-4.805204\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00131602\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 406250005.289590\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4510):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -2.85793646e-01 -1.76715950e-01 -8.74194396e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.90\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.29631223 0.33442992 0.36925785]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2950, Std: 6.9608\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.13\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -2.5615\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4510):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -2.5614990755009286)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -2.5614990755009286}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.25614990755009287}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.756150\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.756150\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.898, trend=-0.244\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000035142754\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4520):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -3.66391816e-02 -3.03733343e-01 -5.07436683e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.90\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.36666916 0.27237303 0.36095781]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2191, Std: 5.9980\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.13\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 12.5826\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4520):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 12.58255752889406)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 12.58255752889406}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.898, trend=+0.024\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000000713887\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4530):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.89683707e-01 -3.21823837e-01 -2.07866375e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.90\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.35177675 0.30351707 0.34470619]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2471, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.13\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.5296\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4530):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 1.52964893819042)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 1.52964893819042}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.152964893819042}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.652965\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.652965\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.866, trend=-0.068\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000021055375\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4540):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.83920320e-01 -1.98088292e-01 -2.52716733e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.89\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.34363415 0.33822268 0.31814317]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2548, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.13\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 15.1400\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4540):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 15.139984953351007)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 15.139984953351007}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.894, trend=+0.252\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000055587827\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4550):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09  1.15476124e-02 -1.69744749e-01 -3.50212642e-03]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.89\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.35728733 0.29141855 0.35129412]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2365, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.13\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 6.2679\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4550):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 6.267901980319514)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 6.267901980319514}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.919, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4560):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -3.68088625e-02 -9.29721405e-02 -3.89095422e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.89\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.38287198 0.3594485  0.25767952]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2587, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.13\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.3731\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4560):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -0.3730645708578725)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -0.3730645708578725}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.03730645708578725}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.537306\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.537306\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.873, trend=-0.463\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000077560599\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 380):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=11.871319\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.839\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00007756\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00007756\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.537, max=1.000, group_baseline=0.849\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.378465, entropy=-4.805188\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00044382\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 500000004.740616\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4570):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.20590826 -0.11435606 -0.14341351 -0.10412226 -0.12293303]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.12293302590164143\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.89\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.1851331  0.20526941 0.19865183 0.20765219 0.20329347]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2360, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.13\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.1740\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4570):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 2.1740478503001546)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 2.1740478503001546}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.21740478503001548}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.717405\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.717405\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.845, trend=-0.065\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000066609638\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 380: reward=0.875, intervention_rate=1.000, scm=fork_6var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4580):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.03152469 -0.03832373 -0.14237417 -0.36542052 -0.08216657]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.08216656778841154\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.88\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.22201819 0.22031675 0.19584706 0.15216401 0.20965398]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2317, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.13\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -4.7284\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4580):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -4.728396068266244)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -4.728396068266244}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.47283960682662446}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.972840\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.972840\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.973) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.864, trend=-0.027\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000056984533\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4590):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.16116551 -0.01384648 -0.11732687 -0.0858399  -0.13074849]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.13074848594092833\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.88\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.18665487 0.22063416 0.19617936 0.20331878 0.19321284]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2648, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.13\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.4539\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4590):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 3.4538893314030794)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': 3.4538893314030794}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.34538893314030794}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.845389\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.845389\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.845) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.848, trend=-0.155\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000062811444\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4600):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 0.05928784 -0.09819791 -0.06682869 -0.04710128 -0.09924173]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.09924173300293965\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.88\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.22610929 0.1889789  0.19585337 0.20030409 0.18875435]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X5 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3169, Std: 7.0398\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.13\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.1459\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4600):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 3.14591509609663)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X5': 3.14591509609663}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.314591509609663}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.814592\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.814592\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.815) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.830, trend=+0.058\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000059580802\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4610):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.19378683 -0.1526616  -0.09135981  0.046526   -0.07990569]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.07990569299234039\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.88\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.17770295 0.18625442 0.19977121 0.23386793 0.20240349]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2663, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.12\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.6870\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4610):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -0.6870360718647035)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -0.6870360718647035}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.06870360718647035}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.568704\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.568704\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.811, trend=-0.431\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4620):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.13510706  0.08854049 -0.17274083 -0.1172781  -0.15957872]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.15957871501955612\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.88\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.19076182 0.24631787 0.18273109 0.19468864 0.18550058]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X5 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2733, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.12\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.4632\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4620):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -1.4631681388822158)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X5': -1.4631681388822158}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.14631681388822157}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.646317\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.646317\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.776, trend=-0.007\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000054895325\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 385):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=8.249714\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.781\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00005490\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00005490\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.569, max=1.000, group_baseline=0.778\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.362975, entropy=-5.028338\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00294584\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 328125004.705300\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4630):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 8.64568682e-03 -1.00000000e+09 -1.06399320e-01 -1.45309663e-01\n",
      " -2.20740122e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.87\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.27174195 0.         0.23815725 0.22776464 0.26233616]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2561, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.12\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 8.0861\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4630):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 8.086060864117892)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 8.086060864117892}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.810, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000071413427\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4640):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.02664660e-01 -1.00000000e+09 -2.57073398e-01 -1.36885960e-01\n",
      " -8.08053373e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.87\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.23989732 0.         0.22534    0.25875805 0.27600464]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2460, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.12\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.9388\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4640):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 0.9387667119185764)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 0.9387667119185764}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.09387667119185765}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.593877\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.593877\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.770, trend=-0.406\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000080503784\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4650):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.25902579e-01 -1.00000000e+09 -1.23922169e-01 -1.76868920e-01\n",
      " -1.94891561e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.87\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.25849193 0.         0.2590836  0.24372151 0.23870296]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2411, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.12\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -8.4027\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4650):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, -8.402725015466878)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -8.402725015466878}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.770, trend=+0.463\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000081909684\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4660):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.54830308e-01 -1.00000000e+09 -2.35056939e-02 -1.37733791e-01\n",
      " -2.06774119e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.86\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.24237085 0.         0.2821931  0.24721863 0.22821742]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2630, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.12\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.0720\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4660):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, 2.0719594121939533)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 2.0719594121939533}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.20719594121939533}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.707196\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.707196\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.787, trend=-0.010\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000072030994\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4670):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.11723611e-01 -1.00000000e+09 -1.26588089e-01 -7.02713954e-02\n",
      " -4.66183397e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.86\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.24325923 0.         0.23909249 0.25526653 0.26238176]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2846, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.12\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 7.0260\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4670):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, 7.025957378892919)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 7.025957378892919}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.815, trend=+0.027\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4680):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.21181675e-02 -1.00000000e+09 -4.41595705e-02 -1.92612895e-02\n",
      " -1.05486530e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.86\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.259583   0.         0.25009336 0.25743672 0.23288692]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2748, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.12\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 7.0162\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4680):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 7.0161787143732175)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 7.0161787143732175}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.818, trend=+0.155\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000073324152\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 390):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=17.497971\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.908\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00007332\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00007332\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.532, max=1.000, group_baseline=0.911\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.318189, entropy=-5.028357\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00039570\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 171875005.405378\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4690):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.12532213 -0.17349748 -0.05377526 -0.11814301 -0.10564497]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.10564497153107265\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.86\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.19747196 0.18668268 0.21465686 0.19913231 0.20205618]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X5 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2828, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.12\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -4.7426\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4690):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -4.74259656827102)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X5': -4.74259656827102}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.474259656827102}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.974260\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.974260\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.974) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.830, trend=+0.160\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000069631552\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 390: reward=0.911, intervention_rate=1.000, scm=collider_6var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4700):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.13159963 -0.05243459 -0.05679851 -0.08193793 -0.0272957 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.02729570165334572\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.85\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.18593492 0.20398418 0.20294508 0.19706135 0.21007448]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2613, Std: 6.8842\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.12\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.8222\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4700):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, 0.8222254202748697)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 0.8222254202748697}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.08222254202748697}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.582223\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.582223\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.807, trend=+0.014\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000047209392\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4710):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.15202441 -0.14296259 -0.11773786 -0.18478301 -0.13461504]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.1346150444819952\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.85\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.1986216  0.2007465  0.2067819  0.19112597 0.20272402]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2681, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.12\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -3.1228\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4710):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -3.1228228798610953)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -3.1228228798610953}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3122822879861096}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.812282\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.812282\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.812) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.832, trend=+0.166\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000036655304\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4720):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.05044495 -0.24194542 -0.10490886 -0.0069659  -0.12507603]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.12507603479496007\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.85\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.21257547 0.16963337 0.19936128 0.22375044 0.19467945]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.1929, Std: 5.4161\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.12\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -8.6799\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4720):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -8.679918582177846)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -8.679918582177846}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.867, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000028486379\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4730):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.03413298 -0.40384452 -0.2235069  -0.05372046 -0.1576808 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.15768080283403452\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.85\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.23329458 0.15067682 0.18648991 0.2279533  0.20158539]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2543, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.12\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.9833\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4730):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -0.9832587021737678)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -0.9832587021737678}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.09832587021737678}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.598326\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.598326\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.827, trend=+0.004\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4740):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.07950675 -0.04283291 -0.08658226 -0.08734613  0.09292233]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: 0.09292232716816277\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.85\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.19037024 0.19880724 0.18878417 0.18861373 0.23342463]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X5 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2825, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.12\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 4.6341\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4740):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 4.634087010132375)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X5': 4.634087010132375}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.4634087010132375}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.963409\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.963409\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.963) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.864, trend=-0.037\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000019631188\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 395):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=11.102233\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.841\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00001963\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00001963\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.548, max=1.000, group_baseline=0.835\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.376161, entropy=-5.028344\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00021754\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 250000004.859753\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4750):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.08023005e-01 -7.85840749e-02 -1.00000000e+09 -1.08229529e-01\n",
      " -3.72429261e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.84\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.22141785 0.25817522 0.         0.2492515  0.27115543]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3058, Std: 5.0846\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.11\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 4.9636\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4750):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, 4.963612748992182)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 4.963612748992182}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.4963612748992183}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.996361\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.996361\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.996) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.863, trend=+0.289\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000010810351\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4760):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-6.95862461e-02 -9.80936028e-02 -1.00000000e+09  3.18677330e-02\n",
      "  1.00552765e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.84\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.23150348 0.22377728 0.         0.26122861 0.28349062]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X5 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2841, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.11\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -6.6388\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4760):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -6.638838068481813)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X5': -6.638838068481813}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.893, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000002550812\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4770):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-3.09568114e-02 -1.01835523e-01 -1.00000000e+09 -3.05335721e-01\n",
      " -1.98949930e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.84\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.28923431 0.26574749 0.         0.2083858  0.2366324 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X5 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3371, Std: 6.9596\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.11\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.2530\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4770):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -0.25296526125272195)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X5': -0.25296526125272195}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.025296526125272195}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.525297\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.525297\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.845, trend=-0.475\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000010904635\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4780):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.83482487e-01 -1.28787063e-01 -1.00000000e+09 -1.03744964e-01\n",
      "  6.37344923e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.83\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.22157431 0.23659298 0.         0.24380491 0.29802781]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2632, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.11\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -10.6859\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4780):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, -10.685854969517518)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -10.685854969517518}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.845, trend=+0.026\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000000390853\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4790):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.31919949e-01 -6.74788267e-02 -1.00000000e+09 -4.63542756e-02\n",
      " -4.41840185e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.83\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.23253541 0.25128403 0.         0.25775328 0.25842727]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X5 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2921, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.11\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 20.2764\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4790):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 20.27635400416275)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X5': 20.27635400416275}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.848, trend=+0.418\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4800):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-3.10360206e-02 -3.40894773e-02 -1.00000000e+09  4.32869824e-03\n",
      " -1.15559763e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.83\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.2536076  0.2526775  0.         0.26463254 0.22908236]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3091, Std: 6.1292\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.11\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 7.7427\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4800):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 7.742674210754693)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 7.742674210754693}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.890, trend=+0.188\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000001663602\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 400):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=20.276354\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.936\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00000166\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00000166\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.691, max=1.000, group_baseline=0.936\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.328012, entropy=-5.028352\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00086606\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 156250005.394856\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4810):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.63460075e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.83\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2713, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.11\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -15.2158\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4810):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -15.21583077356503)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -15.21583077356503}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.908, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000009091986\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 400: reward=0.932, intervention_rate=1.000, scm=fork_3var\n",
      "INFO:causal_bayes_opt.training.modular_trainer:Saved checkpoint: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/checkpoints/grpo_training/enriched_grpo_episode_400/checkpoint.pkl\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4820):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.48650788e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.83\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2919, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.11\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 9.2044\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4820):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 9.20436777916882)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 9.20436777916882}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.908, trend=+0.402\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000011867018\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4830):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.20603558e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.82\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2923, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.11\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -3.6547\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4830):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -3.654723758527423)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -3.654723758527423}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3654723758527423}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.865472\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.865472\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.865) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.935, trend=-0.098\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000011846472\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4840):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.15428765e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.82\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2930, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.11\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 15.1483\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4840):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 15.148325772251955)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 15.148325772251955}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.939, trend=+0.004\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000017587176\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4850):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.61903133e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.82\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2817, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.11\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.5982\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4850):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 0.5981568533098018)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 0.5981568533098018}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.05981568533098019}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.559816\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.559816\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.895, trend=-0.440\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4860):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-3.1397985e-01 -1.0000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.82\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3346, Std: 6.9648\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.11\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -2.9104\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4860):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -2.9103972309625523)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -2.9103972309625523}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.29103972309625525}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.791040\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.791040\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.874, trend=+0.266\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000011132793\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 405):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=11.124731\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.810\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00001113\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00001113\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.539, max=1.000, group_baseline=0.802\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.356881, entropy=-4.112066\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00408889\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 3.843089\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4870):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.05024496 -0.18829606]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: -0.1882960641928387\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.81\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.54232474 0.45767526]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3268, Std: 6.3273\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.10\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -8.4245\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4870):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -8.424538963648233)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -8.424538963648233}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.922, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000002796338\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4880):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.19416905  0.00556743]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: 0.0055674341401425785\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.81\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.43870439 0.56129561]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2087, Std: 6.8562\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.10\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 7.4212\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4880):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 7.421175231027192)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 7.421175231027192}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.922, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000024871225\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4890):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.22198064 -0.11067745]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: -0.1106774453501672\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.81\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.46560024 0.53439976]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2888, Std: 7.3032\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.10\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -18.7706\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4890):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -18.770571053003533)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -18.770571053003533}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.922, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000019979629\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4900):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.15231087 -0.18206928]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: -0.1820692789215922\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.80\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.50924428 0.49075572]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3336, Std: 6.2083\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.10\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 7.2352\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4900):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 7.235228874817997)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 7.235228874817997}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.922, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000007737309\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4910):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.26800879 -0.13285815]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: -0.13285815415794797\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.80\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.45795753 0.54204247]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2654, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.10\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 13.3484\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4910):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 13.348353810425772)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 13.348353810425772}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.922, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4920):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.13094676 -0.24645916]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: -0.2464591619776274\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.80\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.53595631 0.46404369]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2658, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.10\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.5170\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4920):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 0.5169904259938802)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 0.5169904259938802}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.051699042599388026}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.551699\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.551699\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.877, trend=-0.314\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000026180847\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 410):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=13.348354\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.837\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00002618\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00002618\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.520, max=1.000, group_baseline=0.839\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.367572, entropy=-4.112069\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00616769\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 4.204368\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4930):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.55797112e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.80\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2708, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.10\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.1469\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4930):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -0.14689458898674068)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -0.14689458898674068}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.014689458898674068}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.514689\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.514689\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.842, trend=-0.485\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000029703465\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 410: reward=0.803, intervention_rate=1.000, scm=collider_3var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4940):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.99762429e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.80\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3117, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.10\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -9.7162\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4940):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -9.716171661869117)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -9.716171661869117}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.842, trend=+0.440\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000050520865\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4950):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.7255041e-01 -1.0000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.79\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2660, Std: 6.4652\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.10\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 17.5516\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4950):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 17.55156693945873)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 17.55156693945873}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.886, trend=+0.209\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000064026920\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4960):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.79798204e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.79\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2733, Std: 6.3255\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.10\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.5246\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4960):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 1.5246448765182996)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 1.5246448765182996}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.15246448765182996}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.652464\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.652464\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.872, trend=-0.348\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000120784159\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4970):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.8121336e-01 -1.0000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.79\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3210, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.10\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.5178\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4970):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -0.5178010013149015)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -0.5178010013149015}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.05178010013149015}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.551780\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.551780\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.827, trend=-0.448\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4980):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.72171385e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.79\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3116, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.10\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.3178\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4980):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -0.31775881975807124)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -0.31775881975807124}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.03177588197580713}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.531776\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.531776\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.780, trend=-0.468\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000159087730\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 415):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=15.430739\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.884\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00015909\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00015909\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.523, max=1.000, group_baseline=0.884\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.341929, entropy=-4.112026\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00075191\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 4.463956\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 4990):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.53864689e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.78\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2820, Std: 6.1152\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.09\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 16.5883\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 4990):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 16.58833801963051)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 16.58833801963051}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.780, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000193102740\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5000):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.3388336e-01 -1.0000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.78\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3253, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.09\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -10.2631\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5000):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -10.263079714213283)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -10.263079714213283}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.780, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000244386075\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5010):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.11259891e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.78\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3019, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.09\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -4.1254\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5010):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -4.125420654304283)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -4.125420654304283}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.4125420654304283}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.912542\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.912542\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.913) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.771, trend=+0.361\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000280331471\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5020):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.4475025e-01 -1.0000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.78\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3027, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.09\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.7754\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5020):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -1.7753907117678638)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -1.7753907117678638}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.17753907117678638}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.677539\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.677539\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.784, trend=+0.163\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000303308793\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5030):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.62891016e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.77\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2677, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.09\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 9.5822\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5030):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 9.582197585748112)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 9.582197585748112}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.833, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5040):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.79141454e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.77\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2860, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.09\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -10.2740\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5040):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -10.27404375166352)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -10.27404375166352}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.833, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000327295644\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 420):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=22.171807\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.985\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00032730\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00032730\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.848, max=1.000, group_baseline=0.986\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.228041, entropy=-4.111938\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00054135\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 4.783506\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5050):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.00617811 -0.41471636 -0.17333578]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.1733357772399769\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.77\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.4179147  0.24576726 0.33631803]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3041, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.09\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 11.5143\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5050):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 11.514262914930779)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 11.514262914930779}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.833, trend=+0.348\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000301601747\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 420: reward=0.882, intervention_rate=1.000, scm=fork_4var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5060):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.18839309 -0.50100066 -0.09061402]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.09061402150915628\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.77\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.35699457 0.23744522 0.4055602 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3426, Std: 6.2341\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.09\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -7.8497\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5060):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -7.849679002483669)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -7.849679002483669}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.867, trend=+0.448\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000259760754\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5070):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.22266726 -0.0466993  -0.45515527]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.4551552671593114\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.76\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33370335 0.42017695 0.2461197 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3112, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.09\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.8118\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5070):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -1.8117864696716626)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -1.8117864696716626}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.18117864696716626}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.681179\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.681179\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.880, trend=+0.149\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000230545595\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5080):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.09630096  0.08777133 -0.33784015]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.33784014695991277\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.76\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33314325 0.4243407  0.24251606]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2858, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.09\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -3.0458\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5080):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -3.0457552179140293)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -3.0457552179140293}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.30457552179140296}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.804576\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.804576\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.805) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.908, trend=-0.195\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000234761789\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5090):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 0.03748383 -0.21580003 -0.19837039]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.19837038645842026\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.76\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.40842431 0.29238644 0.29918925]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2772, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.09\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 9.4100\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5090):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 9.409997256124905)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 9.409997256124905}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.908, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5100):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.091165   -0.33242595 -0.25692725]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.25692724953064866\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.76\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.3951211  0.28738631 0.31749259]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2723, Std: 6.8495\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.09\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 10.3397\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5100):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 10.339678104588165)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 10.339678104588165}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.908, trend=+0.087\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000237885018\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 425):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=18.941389\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.931\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00023789\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00023789\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.570, max=1.000, group_baseline=0.935\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.304436, entropy=-4.517454\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00040093\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 234375004.818540\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5110):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-9.16746614e-02 -1.00000000e+09 -2.21591410e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.75\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.54291958 0.         0.45708042]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3073, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.08\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.6495\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5110):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 2.649508253666804)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 2.649508253666804}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.2649508253666804}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.764951\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.764951\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.893, trend=+0.087\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000223744689\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5120):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-3.9039886e-01 -1.0000000e+09 -1.1078910e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.75\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.37649635 0.         0.62350365]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3145, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.08\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.4362\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5120):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -0.43618034605587613)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -0.43618034605587613}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.043618034605587615}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.543618\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.543618\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.879, trend=-0.456\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000403391312\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5130):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.63202439e-01 -1.00000000e+09 -5.21877576e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.75\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.61747794 0.         0.38252206]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3028, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.08\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.8619\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5130):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -1.8619168667182673)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -1.8619168667182673}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.18619168667182673}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.686192\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.686192\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.848, trend=-0.314\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000630902297\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5140):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-7.7556407e-02 -1.0000000e+09 -3.3322974e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.75\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.58484201 0.         0.41515799]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2649, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.08\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 4.2957\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5140):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 4.295715709669667)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 4.295715709669667}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.42957157096696674}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.929572\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.929572\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.930) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.841, trend=-0.070\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000422912518\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5150):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.24343120e-01 -1.00000000e+09  5.91883396e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.74\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.4057605 0.        0.5942395]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3065, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.08\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -6.4546\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5150):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -6.45455654307682)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -6.45455654307682}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.841, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5160):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-3.41636290e-01 -1.00000000e+09 -3.64784418e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.74\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.50778639 0.         0.49221361]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2552, Std: 5.6052\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.08\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.2514\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5160):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 3.251374850753769)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 3.251374850753769}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.32513748507537693}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.825137\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.825137\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.825) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.824, trend=+0.144\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000115352942\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 430):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=7.807474\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.769\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00011535\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00011535\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.523, max=1.000, group_baseline=0.774\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.356280, entropy=-4.515533\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00350249\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 671875004.077080\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5170):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.0911878  -0.3428534  -0.31778288]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.317782883473524\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.74\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.40848212 0.29075098 0.3007669 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2961, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.08\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.4363\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5170):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 2.4362677335151206)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 2.4362677335151206}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.24362677335151206}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.743627\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.743627\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.830, trend=-0.061\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000126796439\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 430: reward=0.855, intervention_rate=1.000, scm=collider_4var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5180):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.30674081 -0.2214259   0.07119001]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: 0.07119001204233993\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.74\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.26369411 0.29604209 0.4402638 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2948, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.08\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -5.8086\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5180):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -5.8085931351539495)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -5.8085931351539495}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.849, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000082075647\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5190):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 0.20148854 -0.59448203 -0.37656772]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.37656771795701677\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.73\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.5575918  0.18862338 0.25378482]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3583, Std: 7.0273\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.08\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 8.6646\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5190):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 8.664628347722212)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 8.664628347722212}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.849, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000078751723\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5200):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.17816514 -0.15845996 -0.40341774]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.403417739284254\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.73\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.36202315 0.37190864 0.26606821]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2936, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.08\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.7349\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5200):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 0.7349119337975653)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 0.7349119337975653}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.07349119337975653}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.573491\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.573491\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.807, trend=-0.191\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000058797405\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5210):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 0.02793628 -0.35356892 -0.24747821]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.24747821417562893\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.73\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.43907082 0.26007916 0.30085002]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3168, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.08\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -4.2244\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5210):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -4.224417114474076)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -4.224417114474076}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.42244171144740766}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.922442\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.922442\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.922) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.822, trend=+0.379\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5220):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.29453161 -0.22188004 -0.23420633]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.23420633330457774\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.73\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.31336191 0.34622341 0.34041468]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X3 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3234, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.08\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.5292\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5220):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 0.5291642310398965)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': 0.5291642310398965}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.052916423103989654}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.552916\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.552916\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.823, trend=-0.133\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000030135446\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 435):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=21.064469\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.834\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00003014\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00003014\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.553, max=1.000, group_baseline=0.836\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.374040, entropy=-4.517303\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00064606\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 328125004.657805\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5230):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.35074697 -0.43176888 -0.44592088]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.445920875087734\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.73\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.36082655 0.32270327 0.31647018]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X3 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2992, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.08\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -4.2560\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5230):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -4.2560247121023025)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -4.2560247121023025}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.42560247121023026}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.925602\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.925602\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.926) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.847, trend=-0.004\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000004080051\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5240):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.38282935 -0.1090921  -0.15920165]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.15920165000674316\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.72\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.26156102 0.38201535 0.35642363]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3138, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.07\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -4.7814\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5240):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -4.781365721683755)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -4.781365721683755}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.47813657216837546}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.978137\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.978137\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.978) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.852, trend=-0.022\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000006369831\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5250):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.45366948 -0.61451048 -0.31727889]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.31727888627832596\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.72\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33240438 0.26583534 0.40176028]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2864, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.07\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.7631\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5250):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 2.763104892636896)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 2.763104892636896}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.2763104892636896}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.776310\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.776310\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.830, trend=-0.049\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000031553943\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5260):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.35654276 -0.35891691 -0.36552888]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.3655288789726686\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.72\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33509425 0.33398619 0.33091956]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X3 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3311, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.07\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.2927\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5260):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 0.2926952491206167)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': 0.2926952491206167}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.029269524912061667}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.529270\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.529270\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.800, trend=-0.214\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000123499988\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5270):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.37545762 -0.31378254 -0.42074229]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.42074229224669113\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.71\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.3301668  0.35996029 0.30987291]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3329, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.07\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.9232\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5270):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 1.923161607662352)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 1.923161607662352}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.1923161607662352}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.692316\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.692316\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.795, trend=-0.308\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5280):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.24646748 -0.28236909 -0.45175313]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.45175312573505977\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.71\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.37022814 0.35206918 0.27770267]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3361, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.07\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -11.1069\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5280):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -11.106854356979612)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -11.106854356979612}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.795, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000097800310\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 440):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=13.722534\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.935\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00009780\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00009780\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.662, max=1.000, group_baseline=0.934\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.320508, entropy=-4.517211\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00089204\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 328125004.575432\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5290):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -2.85500444e-01 -3.78647831e-01 -6.14336460e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.71\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.39890176 0.34991654 0.2511817 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3377, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.07\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 12.1542\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5290):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 12.154194734381235)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 12.154194734381235}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.795, trend=+0.427\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000091666040\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 440: reward=0.857, intervention_rate=1.000, scm=fork_5var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5300):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09  1.37939360e-01  6.66163628e-02 -5.92113980e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.71\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.4423269  0.39993883 0.15773427]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3407, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.07\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.6628\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5300):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 2.662780296076506)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 2.662780296076506}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.2662780296076506}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.766278\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.766278\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.814, trend=-0.156\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000103415292\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5310):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -3.08307563e-02 -3.48104950e-01 -3.26431316e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.71\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.43569547 0.27781602 0.28648851]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3145, Std: 6.7998\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.07\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 12.8736\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5310):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 12.873613988763045)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 12.873613988763045}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.822, trend=+0.447\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000104454841\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5320):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -3.28281070e-01 -3.84006665e-01 -1.47486763e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.70\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.31081203 0.28709809 0.40208988]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3411, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.07\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -5.2135\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5320):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -5.21353544359665)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -5.21353544359665}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.867, trend=+0.074\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000133796758\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5330):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -2.01197252e-01 -3.46837962e-01 -2.95690371e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.70\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.3723613  0.30234658 0.32529212]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3175, Std: 6.7798\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.07\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.0370\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5330):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 2.0370192424632054)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 2.0370192424632054}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.20370192424632055}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.703702\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.703702\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.845, trend=-0.274\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5340):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -3.38473486e-01 -1.95735083e-01 -3.05862436e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.70\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.30541685 0.37458449 0.31999866]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3228, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.07\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -5.5746\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5340):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -5.574579085446001)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -5.574579085446001}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.847, trend=+0.224\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000147369158\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 445):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=11.428579\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.924\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00014737\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00014737\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.642, max=1.000, group_baseline=0.924\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.338374, entropy=-4.805165\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00030916\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 312500004.812741\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5350):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.49925967e-01 -1.00000000e+09 -2.76005625e-01 -2.63620390e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.70\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.37261685 0.         0.31090175 0.31648139]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3348, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.07\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -7.3691\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5350):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -7.369081915705887)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -7.369081915705887}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.869, trend=+0.471\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000102961614\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5360):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.84374672e-01 -1.00000000e+09 -1.35270871e-01 -1.89076665e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.69\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.3260909 0.        0.3500221 0.323887 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3157, Std: 7.0165\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.06\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 7.6309\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5360):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 7.630858556204134)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 7.630858556204134}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.916, trend=+0.308\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000148115972\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5370):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.28011564e-01 -1.00000000e+09 -2.53508278e-01  5.85994966e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.69\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.28749701 0.         0.27707375 0.43542924]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3381, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.06\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -2.0705\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5370):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -2.070517419414296)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -2.070517419414296}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.2070517419414296}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.707052\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.707052\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.918, trend=-0.293\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000127025057\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5380):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.64437972e-01 -1.00000000e+09 -8.51573189e-02 -3.15103285e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.69\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.45591853 0.         0.31711562 0.22696585]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3348, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.06\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.4382\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5380):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 1.4381947066429395)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 1.4381947066429395}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.14381947066429396}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.643819\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.643819\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.882, trend=-0.356\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000138881974\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5390):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-7.52667816e-02 -1.00000000e+09 -1.33462483e-01 -2.46020422e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.68\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.37067982 0.         0.34047038 0.2888498 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3364, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.06\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.9515\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5390):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 2.9514994207346446)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 2.9514994207346446}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.29514994207346446}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.795150\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.795150\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.862, trend=+0.029\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5400):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.16766531e-01 -1.00000000e+09 -3.71864587e-01 -1.93472731e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.68\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.35312208 0.         0.28153343 0.36534449]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3262, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.06\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.9413\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5400):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 2.941253852003986)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 2.941253852003986}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.2941253852003986}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.794125\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.794125\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.864, trend=-0.206\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000104281021\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 450):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=16.893263\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.899\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00010428\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00010428\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.635, max=1.000, group_baseline=0.896\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.348481, entropy=-4.804913\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00055143\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 171875005.200751\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5410):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09  1.17158352e-01 -1.67382782e-02  9.24482307e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.68\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.35893049 0.29491757 0.34615194]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3746, Std: 7.0614\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.06\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -5.5248\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5410):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -5.524816536209019)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -5.524816536209019}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.864, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000004248826\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 450: reward=0.880, intervention_rate=1.000, scm=collider_5var\n",
      "INFO:causal_bayes_opt.training.modular_trainer:Saved checkpoint: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/checkpoints/grpo_training/enriched_grpo_episode_450/checkpoint.pkl\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5420):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.33506899e-01 -1.05332560e-01 -3.51339143e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.68\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.36129194 0.37660537 0.26210269]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3361, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.06\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.9171\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5420):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 0.917078626012381)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 0.917078626012381}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.0917078626012381}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.591708\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.591708\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.824, trend=-0.112\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000027073337\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5430):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09  9.08853959e-03 -2.09648837e-01 -1.85235193e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.68\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.40427282 0.29248378 0.30324339]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3186, Std: 7.2436\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.06\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -5.2544\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5430):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -5.254427230035289)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -5.254427230035289}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.853, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000042587261\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5440):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09  1.07660697e-01 -1.23818747e-02 -1.78624931e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.67\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.37503552 0.31375488 0.31120961]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3192, Std: 6.7671\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.06\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -7.5820\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5440):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -7.582042217090293)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -7.582042217090293}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.853, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000040687494\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5450):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -9.06427173e-02  1.20760832e-01 -1.64397606e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.67\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.30611162 0.41968913 0.27419925]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2928, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.06\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 12.7970\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5450):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 12.79703939608613)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 12.79703939608613}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.853, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5460):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -2.64756574e-01 -1.43819184e-01  4.69946712e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.67\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.2638227  0.31601886 0.42015845]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3419, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.06\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -13.2815\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5460):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -13.281543745373844)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -13.281543745373844}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.853, trend=+0.293\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000054147213\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 455):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=13.281544\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.860\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00005415\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00005415\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.530, max=1.000, group_baseline=0.863\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.355272, entropy=-4.805136\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00180744\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 421875004.801020\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5470):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09  1.23976152e-01  7.38000150e-02 -1.37387258e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.67\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.36483276 0.33839423 0.29677301]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3174, Std: 6.8993\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.06\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 5.6718\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5470):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 5.671797819961632)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 5.671797819961632}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.882, trend=+0.356\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000002569511\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5480):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09  2.45073060e-02  1.92073736e-01  6.05777949e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.66\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.29914614 0.38500932 0.31584454]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3417, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.05\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -6.3702\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5480):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -6.370208082132551)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -6.370208082132551}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.918, trend=+0.205\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000005202286\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5490):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09  1.36526398e-02  1.09865543e-01 -3.98479189e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.66\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.32478979 0.37566791 0.2995423 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3362, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.05\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -11.3676\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5490):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -11.367561394506172)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -11.367561394506172}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.939, trend=+0.206\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000021710903\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5500):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09 -1.41993191e-01  2.00988408e-02  3.12456389e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.66\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.27930431 0.35729664 0.36339905]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3100, Std: 6.6745\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.05\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.8438\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5500):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -1.843779317191129)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -1.843779317191129}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.1843779317191129}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.684378\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.684378\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.928, trend=-0.316\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000014835266\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5510):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09  9.54388911e-02  4.52431261e-02  2.51346030e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.66\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.3540421  0.32793423 0.31802368]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3376, Std: 6.0221\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.05\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -2.7088\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5510):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -2.7087871188340964)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -2.7087871188340964}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.2708787118834097}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.770879\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.770879\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.905, trend=+0.179\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5520):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00000000e+09  4.86124590e-03 -1.23970988e-01  4.80134414e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X0', 'X1', 'X3'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.66\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.         0.34607072 0.28430136 0.36962792]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3248, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.05\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -6.5048\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5520):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -6.504833159924419)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -6.504833159924419}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.946, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000027680721\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 460):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=12.117173\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.829\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00002768\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00002768\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.541, max=1.000, group_baseline=0.828\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.343857, entropy=-4.805222\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00101888\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 250000004.577121\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5530):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 0.04407477  0.03467276  0.01200208 -0.07901077  0.0916048 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: 0.09160480456864416\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.65\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.20655419 0.20359854 0.19664449 0.17103715 0.22216563]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3381, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.05\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.3886\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5530):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 0.38855417027963607)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': 0.38855417027963607}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.03885541702796361}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.538855\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.538855\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.899, trend=-0.461\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000019327286\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 460: reward=0.884, intervention_rate=1.000, scm=fork_6var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5540):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.20693947 -0.18876782 -0.03225703  0.03972959 -0.22000842]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.22000842395285986\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.65\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.17303644 0.17794666 0.22644156 0.25298633 0.16958902]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3330, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.05\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -4.9012\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5540):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -4.901215740480518)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -4.901215740480518}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.49012157404805184}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.990122\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.990122\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.990) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.898, trend=-0.010\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000012192141\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5550):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [0.00927581 0.05255182 0.13442754 0.15784804 0.04733084]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: 0.047330843741589815\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.65\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.17851316 0.19087196 0.21664293 0.22463525 0.1893367 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3145, Std: 6.9479\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.05\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.6585\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5550):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 3.6585249737915597)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': 3.6585249737915597}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.365852497379156}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.865852\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.865852\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.866) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.885, trend=-0.134\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000007510762\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5560):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.05967148  0.0172712   0.05076045 -0.06306188 -0.01619086]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.016190864515018243\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.64\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.18591362 0.20952457 0.22071647 0.18493676 0.19890858]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3326, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.05\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -10.2949\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5560):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -10.294856283526961)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -10.294856283526961}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.885, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000005766968\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5570):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 0.02461095 -0.09056733 -0.01723084 -0.04359904 -0.19621503]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.19621502889361733\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.64\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.22832891 0.1907563  0.21389242 0.20526731 0.16175506]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3476, Std: 6.6073\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.05\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -7.5629\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5570):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -7.562886376881685)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -7.562886376881685}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.885, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5580):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.20469194  0.07629131  0.00770613  0.00156388 -0.0130767 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.013076699332805471\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.64\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.14987663 0.23239082 0.20879663 0.20680427 0.20213165]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3341, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.05\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -2.8583\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5580):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -2.858273602759044)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -2.858273602759044}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.28582736027590444}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.785827\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.785827\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.864, trend=-0.214\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000005086398\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 465):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=17.762649\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.829\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00000509\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00000509\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.541, max=1.000, group_baseline=0.825\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.355139, entropy=-5.028300\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00033989\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 250000005.007248\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5590):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-6.31097127e-03 -1.00000000e+09 -9.25555443e-02 -3.03430502e-02\n",
      " -1.17086101e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.64\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.2719566  0.         0.2375548  0.26189841 0.22859019]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2704, Std: 6.1151\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.05\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -6.7905\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5590):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -6.79050292639623)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -6.79050292639623}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.864, trend=+0.316\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000009522849\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5600):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-9.31489048e-02 -1.00000000e+09 -1.54759030e-02  4.63258192e-02\n",
      "  1.75273634e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.63\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.21899168 0.         0.24749704 0.27280577 0.26070551]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3381, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.04\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -3.8180\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5600):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, -3.8179564280417093)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -3.8179564280417093}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.38179564280417094}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.881796\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.881796\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.882) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.883, trend=+0.111\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000025620308\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5610):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 4.28088330e-02 -1.00000000e+09  6.59381767e-02 -4.04524063e-02\n",
      "  4.37930376e-03]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.63\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.259416   0.         0.26908829 0.22738766 0.24410805]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3002, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.04\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -8.6321\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5610):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, -8.632058036676016)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -8.632058036676016}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.906, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000037633969\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5620):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-6.38851658e-02 -1.00000000e+09 -1.18261822e-01  1.07136981e-01\n",
      " -1.36568295e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.63\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.2426872  0.         0.22258545 0.31852762 0.21619973]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3046, Std: 6.4493\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.04\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 7.6886\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5620):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, 7.688601756346842)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 7.688601756346842}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.906, trend=+0.461\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000052523953\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5630):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.16494283e-03 -1.00000000e+09  2.27440733e-01  7.83078508e-02\n",
      "  9.72287892e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.63\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.21042131 0.         0.30365972 0.23928788 0.24663109]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3293, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.04\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 12.0976\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5630):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 12.097590133783129)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 12.097590133783129}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.952, trend=+0.010\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5640):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 4.16867296e-02 -1.00000000e+09 -1.15434885e-01  1.50970422e-01\n",
      "  1.99863998e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X5' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.63\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.25414927 0.         0.19773335 0.30262757 0.24548981]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2778, Std: 7.0259\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.04\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.8683\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5640):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 3.8682762361122296)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': 3.8682762361122296}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.38682762361122297}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.886828\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.886828\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.887) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.942, trend=+0.021\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000060785605\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 470):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=12.560096\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.861\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00006079\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00006079\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.536, max=1.000, group_baseline=0.859\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.344300, entropy=-5.028264\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00047511\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 93750004.938307\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5650):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.02867013 -0.04114384 -0.01803624 -0.01026565 -0.0732632 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.0732631965778797\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.62\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.20168197 0.19768435 0.20515373 0.20772841 0.18775154]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3593, Std: 6.9294\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.04\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -4.8978\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5650):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -4.897789502225482)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -4.897789502225482}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.48977895022254825}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.989779\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.989779\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.990) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.954, trend=-0.010\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000091234263\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 470: reward=0.896, intervention_rate=1.000, scm=collider_6var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5660):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.09044332  0.03440073 -0.0364955   0.01516187  0.10124441]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: 0.10124441204296426\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.62\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.17059632 0.20864274 0.18610225 0.20226907 0.23238963]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2529, Std: 6.4617\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.04\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.1384\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5660):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 3.138417188559566)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': 3.138417188559566}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.31384171885595663}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.813842\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.813842\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.814) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.936, trend=-0.186\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000092819465\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5670):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [0.09284061 0.07447527 0.09771267 0.01778914 0.16376476]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: 0.16376475660938283\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.62\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.20056617 0.19468595 0.2021557  0.17760142 0.22499075]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2936, Std: 6.9838\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.04\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.3420\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5670):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, -0.3419777524766699)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -0.3419777524766699}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.03419777524766699}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.534198\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.534198\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.889, trend=-0.252\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000111660772\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5680):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 0.06845997  0.04105348  0.03739388  0.14725161 -0.09556922]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: -0.09556922451294096\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.61\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.20791954 0.19884666 0.1976655  0.2363757  0.1591926 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3140, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.04\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -2.2142\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5680):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -2.21423114563538)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -2.21423114563538}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.22142311456353803}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.721423\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.721423\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.883, trend=-0.279\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000110648613\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5690):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 0.06682347 -0.01567623  0.02860479 -0.00564174  0.09813849]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: 0.09813848810070781\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.61\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.21035215 0.18379692 0.19760411 0.18683871 0.2214081 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3220, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.04\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -3.9599\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5690):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -3.9598847486986695)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -3.9598847486986695}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.395988474869867}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.895988\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.895988\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.896) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.872, trend=+0.014\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5700):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.06528688 -0.0332158  -0.05211738  0.01698805  0.04771884]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 5, logit: 0.047718839220486774\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.61\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.18440862 0.1943412  0.18842433 0.21097465 0.2218512 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X4 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3080, Std: 6.5358\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.04\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.8970\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5700):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 1.8970487233644282)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': 1.8970487233644282}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.18970487233644284}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.689705\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.689705\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.853, trend=-0.310\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000117790274\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 475):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=13.650041\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.831\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00011779\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00011779\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.543, max=1.000, group_baseline=0.825\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.362047, entropy=-5.028360\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00093981\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 265625004.999158\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5710):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.92970841e-01  3.96735229e-02 -1.00000000e+09  1.22891796e-01\n",
      "  8.77735331e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.61\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.28492594 0.22146414 0.         0.25392608 0.23968384]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2718, Std: 6.9167\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.04\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 4.2261\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5710):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, 4.226117400452754)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 4.226117400452754}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.4226117400452754}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.922612\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.922612\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.923) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.845, trend=-0.077\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000111017760\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5720):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.91721520e-01  9.73070082e-02 -1.00000000e+09  1.87098925e-01\n",
      " -6.18551464e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.61\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.28523859 0.24405406 0.         0.28306916 0.18763818]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2985, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.04\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.1251\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5720):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -1.1251296052347035)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -1.1251296052347035}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.11251296052347036}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.612513\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.612513\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.807, trend=-0.387\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000102853346\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5730):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-3.35731798e-02  1.45047538e-01 -1.00000000e+09 -9.43643589e-02\n",
      "  7.81281821e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.60\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.22457866 0.30207421 0.         0.20302606 0.27032108]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X2 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3180, Std: 6.4374\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.03\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -7.3910\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5730):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -7.391033598433131)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -7.391033598433131}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.807, trend=+0.113\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000091703272\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5740):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.89200012e-01 -8.13062487e-02 -1.00000000e+09 -3.21420834e-02\n",
      " -7.00892664e-03]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.60\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.3279604  0.20887905 0.         0.22672754 0.23643301]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 4)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3124, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.03\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.1879\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5740):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (4, 0.18794313511065083)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 0.18794313511065083}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.018794313511065086}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.518794\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.518794\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.770, trend=-0.471\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000087445747\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5750):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 2.95068925e-01  4.53098503e-02 -1.00000000e+09  5.85191649e-02\n",
      "  2.80277495e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.60\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33671359 0.22155064 0.         0.22651003 0.21522574]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3510, Std: 4.8718\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.03\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -4.5700\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5750):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -4.57004896069095)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -4.57004896069095}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.457004896069095}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.957005\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.957005\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.957) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.767, trend=+0.143\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5760):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.13967979e-01  9.29318972e-02 -1.00000000e+09  1.34387499e-01\n",
      "  5.64933449e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X0', 'X1', 'X3'], Target: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X4' at index 2, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.60\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.25586292 0.24699957 0.         0.26477058 0.23236693]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 3)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3024, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.03\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.0480\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5760):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (3, -1.0479928525600333)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -1.0479928525600333}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.10479928525600334}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.604799\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.604799\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.746, trend=+0.071\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000082536907\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 480):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=16.470984\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.766\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00008254\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00008254\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.545, max=1.000, group_baseline=0.769\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.374976, entropy=-5.028356\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00040703\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 328125004.835833\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5770):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 2.2445257e-01 -1.0000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.59\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3148, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.03\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.7514\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5770):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 0.751350191953486)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 0.751350191953486}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.0751350191953486}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.575135\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.575135\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.750, trend=-0.146\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000074839317\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 480: reward=0.875, intervention_rate=1.000, scm=fork_3var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5780):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.70662462e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.59\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2790, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.03\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -7.2115\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5780):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -7.211489315735193)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -7.211489315735193}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.778, trend=+0.104\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000076049937\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5790):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.23910189e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.59\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3144, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.03\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -11.7205\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5790):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -11.720521939990668)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -11.720521939990668}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.788, trend=+0.310\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000077623377\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5800):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-7.07294522e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.58\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2984, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.03\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -2.8086\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5800):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -2.8085858610643832)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -2.8085858610643832}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.2808585861064383}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.780859\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.780859\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.797, trend=-0.142\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000081724802\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5810):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 4.32015276e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.58\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2866, Std: 6.5843\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.03\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 0.8440\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5810):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 0.8439537115887604)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 0.8439537115887604}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.08439537115887605}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.584395\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.584395\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.763, trend=-0.028\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5820):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 2.14454894e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.58\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3209, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.03\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -8.3602\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5820):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -8.360201630928984)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -8.360201630928984}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.802, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000080729577\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 485):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=10.891959\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.807\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00008073\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00008073\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.541, max=1.000, group_baseline=0.812\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.375212, entropy=-4.112070\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00478834\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 3.890685\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5830):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 0.15189572 -0.01668982]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: -0.016689815813489408\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.58\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.57226924 0.42773076]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.2384, Std: 5.3892\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.03\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.4855\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5830):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 2.4855137847839046)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 2.4855137847839046}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.24855137847839048}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.748551\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.748551\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.777, trend=+0.230\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000079871099\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5840):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [0.1337433  0.03474632]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: 0.034746318255286957\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.58\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.54284926 0.45715074]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3358, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.03\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 5.6893\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5840):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 5.689332591295863)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 5.689332591295863}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.825, trend=+0.043\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000077105460\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5850):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [0.17989845 0.02433092]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: 0.024330923168035812\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.57\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.56743212 0.43256788]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3460, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.02\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 2.0603\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5850):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 2.060338006363976)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 2.060338006363976}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.2060338006363976}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.706034\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.706034\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.800, trend=+0.101\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000070987611\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5860):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [0.17671862 0.1487637 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: 0.14876369998152028\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.57\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.51225176 0.48774824]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3381, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.02\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 5.1698\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5860):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 5.169781528405791)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 5.169781528405791}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.839, trend=+0.425\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000070988091\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5870):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [0.05966226 0.27678349]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: 0.276783494789405\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.57\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.40548272 0.59451728]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3575, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.02\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.1519\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5870):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -0.15187050060878476)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -0.15187050060878476}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.015187050060878476}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.515187\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.515187\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.834, trend=-0.485\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5880):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [0.05616322 0.07571017]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 2, logit: 0.07571017240716371\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.57\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.49138808 0.50861192]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3319, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.02\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.7785\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5880):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, -1.7785305446345514)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -1.7785305446345514}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.17785305446345515}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.677853\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.677853\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.801, trend=-0.322\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000054620169\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 490):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=6.604541\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.738\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00005462\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00005462\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.515, max=1.000, group_baseline=0.739\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.333863, entropy=-4.112068\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00131792\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 3.710590\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5890):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 6.53173905e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.56\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3295, Std: 6.9528\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.02\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -7.9408\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5890):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -7.940793571508355)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -7.940793571508355}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.801, trend=+0.219\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000066276172\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 490: reward=0.902, intervention_rate=1.000, scm=collider_3var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5900):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.57805604e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.56\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3132, Std: 7.1118\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.02\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.2384\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5900):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 3.23837639520054)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 3.23837639520054}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.323837639520054}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.823838\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.823838\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.824) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.806, trend=+0.239\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000093484611\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5910):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-2.56903946e-03 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.56\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3823, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.02\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 9.4937\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5910):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 9.493714898553149)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 9.493714898553149}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.847, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000107721588\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5920):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.79105683e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.56\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3800, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.02\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 13.3839\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5920):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 13.38390907190089)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 13.38390907190089}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.847, trend=+0.251\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000109963002\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5930):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-4.6168241e-02 -1.0000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.55\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3183, Std: 6.7793\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.02\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 9.4544\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5930):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 9.454413613746455)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 9.454413613746455}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.872, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5940):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.45014648e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.55\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3649, Std: 6.8419\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.02\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -0.1045\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5940):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -0.10452667708747937)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -0.10452667708747937}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.010452667708747938}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.510453\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.510453\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.823, trend=-0.196\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000120711625\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 495):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=21.307799\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.873\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00012071\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00012071\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.510, max=1.000, group_baseline=0.875\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.346034, entropy=-4.112056\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00369342\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 4.540909\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5950):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.05667226e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.55\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3958, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.02\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 7.1667\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5950):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 7.166653814453177)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 7.166653814453177}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.853, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000144701133\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5960):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 2.48867118e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.55\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3762, Std: 7.3485\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.02\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 9.4046\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5960):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 9.404585093128834)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 9.404585093128834}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.853, trend=+0.485\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000160354457\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5970):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.4701619e-01 -1.0000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.54\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.3765, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.01\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -14.9836\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5970):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -14.983601718557338)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -14.983601718557338}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.901, trend=+0.322\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000168429348\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5980):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 1.20355085e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.54\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4207, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.01\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 7.6910\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5980):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 7.690957828139117)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 7.690957828139117}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.933, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000181297939\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 5990):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.78458228e-02 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.54\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4090, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.01\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 5.4865\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 5990):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 5.486475855307802)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 5.486475855307802}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.933, trend=+0.176\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 6000):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.00064361e-01 -1.00000000e+09]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X1', 'X2'], Target: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.54\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [1. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4345, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.01\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -6.9461\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 6000):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -6.946111975038379)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -6.946111975038379}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.951, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000224607654\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 500):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=11.966312\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.901\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00022461\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00022461\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.591, max=1.000, group_baseline=0.895\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.345110, entropy=-4.112032\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00265751\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 3.947980\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 6010):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.07298982  0.26464829  0.00969413]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: 0.00969413183758042\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.54\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.24713272 0.46444379 0.28842349]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4339, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.01\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 1.0189\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 6010):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 1.0188854320252554)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 1.0188854320252554}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.10188854320252555}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.601889\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.601889\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.911, trend=-0.398\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000209369520\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 500: reward=0.835, intervention_rate=1.000, scm=fork_4var\n",
      "INFO:causal_bayes_opt.training.modular_trainer:Saved checkpoint: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/checkpoints/grpo_training/enriched_grpo_episode_500/checkpoint.pkl\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 6020):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [0.19773529 0.23710802 0.16584773]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: 0.16584773308316236\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.53\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.33127628 0.35671248 0.31201124]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4753, Std: 6.5947\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.01\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -3.2729\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 6020):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -3.2729209909822137)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -3.2729209909822137}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3272920990982214}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.827292\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.827292\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.827) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.894, trend=-0.173\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000196470239\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 6030):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [0.07105778 0.17145594 0.11875068]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: 0.1187506843602124\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.53\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.3027408  0.36597284 0.33128636]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4720, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.01\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.3097\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 6030):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 3.3096733214027694)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 3.3096733214027694}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.33096733214027696}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.830967\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.830967\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.831) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.877, trend=+0.321\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000192227815\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 6040):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [0.07555132 0.12183147 0.13782086]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: 0.13782085539362945\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.53\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.31080155 0.3393657  0.34983275]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4542, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.01\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -4.1975\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 6040):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -4.197483691406564)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -4.197483691406564}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.41974836914065644}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.919748\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.919748\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.920) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.918, trend=-0.080\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000181678190\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 6050):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 0.09223418  0.08868774 -0.02475702]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.02475702377949675\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.52\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.35804333 0.35562568 0.28633099]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4552, Std: 6.4353\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.01\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 5.9530\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 6050):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 5.952990236395551)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 5.952990236395551}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.918, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 6060):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.00898003  0.03131244 -0.12712116]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.12712115657724787\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.52\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.34746685 0.37527006 0.27726308]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4665, Std: 6.2235\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.01\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 4.2043\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 6060):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, 4.204294458990837)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': 4.204294458990837}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.42042944589908376}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.920429\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.920429\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.920) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.910, trend=-0.080\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000161048891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 505):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=7.172730\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.827\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00016105\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00016105\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.532, max=1.000, group_baseline=0.832\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.380446, entropy=-4.517513\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00273060\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 250000004.201985\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 6070):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 2.16284125e-02 -1.00000000e+09  1.02718051e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.52\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.46113121 0.         0.53886879]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4154, Std: 6.4988\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.01\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.9969\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 6070):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, -1.9968774634901565)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': -1.9968774634901565}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.19968774634901565}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.699688\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.699688\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.880, trend=-0.300\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000178177748\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 6080):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 7.52010373e-02 -1.00000000e+09  1.00111789e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.52\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.48796996 0.         0.51203004]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4472, Std: 6.8905\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.01\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 11.1492\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 6080):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 11.14920117673382)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 11.14920117673382}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.880, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000116872676\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 6090):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-1.73963012e-01 -1.00000000e+09 -2.28351708e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.51\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.42710989 0.         0.57289011]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.5090, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.00\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -9.6053\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 6090):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -9.605250162248444)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -9.605250162248444}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.880, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000111207382\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 6100):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 7.43292902e-02 -1.00000000e+09  3.00343491e-01]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.51\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.39134154 0.         0.60865846]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4997, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.00\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.0196\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 6100):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -1.019570991374164)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -1.019570991374164}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.10195709913741641}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.601957\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.601957\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.840, trend=+0.000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000098569309\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 6110):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-5.91755406e-02 -1.00000000e+09 -7.64717170e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.51\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.50849788 0.         0.49150212]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4574, Std: 7.1350\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.00\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -6.4035\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 6110):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -6.40353635943189)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -6.40353635943189}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.880, trend=+0.173\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 6120):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 2.96408075e-03 -1.00000000e+09  7.30383092e-02]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.51\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.46562246 0.         0.53437754]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X1 (index 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.5040, Std: 6.6795\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.00\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: -1.3842\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 6120):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (2, -1.3842087581026505)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -1.3842087581026505}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.13842087581026505}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.638421\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.638421\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.861, trend=-0.193\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000059784915\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Policy Learning Diagnostics (update 510):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action magnitudes: max=11.817502\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Mean reward: 0.928\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Policy param change: 0.00005978\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Parameter norm change: 0.00005978\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Rewards: min=0.638, max=1.000, group_baseline=0.931\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  GRPO losses: policy=0.310245, entropy=-4.517203\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Gradient norm: 0.00160453\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Learning rate: 0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  KL penalty: 0.000000, approx_kl: 593750004.505063\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 6130):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [-0.11051717  0.16754564 -0.10955265]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.10955265069756835\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.51\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.26776529 0.46395838 0.26827633]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X3 (index 1)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.4915, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.00\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 6.5843\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 6130):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (1, 6.584265419163127)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': 6.584265419163127}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 1.000000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.878, trend=+0.080\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000060178927\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 510: reward=0.898, intervention_rate=1.000, scm=collider_4var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç Per-Variable Encoding - Policy Output (call 6140):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable logits: [ 0.12799441  0.06387296 -0.08416821]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X0', 'X3', 'X1', 'X2'], Target: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable 'X2' at index 3, logit: -0.08416821066277884\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è Target variable not properly masked!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variable selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 0.50\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Probabilities: [0.39430199 0.34710288 0.25859513]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Selected: X0 (index 0)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Value selection:\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Mean: 0.5139, Std: 7.3891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Temperature: 1.00\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:    Sampled value: 3.8023\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 6140):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: (0, 3.8022964853616035)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X0': 3.8022964853616035}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.38022964853616037}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.880230\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.880230\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  üí∞ HIGH REWARD: Policy achieved high reward (0.880) - good performance!\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.874, trend=-0.120\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:‚úÖ Parameters changed - norm delta: 0.000058926959\n",
      "INFO:causal_bayes_opt.training.modular_trainer:Saved checkpoint: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/checkpoints/grpo_training/enriched_grpo_final/checkpoint.pkl\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Training completed in 2669.2s\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Final checkpoint: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/checkpoints/grpo_training/enriched_grpo_final\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Training completed!\n",
      "‚è±Ô∏è Training time: 44.5 minutes\n",
      "\n",
      "üìä Final Results:\n",
      "  Final reward (internal): 0.8789\n",
      "  Final target value: -0.8789 (‚Üì better)\n",
      "\n",
      "üìÅ Checkpoint saved to: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/checkpoints/grpo_training/enriched_grpo_final\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cell 5: Train GRPO policy with correct optimization direction\n",
    "\n",
    "This cell performs the actual training.\n",
    "Progress is saved periodically for resumption.\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "\n",
    "print(\"üöÄ Starting GRPO Policy Training\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"üîß Training mode: {TRAINING_MODE}\")\n",
    "print(f\"üéØ Optimization: {optimization_config.direction}\")\n",
    "print(f\"üìä Total episodes: {total_episodes}\")\n",
    "print(f\"‚öñÔ∏è Reward weights: {config.training.reward_weights}\")\n",
    "print(f\"‚úÖ Surrogate integration: ACTIVE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Configure trainer for optimization direction\n",
    "if hasattr(trainer, 'optimization_config'):\n",
    "    trainer.optimization_config = optimization_config\n",
    "else:\n",
    "    # Inject optimization config\n",
    "    trainer.config.optimization = optimization_config.__dict__\n",
    "\n",
    "# Set training SCMs\n",
    "if hasattr(trainer, 'set_training_scms'):\n",
    "    trainer.set_training_scms(training_scms)\n",
    "\n",
    "# Training loop with explicit error handling\n",
    "training_start_time = time.time()\n",
    "training_metrics = {}\n",
    "\n",
    "try:\n",
    "    print(\"\\nüèÉ Starting Training Loop...\")\n",
    "    \n",
    "    # Run training\n",
    "    training_metrics = trainer.train()\n",
    "    \n",
    "    training_end_time = time.time()\n",
    "    training_duration = training_end_time - training_start_time\n",
    "    \n",
    "    print(f\"\\n‚úÖ Training completed!\")\n",
    "    print(f\"‚è±Ô∏è Training time: {training_duration/60:.1f} minutes\")\n",
    "    \n",
    "    # Extract performance metrics\n",
    "    performance = training_metrics.get('performance', {})\n",
    "    final_reward = performance.get('final_reward', 0.0)\n",
    "    \n",
    "    # Convert reward to actual target value if minimizing\n",
    "    if optimization_config.is_minimizing:\n",
    "        final_target_value = optimization_config.convert_from_maximization(final_reward)\n",
    "        print(f\"\\nüìä Final Results:\")\n",
    "        print(f\"  Final reward (internal): {final_reward:.4f}\")\n",
    "        print(f\"  Final target value: {optimization_config.format_improvement(final_target_value)}\")\n",
    "    else:\n",
    "        print(f\"\\nüìä Final Results:\")\n",
    "        print(f\"  Final target value: {optimization_config.format_improvement(final_reward)}\")\n",
    "    \n",
    "    # Store optimization direction in metrics\n",
    "    training_metrics['optimization_direction'] = optimization_config.direction\n",
    "    training_metrics['duration_minutes'] = training_duration / 60\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚ö†Ô∏è Training interrupted by user\")\n",
    "    training_metrics['interrupted'] = True\n",
    "    training_metrics['duration_minutes'] = (time.time() - training_start_time) / 60\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Training failed with error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise NotebookError(f\"Training failed: {e}\")\n",
    "\n",
    "# Get checkpoint path\n",
    "checkpoint_path = training_metrics.get('checkpoint_path', checkpoint_dir / \"grpo_final\")\n",
    "print(f\"\\nüìÅ Checkpoint saved to: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Checkpoint with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:scripts.notebooks.base_components:Saved checkpoint data: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/checkpoints/grpo_training/grpo_full_minimize_20250728_163157/checkpoint.pkl\n",
      "INFO:scripts.notebooks.base_components:Saved policy params separately: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/checkpoints/grpo_training/grpo_full_minimize_20250728_163157/policy_params.pkl\n",
      "INFO:scripts.notebooks.base_components:Saved checkpoint: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/checkpoints/grpo_training/grpo_full_minimize_20250728_163157\n",
      "INFO:scripts.notebooks.base_components:Optimization: MINIMIZE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saving Checkpoint with Metadata\n",
      "==================================================\n",
      "‚úÖ Extracted model parameters from trainer\n",
      "\n",
      "‚úÖ Checkpoint saved successfully!\n",
      "üìÅ Location: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/checkpoints/grpo_training/grpo_full_minimize_20250728_163157\n",
      "üìã Name: grpo_full_minimize_20250728_163157\n",
      "üìã Includes: Model parameters, config, and metrics\n",
      "üîÑ Policy params saved separately: policy_params.pkl\n",
      "\n",
      "üìä Training Summary:\n",
      "  Mode: FULL\n",
      "  Optimization: MINIMIZE\n",
      "  Duration: 44.5 minutes\n",
      "  Episodes: 512\n",
      "  Success: Yes\n",
      "  Final target value: -0.8789 (‚Üì better)\n",
      "\n",
      "üí° Checkpoint name stored in variable: TRAINED_CHECKPOINT\n",
      "   Use this in evaluation notebook: 'grpo_full_minimize_20250728_163157'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cell 6: Save checkpoint with complete metadata\n",
    "\n",
    "This cell saves the trained model with all necessary metadata\n",
    "for later evaluation and comparison.\n",
    "\"\"\"\n",
    "from omegaconf import OmegaConf\n",
    "print(\"üíæ Saving Checkpoint with Metadata\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Generate checkpoint name\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "opt_direction = optimization_config.direction.lower()\n",
    "checkpoint_name = f\"grpo_{TRAINING_MODE.lower()}_{opt_direction}_{timestamp}\"\n",
    "\n",
    "# Extract actual model parameters from trainer\n",
    "try:\n",
    "    checkpoint_data = {\n",
    "        'policy_params': trainer.policy_params,\n",
    "        'policy_config': {\n",
    "            'architecture': OmegaConf.to_container(config.training.architecture),\n",
    "            'state_config': OmegaConf.to_container(config.training.state_config),\n",
    "            'grpo_config': OmegaConf.to_container(config.training.grpo_config)\n",
    "        },\n",
    "        'training_metrics': training_metrics,\n",
    "        'optimization_config': optimization_config.__dict__\n",
    "    }\n",
    "    print(f\"‚úÖ Extracted model parameters from trainer\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Warning: Could not extract model parameters: {e}\")\n",
    "    checkpoint_data = None\n",
    "\n",
    "# Create checkpoint metadata\n",
    "metadata = CheckpointMetadata(\n",
    "    name=checkpoint_name,\n",
    "    path=checkpoint_dir / checkpoint_name,\n",
    "    optimization_config=optimization_config,\n",
    "    training_config={\n",
    "        'mode': TRAINING_MODE,\n",
    "        'objective': OPTIMIZATION_OBJECTIVE,\n",
    "        'config': OmegaConf.to_container(config.training),\n",
    "        'reward_weights': dict(config.training.reward_weights),\n",
    "        'scm_config': OmegaConf.to_container(config.experiment.scm_generation)\n",
    "    },\n",
    "    training_results={\n",
    "        'duration_minutes': training_metrics.get('duration_minutes', 0),\n",
    "        'final_performance': performance if 'performance' in locals() else {},\n",
    "        'episodes_completed': total_episodes if not training_metrics.get('interrupted', False) else starting_episode,\n",
    "        'success': not training_metrics.get('interrupted', False)\n",
    "    },\n",
    "    timestamp=timestamp\n",
    ")\n",
    "\n",
    "# Save checkpoint\n",
    "try:\n",
    "    final_checkpoint_path = checkpoint_manager.save_checkpoint(\n",
    "        checkpoint_data=checkpoint_data,\n",
    "        metadata=metadata,\n",
    "        checkpoint_name=checkpoint_name\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ Checkpoint saved successfully!\")\n",
    "    print(f\"üìÅ Location: {final_checkpoint_path}\")\n",
    "    print(f\"üìã Name: {checkpoint_name}\")\n",
    "    if checkpoint_data is not None:\n",
    "        print(f\"üìã Includes: Model parameters, config, and metrics\")\n",
    "        print(f\"üîÑ Policy params saved separately: policy_params.pkl\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Warning: Only metadata saved (no model parameters)\")\n",
    "    \n",
    "    # Display summary\n",
    "    print(f\"\\nüìä Training Summary:\")\n",
    "    print(f\"  Mode: {TRAINING_MODE}\")\n",
    "    print(f\"  Optimization: {optimization_config.direction}\")\n",
    "    print(f\"  Duration: {metadata.training_results['duration_minutes']:.1f} minutes\")\n",
    "    print(f\"  Episodes: {metadata.training_results['episodes_completed']}\")\n",
    "    print(f\"  Success: {'Yes' if metadata.training_results['success'] else 'No (interrupted)'}\")\n",
    "    \n",
    "    if 'final_reward' in performance:\n",
    "        final_value = performance['final_reward']\n",
    "        if optimization_config.is_minimizing:\n",
    "            final_value = optimization_config.convert_from_maximization(final_value)\n",
    "        print(f\"  Final target value: {optimization_config.format_improvement(final_value)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    raise NotebookError(f\"Failed to save checkpoint: {e}\")\n",
    "\n",
    "# Store checkpoint name for easy access\n",
    "TRAINED_CHECKPOINT = checkpoint_name\n",
    "print(f\"\\nüí° Checkpoint name stored in variable: TRAINED_CHECKPOINT\")\n",
    "print(f\"   Use this in evaluation notebook: '{TRAINED_CHECKPOINT}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "**What we've accomplished:**\n",
    "1. ‚úÖ Configured training with explicit optimization direction\n",
    "2. ‚úÖ Trained GRPO policy with correct reward signals\n",
    "3. ‚úÖ Saved checkpoint with complete metadata\n",
    "4. ‚úÖ Validated policy behavior\n",
    "\n",
    "**Key improvements over original notebook:**\n",
    "- No silent failures - explicit errors when things go wrong\n",
    "- Independent cells - can resume training or load checkpoints\n",
    "- Optimization direction support - correctly handles minimization like PARENT_SCALE\n",
    "- Clean checkpoint management - all metadata preserved\n",
    "\n",
    "**Next steps:**\n",
    "1. Use `grpo_evaluation_modular.ipynb` to evaluate this checkpoint\n",
    "2. Compare minimization vs maximization policies\n",
    "3. Analyze how optimization direction affects performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Phase 2 Active Learning - Next Steps\n",
      "==================================================\n",
      "\n",
      "Your trained GRPO policy is ready for Phase 2 active learning!\n",
      "Checkpoint: grpo_full_minimize_20250728_163157\n",
      "\n",
      "üìö What is Phase 2?\n",
      "Phase 2 combines your trained GRPO policy with an active learning surrogate:\n",
      "  ‚Ä¢ Phase 1 (just completed): GRPO policy learns good intervention strategies\n",
      "  ‚Ä¢ Phase 2 (optional next): Use GRPO to guide active structure discovery\n",
      "\n",
      "üöÄ To run Phase 2 evaluation:\n",
      "1. Open grpo_evaluation_modular.ipynb\n",
      "2. Set EVALUATION_MODE = 'PHASE2_ACTIVE_LEARNING'\n",
      "3. Use checkpoint: 'grpo_full_minimize_20250728_163157'\n",
      "\n",
      "üîÑ Phase 2 Benefits:\n",
      "  ‚Ä¢ Better structure learning: Active surrogate discovers true causal structure\n",
      "  ‚Ä¢ Guided exploration: GRPO policy provides intelligent intervention selection\n",
      "  ‚Ä¢ Measurable progress: Track F1/SHD improvements over time\n",
      "\n",
      "üìä Comparison Options:\n",
      "  ‚Ä¢ GRPO + Bootstrap (Phase 1 only) - what you just trained\n",
      "  ‚Ä¢ GRPO + Active Learning (Phase 2) - enhanced structure discovery\n",
      "  ‚Ä¢ Random + Active Learning - baseline for comparison\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cell 7: Phase 2 Active Learning Information\n",
    "\n",
    "This trained GRPO policy can now be used for Phase 2 active learning.\n",
    "\"\"\"\n",
    "print(\"üéØ Phase 2 Active Learning - Next Steps\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nYour trained GRPO policy is ready for Phase 2 active learning!\")\n",
    "print(f\"Checkpoint: {TRAINED_CHECKPOINT}\")\n",
    "\n",
    "print(f\"\\nüìö What is Phase 2?\")\n",
    "print(f\"Phase 2 combines your trained GRPO policy with an active learning surrogate:\")\n",
    "print(f\"  ‚Ä¢ Phase 1 (just completed): GRPO policy learns good intervention strategies\")\n",
    "print(f\"  ‚Ä¢ Phase 2 (optional next): Use GRPO to guide active structure discovery\")\n",
    "\n",
    "print(f\"\\nüöÄ To run Phase 2 evaluation:\")\n",
    "print(f\"1. Open grpo_evaluation_modular.ipynb\")\n",
    "print(f\"2. Set EVALUATION_MODE = 'PHASE2_ACTIVE_LEARNING'\")\n",
    "print(f\"3. Use checkpoint: '{TRAINED_CHECKPOINT}'\")\n",
    "\n",
    "print(f\"\\nüîÑ Phase 2 Benefits:\")\n",
    "print(f\"  ‚Ä¢ Better structure learning: Active surrogate discovers true causal structure\")\n",
    "print(f\"  ‚Ä¢ Guided exploration: GRPO policy provides intelligent intervention selection\")\n",
    "print(f\"  ‚Ä¢ Measurable progress: Track F1/SHD improvements over time\")\n",
    "\n",
    "print(f\"\\nüìä Comparison Options:\")\n",
    "print(f\"  ‚Ä¢ GRPO + Bootstrap (Phase 1 only) - what you just trained\")\n",
    "print(f\"  ‚Ä¢ GRPO + Active Learning (Phase 2) - enhanced structure discovery\")\n",
    "print(f\"  ‚Ä¢ Random + Active Learning - baseline for comparison\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal-bayes-opt-9Aj1r1ec-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
