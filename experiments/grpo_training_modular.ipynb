{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRPO Training Pipeline - Modular Version\n",
    "\n",
    "**Purpose**: Train GRPO policies with explicit optimization direction support and modular execution.\n",
    "\n",
    "**Key Features**:\n",
    "- ‚úÖ **No silent failures** - explicit errors when things go wrong\n",
    "- ‚úÖ **Independent cells** - run any cell with checkpoint support\n",
    "- ‚úÖ **Optimization direction** - support both MINIMIZE and MAXIMIZE\n",
    "- ‚úÖ **Clean checkpoint management** - save/load with full metadata\n",
    "- ‚úÖ **Consistent with PARENT_SCALE** - correct handling of minimization objective\n",
    "\n",
    "**Workflow**:\n",
    "1. Configure training parameters and optimization direction\n",
    "2. Load existing checkpoint OR initialize new training\n",
    "3. Generate or load training SCMs\n",
    "4. Train with appropriate reward signals\n",
    "5. Save checkpoint with complete metadata\n",
    "6. Quick validation with correct metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2025-07-23 10:07:34,087:jax._src.xla_bridge:749: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: dlopen(libtpu.so, 0x0001): tried: 'libtpu.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OSlibtpu.so' (no such file), '/opt/homebrew/lib/libtpu.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/lib/libtpu.so' (no such file), '/usr/lib/libtpu.so' (no such file, not in dyld cache), 'libtpu.so' (no such file)\n",
      "[2025-07-23 10:07:34,087][jax._src.xla_bridge][INFO] - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: dlopen(libtpu.so, 0x0001): tried: 'libtpu.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OSlibtpu.so' (no such file), '/opt/homebrew/lib/libtpu.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/lib/libtpu.so' (no such file), '/usr/lib/libtpu.so' (no such file, not in dyld cache), 'libtpu.so' (no such file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment Setup Complete\n",
      "üìÅ Project root: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt\n",
      "üîß JAX devices: [CpuDevice(id=0)]\n",
      "üîß JAX backend: cpu\n",
      "üìÖ Date: 2025-07-23 10:07:34\n",
      "\n",
      "üìÅ Checkpoint directory: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/checkpoints/grpo_training\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Cell 1: Import base components and configure environment\n",
    "\n",
    "This cell can be run independently at any time.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent if Path.cwd().name == \"experiments\" else Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import base components\n",
    "from scripts.notebooks.base_components import (\n",
    "    NotebookError, CheckpointManager, SCMGenerator, \n",
    "    OptimizationConfig, CheckpointMetadata, validate_environment,\n",
    "    format_results_summary\n",
    ")\n",
    "from scripts.notebooks.config_templates import (\n",
    "    create_training_config, TRAINING_MODES, OBJECTIVE_CONFIGS,\n",
    "    get_quick_minimize_config, get_quick_maximize_config\n",
    ")\n",
    "\n",
    "# Core imports\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as random\n",
    "import numpy as onp\n",
    "import pyrsistent as pyr\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Validate environment\n",
    "try:\n",
    "    env_info = validate_environment()\n",
    "    print(\"‚úÖ Environment Setup Complete\")\n",
    "    print(f\"üìÅ Project root: {project_root}\")\n",
    "    print(f\"üîß JAX devices: {env_info['jax_devices']}\")\n",
    "    print(f\"üîß JAX backend: {env_info['jax_backend']}\")\n",
    "    print(f\"üìÖ Date: {env_info['timestamp']}\")\n",
    "except Exception as e:\n",
    "    raise NotebookError(f\"Environment validation failed: {e}\")\n",
    "\n",
    "# Initialize checkpoint manager\n",
    "checkpoint_dir = project_root / \"checkpoints\" / \"grpo_training\"\n",
    "checkpoint_manager = CheckpointManager(checkpoint_dir)\n",
    "print(f\"\\nüìÅ Checkpoint directory: {checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Training Configuration\n",
      "==================================================\n",
      "Mode: QUICK - Fast testing and development\n",
      "Objective: TARGET_MINIMIZE - Minimize target variable (like PARENT_SCALE)\n",
      "Optimization: MINIMIZE\n",
      "Random seed: 42\n",
      "\n",
      "Training parameters:\n",
      "  Total episodes: 96\n",
      "  Episode length: 8\n",
      "  Learning rate: 0.001\n",
      "  Number of SCMs: 32\n",
      "\n",
      "Reward weights:\n",
      "  optimization: 0.8\n",
      "  discovery: 0.1\n",
      "  efficiency: 0.1\n",
      "\n",
      "üöÄ Will train from scratch\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cell 2: Configure training parameters\n",
    "\n",
    "Choose training mode and optimization objective.\n",
    "This cell defines what kind of training will be performed.\n",
    "\"\"\"\n",
    "\n",
    "# SELECT TRAINING CONFIGURATION\n",
    "TRAINING_MODE = \"QUICK\"  # Options: \"QUICK\", \"STANDARD\", \"FULL\", \"PRECISION\"\n",
    "OPTIMIZATION_OBJECTIVE = \"TARGET_MINIMIZE\"  # Options: \"TARGET_MINIMIZE\", \"TARGET_MAXIMIZE\", \"STRUCTURE_FOCUSED\", \"BALANCED\"\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Optional: Load from existing checkpoint (set to None to train from scratch)\n",
    "RESUME_FROM_CHECKPOINT = None  # Or path like \"checkpoints/grpo_training/grpo_minimize_20250722_120000\"\n",
    "\n",
    "# Create configuration\n",
    "try:\n",
    "    config = create_training_config(\n",
    "        mode=TRAINING_MODE,\n",
    "        objective=OPTIMIZATION_OBJECTIVE,\n",
    "        random_seed=RANDOM_SEED,\n",
    "        checkpoint_dir=str(checkpoint_dir)\n",
    "    )\n",
    "    \n",
    "    # Create optimization config\n",
    "    optimization_config = OptimizationConfig(\n",
    "        direction=config.optimization.direction,\n",
    "        target_baseline=config.optimization.target_baseline\n",
    "    )\n",
    "    \n",
    "    print(\"üéØ Training Configuration\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Mode: {TRAINING_MODE} - {TRAINING_MODES[TRAINING_MODE].description}\")\n",
    "    print(f\"Objective: {OPTIMIZATION_OBJECTIVE} - {OBJECTIVE_CONFIGS[OPTIMIZATION_OBJECTIVE].description}\")\n",
    "    print(f\"Optimization: {optimization_config.direction}\")\n",
    "    print(f\"Random seed: {RANDOM_SEED}\")\n",
    "    print(f\"\\nTraining parameters:\")\n",
    "    print(f\"  Total episodes: {config.training.n_episodes}\")\n",
    "    print(f\"  Episode length: {config.training.episode_length}\")\n",
    "    print(f\"  Learning rate: {config.training.learning_rate}\")\n",
    "    print(f\"  Number of SCMs: {config.experiment.scm_generation.num_scms}\")  # Fixed path\n",
    "    print(f\"\\nReward weights:\")\n",
    "    for component, weight in config.training.reward_weights.items():\n",
    "        print(f\"  {component}: {weight}\")\n",
    "    \n",
    "    if RESUME_FROM_CHECKPOINT:\n",
    "        print(f\"\\nüîÑ Will resume from: {RESUME_FROM_CHECKPOINT}\")\n",
    "    else:\n",
    "        print(f\"\\nüöÄ Will train from scratch\")\n",
    "        \n",
    "except Exception as e:\n",
    "    raise NotebookError(f\"Failed to create configuration: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize or Load Training State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-23 10:07:36,369][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 3 variables, 2 edges, target='X1'\n",
      "[2025-07-23 10:07:36,369][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated fork SCM: 3 vars, 2 edges, target=X1\n",
      "[2025-07-23 10:07:36,383][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 3 variables, 2 edges, target='X2'\n",
      "[2025-07-23 10:07:36,383][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated chain SCM: 3 vars, 2 edges, target=X2\n",
      "[2025-07-23 10:07:36,385][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 3 variables, 2 edges, target='X1'\n",
      "[2025-07-23 10:07:36,385][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated collider SCM: 3 vars, 2 edges, target=X1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Initializing new training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-23 10:07:36,456][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 3 variables, 2 edges, target='X1'\n",
      "[2025-07-23 10:07:36,456][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated mixed SCM: 3 vars, 2 edges, target=X1\n",
      "[2025-07-23 10:07:36,471][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 4 variables, 3 edges, target='X2'\n",
      "[2025-07-23 10:07:36,471][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated fork SCM: 4 vars, 3 edges, target=X2\n",
      "[2025-07-23 10:07:36,473][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 4 variables, 3 edges, target='X3'\n",
      "[2025-07-23 10:07:36,474][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated chain SCM: 4 vars, 3 edges, target=X3\n",
      "[2025-07-23 10:07:36,475][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 4 variables, 3 edges, target='X2'\n",
      "[2025-07-23 10:07:36,475][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated collider SCM: 4 vars, 3 edges, target=X2\n",
      "[2025-07-23 10:07:36,477][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 4 variables, 3 edges, target='X2'\n",
      "[2025-07-23 10:07:36,477][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated mixed SCM: 4 vars, 3 edges, target=X2\n",
      "[2025-07-23 10:07:36,491][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 5 variables, 4 edges, target='X2'\n",
      "[2025-07-23 10:07:36,492][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated fork SCM: 5 vars, 4 edges, target=X2\n",
      "[2025-07-23 10:07:36,493][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 5 variables, 4 edges, target='X4'\n",
      "[2025-07-23 10:07:36,494][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated chain SCM: 5 vars, 4 edges, target=X4\n",
      "[2025-07-23 10:07:36,495][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 5 variables, 4 edges, target='X2'\n",
      "[2025-07-23 10:07:36,496][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated collider SCM: 5 vars, 4 edges, target=X2\n",
      "[2025-07-23 10:07:36,497][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 5 variables, 4 edges, target='X2'\n",
      "[2025-07-23 10:07:36,497][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated mixed SCM: 5 vars, 4 edges, target=X2\n",
      "[2025-07-23 10:07:36,499][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 6 variables, 5 edges, target='X3'\n",
      "[2025-07-23 10:07:36,499][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated fork SCM: 6 vars, 5 edges, target=X3\n",
      "[2025-07-23 10:07:36,501][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 6 variables, 5 edges, target='X5'\n",
      "[2025-07-23 10:07:36,501][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated chain SCM: 6 vars, 5 edges, target=X5\n",
      "[2025-07-23 10:07:36,503][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 6 variables, 5 edges, target='X3'\n",
      "[2025-07-23 10:07:36,503][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated collider SCM: 6 vars, 5 edges, target=X3\n",
      "[2025-07-23 10:07:36,505][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 6 variables, 5 edges, target='X4'\n",
      "[2025-07-23 10:07:36,505][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated mixed SCM: 6 vars, 5 edges, target=X4\n",
      "[2025-07-23 10:07:36,505][causal_bayes_opt.training.modular_trainer][INFO] - Created 16 variable SCMs for training\n",
      "[2025-07-23 10:07:41,466][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Using optimized GRPO config: group_size=32, interventions_per_state=4\n",
      "[2025-07-23 10:07:41,768][causal_bayes_opt.training.enriched_trainer][INFO] - Correct GRPO Config: group_size=32, lr=0.001000\n",
      "[2025-07-23 10:07:41,769][causal_bayes_opt.training.enriched_trainer][INFO] - Correct GRPO Config: entropy_coeff=0.010, clip_ratio=0.20\n",
      "[2025-07-23 10:07:41,769][causal_bayes_opt.training.enriched_trainer][INFO] - Initialized trainer with 6 max variables\n",
      "[2025-07-23 10:07:41,770][causal_bayes_opt.training.enriched_trainer][INFO] - GRPO group size: 32, update frequency: 1 episodes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Trainer initialized successfully\n",
      "  Optimization: MINIMIZE\n",
      "  Surrogate integration: Enabled\n",
      "\n",
      "‚úÖ Training state ready\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cell 3: Initialize new training or load from checkpoint\n",
    "\n",
    "This cell handles checkpoint loading and training initialization.\n",
    "Can be run independently to load a specific checkpoint.\n",
    "\"\"\"\n",
    "\n",
    "# Import trainer and related modules\n",
    "try:\n",
    "    from causal_bayes_opt.training.enriched_trainer import EnrichedGRPOTrainer\n",
    "    from causal_bayes_opt.surrogate.bootstrap import create_bootstrap_surrogate_features\n",
    "    from causal_bayes_opt.surrogate.phase_manager import PhaseConfig, BootstrapConfig\n",
    "except ImportError as e:\n",
    "    raise NotebookError(f\"Failed to import training modules: {e}\")\n",
    "\n",
    "# Production phase configuration\n",
    "PRODUCTION_PHASE_CONFIG = PhaseConfig(\n",
    "    bootstrap_steps=100,\n",
    "    transition_steps=50,\n",
    "    exploration_noise_start=0.5,\n",
    "    exploration_noise_end=0.1,\n",
    "    transition_schedule=\"linear\"\n",
    ")\n",
    "\n",
    "PRODUCTION_BOOTSTRAP_CONFIG = BootstrapConfig(\n",
    "    structure_encoding_dim=128,\n",
    "    use_graph_distance=True,\n",
    "    use_structural_priors=True,\n",
    "    noise_schedule=\"exponential_decay\",\n",
    "    min_noise_factor=0.1\n",
    ")\n",
    "\n",
    "# Update config with production settings\n",
    "config.surrogate_integration = {\n",
    "    'enabled': True,\n",
    "    'phase_config': {\n",
    "        'bootstrap_steps': PRODUCTION_PHASE_CONFIG.bootstrap_steps,\n",
    "        'transition_steps': PRODUCTION_PHASE_CONFIG.transition_steps,\n",
    "        'exploration_noise_start': PRODUCTION_PHASE_CONFIG.exploration_noise_start,\n",
    "        'exploration_noise_end': PRODUCTION_PHASE_CONFIG.exploration_noise_end,\n",
    "        'transition_schedule': PRODUCTION_PHASE_CONFIG.transition_schedule\n",
    "    },\n",
    "    'bootstrap_config': {\n",
    "        'structure_encoding_dim': PRODUCTION_BOOTSTRAP_CONFIG.structure_encoding_dim,\n",
    "        'use_graph_distance': PRODUCTION_BOOTSTRAP_CONFIG.use_graph_distance,\n",
    "        'use_structural_priors': PRODUCTION_BOOTSTRAP_CONFIG.use_structural_priors,\n",
    "        'noise_schedule': PRODUCTION_BOOTSTRAP_CONFIG.noise_schedule,\n",
    "        'min_noise_factor': PRODUCTION_BOOTSTRAP_CONFIG.min_noise_factor\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize trainer state\n",
    "trainer = None\n",
    "starting_episode = 0\n",
    "checkpoint_metadata = None\n",
    "\n",
    "if RESUME_FROM_CHECKPOINT:\n",
    "    print(f\"üì• Loading checkpoint: {RESUME_FROM_CHECKPOINT}\")\n",
    "    try:\n",
    "        checkpoint_data, checkpoint_metadata = checkpoint_manager.load_checkpoint(RESUME_FROM_CHECKPOINT)\n",
    "        \n",
    "        # Validate compatibility\n",
    "        if checkpoint_metadata.optimization_config.direction != optimization_config.direction:\n",
    "            raise NotebookError(\n",
    "                f\"Optimization direction mismatch! \"\n",
    "                f\"Checkpoint: {checkpoint_metadata.optimization_config.direction}, \"\n",
    "                f\"Config: {optimization_config.direction}\"\n",
    "            )\n",
    "        \n",
    "        print(f\"‚úÖ Loaded checkpoint: {checkpoint_metadata.name}\")\n",
    "        print(f\"  Training mode: {checkpoint_metadata.training_config.get('mode', 'unknown')}\")\n",
    "        print(f\"  Optimization: {checkpoint_metadata.optimization_config.direction}\")\n",
    "        print(f\"  Timestamp: {checkpoint_metadata.timestamp}\")\n",
    "        \n",
    "        # TODO: Actually load trainer state from checkpoint_data\n",
    "        # For now, we'll initialize a new trainer\n",
    "        trainer = EnrichedGRPOTrainer(config=config)\n",
    "        starting_episode = checkpoint_metadata.training_results.get('episodes_completed', 0)\n",
    "        \n",
    "        print(f\"  Starting from episode: {starting_episode}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise NotebookError(f\"Failed to load checkpoint: {e}\")\n",
    "else:\n",
    "    print(\"üöÄ Initializing new training\")\n",
    "    try:\n",
    "        # Add optimization direction to config\n",
    "        config.optimization = optimization_config.__dict__\n",
    "        \n",
    "        # Initialize trainer\n",
    "        trainer = EnrichedGRPOTrainer(config=config)\n",
    "        \n",
    "        print(\"‚úÖ Trainer initialized successfully\")\n",
    "        print(f\"  Optimization: {optimization_config.direction}\")\n",
    "        print(f\"  Surrogate integration: {'Enabled' if config.surrogate_integration.enabled else 'Disabled'}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise NotebookError(f\"Failed to initialize trainer: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ Training state ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate or Load Training SCMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-23 10:07:41,778][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 3 variables, 2 edges, target='X1'\n",
      "[2025-07-23 10:07:41,779][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated fork SCM: 3 vars, 2 edges, target=X1\n",
      "[2025-07-23 10:07:41,780][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 3 variables, 2 edges, target='X1'\n",
      "[2025-07-23 10:07:41,781][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated fork SCM: 3 vars, 2 edges, target=X1\n",
      "[2025-07-23 10:07:41,782][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 4 variables, 3 edges, target='X2'\n",
      "[2025-07-23 10:07:41,782][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated fork SCM: 4 vars, 3 edges, target=X2\n",
      "[2025-07-23 10:07:41,784][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 4 variables, 3 edges, target='X2'\n",
      "[2025-07-23 10:07:41,784][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated fork SCM: 4 vars, 3 edges, target=X2\n",
      "[2025-07-23 10:07:41,786][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 5 variables, 4 edges, target='X2'\n",
      "[2025-07-23 10:07:41,786][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated fork SCM: 5 vars, 4 edges, target=X2\n",
      "[2025-07-23 10:07:41,788][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 5 variables, 4 edges, target='X2'\n",
      "[2025-07-23 10:07:41,788][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated fork SCM: 5 vars, 4 edges, target=X2\n",
      "[2025-07-23 10:07:41,790][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 6 variables, 5 edges, target='X3'\n",
      "[2025-07-23 10:07:41,790][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated fork SCM: 6 vars, 5 edges, target=X3\n",
      "[2025-07-23 10:07:41,792][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 6 variables, 5 edges, target='X3'\n",
      "[2025-07-23 10:07:41,792][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated fork SCM: 6 vars, 5 edges, target=X3\n",
      "[2025-07-23 10:07:41,794][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 3 variables, 2 edges, target='X2'\n",
      "[2025-07-23 10:07:41,794][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated chain SCM: 3 vars, 2 edges, target=X2\n",
      "[2025-07-23 10:07:41,795][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 3 variables, 2 edges, target='X2'\n",
      "[2025-07-23 10:07:41,796][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated chain SCM: 3 vars, 2 edges, target=X2\n",
      "[2025-07-23 10:07:41,797][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 4 variables, 3 edges, target='X3'\n",
      "[2025-07-23 10:07:41,798][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated chain SCM: 4 vars, 3 edges, target=X3\n",
      "[2025-07-23 10:07:41,799][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 4 variables, 3 edges, target='X3'\n",
      "[2025-07-23 10:07:41,799][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated chain SCM: 4 vars, 3 edges, target=X3\n",
      "[2025-07-23 10:07:41,801][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 5 variables, 4 edges, target='X4'\n",
      "[2025-07-23 10:07:41,801][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated chain SCM: 5 vars, 4 edges, target=X4\n",
      "[2025-07-23 10:07:41,803][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 5 variables, 4 edges, target='X4'\n",
      "[2025-07-23 10:07:41,803][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated chain SCM: 5 vars, 4 edges, target=X4\n",
      "[2025-07-23 10:07:41,805][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 6 variables, 5 edges, target='X5'\n",
      "[2025-07-23 10:07:41,805][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated chain SCM: 6 vars, 5 edges, target=X5\n",
      "[2025-07-23 10:07:41,807][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 6 variables, 5 edges, target='X5'\n",
      "[2025-07-23 10:07:41,807][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated chain SCM: 6 vars, 5 edges, target=X5\n",
      "[2025-07-23 10:07:41,809][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 3 variables, 2 edges, target='X1'\n",
      "[2025-07-23 10:07:41,809][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated collider SCM: 3 vars, 2 edges, target=X1\n",
      "[2025-07-23 10:07:41,810][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 3 variables, 2 edges, target='X1'\n",
      "[2025-07-23 10:07:41,811][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated collider SCM: 3 vars, 2 edges, target=X1\n",
      "[2025-07-23 10:07:41,812][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 4 variables, 3 edges, target='X2'\n",
      "[2025-07-23 10:07:41,812][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated collider SCM: 4 vars, 3 edges, target=X2\n",
      "[2025-07-23 10:07:41,814][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 4 variables, 3 edges, target='X2'\n",
      "[2025-07-23 10:07:41,814][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated collider SCM: 4 vars, 3 edges, target=X2\n",
      "[2025-07-23 10:07:41,816][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 5 variables, 4 edges, target='X2'\n",
      "[2025-07-23 10:07:41,816][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated collider SCM: 5 vars, 4 edges, target=X2\n",
      "[2025-07-23 10:07:41,818][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 5 variables, 4 edges, target='X2'\n",
      "[2025-07-23 10:07:41,818][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated collider SCM: 5 vars, 4 edges, target=X2\n",
      "[2025-07-23 10:07:41,820][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 6 variables, 5 edges, target='X3'\n",
      "[2025-07-23 10:07:41,820][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated collider SCM: 6 vars, 5 edges, target=X3\n",
      "[2025-07-23 10:07:41,822][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 6 variables, 5 edges, target='X3'\n",
      "[2025-07-23 10:07:41,822][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated collider SCM: 6 vars, 5 edges, target=X3\n",
      "[2025-07-23 10:07:41,823][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 3 variables, 2 edges, target='X1'\n",
      "[2025-07-23 10:07:41,824][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated mixed SCM: 3 vars, 2 edges, target=X1\n",
      "[2025-07-23 10:07:41,825][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 3 variables, 2 edges, target='X2'\n",
      "[2025-07-23 10:07:41,826][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated mixed SCM: 3 vars, 2 edges, target=X2\n",
      "[2025-07-23 10:07:41,827][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 4 variables, 3 edges, target='X3'\n",
      "[2025-07-23 10:07:41,827][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated mixed SCM: 4 vars, 3 edges, target=X3\n",
      "[2025-07-23 10:07:41,829][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 4 variables, 3 edges, target='X2'\n",
      "[2025-07-23 10:07:41,829][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated mixed SCM: 4 vars, 3 edges, target=X2\n",
      "[2025-07-23 10:07:41,831][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 5 variables, 4 edges, target='X2'\n",
      "[2025-07-23 10:07:41,831][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated mixed SCM: 5 vars, 4 edges, target=X2\n",
      "[2025-07-23 10:07:41,833][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 5 variables, 4 edges, target='X1'\n",
      "[2025-07-23 10:07:41,833][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated mixed SCM: 5 vars, 4 edges, target=X1\n",
      "[2025-07-23 10:07:41,835][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 6 variables, 5 edges, target='X3'\n",
      "[2025-07-23 10:07:41,835][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated mixed SCM: 6 vars, 5 edges, target=X3\n",
      "[2025-07-23 10:07:41,837][causal_bayes_opt.experiments.test_scms][INFO] - Created linear SCM with 6 variables, 5 edges, target='X3'\n",
      "[2025-07-23 10:07:41,837][causal_bayes_opt.experiments.variable_scm_factory][INFO] - Generated mixed SCM: 6 vars, 5 edges, target=X3\n",
      "[2025-07-23 10:07:41,837][scripts.notebooks.base_components][INFO] - Generated 32 SCMs\n",
      "[2025-07-23 10:07:41,838][scripts.notebooks.base_components][INFO] - Distribution: {'structure_types': {'fork': 8, 'chain': 8, 'collider': 8, 'mixed': 8}, 'variable_counts': {3: 8, 4: 8, 5: 8, 6: 8}, 'total': 32}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ Generating Training SCMs\n",
      "==================================================\n",
      "\n",
      "‚úÖ Generated 32 training SCMs\n",
      "\n",
      "üìä SCM Distribution:\n",
      "  Structure types: {'fork': 8, 'chain': 8, 'collider': 8, 'mixed': 8}\n",
      "  Variable counts: {3: 8, 4: 8, 5: 8, 6: 8}\n",
      "\n",
      "üìà Training schedule:\n",
      "  Episodes per SCM: 3\n",
      "  Total episodes: 96\n",
      "\n",
      "üíæ Saved SCM metadata to: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/checkpoints/grpo_training/training_scms/scms_QUICK_42.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cell 4: Generate training SCMs\n",
    "\n",
    "This cell generates the SCMs for training.\n",
    "Can be run independently to regenerate SCMs.\n",
    "\"\"\"\n",
    "\n",
    "print(\"üî¨ Generating Training SCMs\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Initialize SCM generator\n",
    "scm_generator = SCMGenerator()\n",
    "\n",
    "# Generate SCMs\n",
    "try:\n",
    "    training_scms, scm_metadata = scm_generator.generate_balanced_scms(\n",
    "        num_scms=config.experiment.scm_generation.num_scms,\n",
    "        variable_range=tuple(config.experiment.scm_generation.variable_range),\n",
    "        structure_types=config.experiment.scm_generation.structure_types,\n",
    "        seed=RANDOM_SEED\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ Generated {len(training_scms)} training SCMs\")\n",
    "    \n",
    "    # Analyze distribution\n",
    "    distribution = scm_generator._summarize_distribution(scm_metadata)\n",
    "    print(f\"\\nüìä SCM Distribution:\")\n",
    "    print(f\"  Structure types: {distribution['structure_types']}\")\n",
    "    print(f\"  Variable counts: {distribution['variable_counts']}\")\n",
    "    \n",
    "    # Calculate total episodes\n",
    "    episodes_per_scm = config.training.n_episodes // len(training_scms)\n",
    "    total_episodes = len(training_scms) * episodes_per_scm\n",
    "    print(f\"\\nüìà Training schedule:\")\n",
    "    print(f\"  Episodes per SCM: {episodes_per_scm}\")\n",
    "    print(f\"  Total episodes: {total_episodes}\")\n",
    "    \n",
    "    # Store in config for trainer\n",
    "    config.training.n_episodes = total_episodes\n",
    "    \n",
    "except Exception as e:\n",
    "    raise NotebookError(f\"Failed to generate SCMs: {e}\")\n",
    "\n",
    "# Optional: Save SCMs for reproducibility\n",
    "scm_save_path = checkpoint_dir / \"training_scms\" / f\"scms_{TRAINING_MODE}_{RANDOM_SEED}.json\"\n",
    "scm_save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save metadata only (SCMs are too complex to serialize directly)\n",
    "with open(scm_save_path, 'w') as f:\n",
    "    json.dump({\n",
    "        'metadata': scm_metadata,\n",
    "        'config': {\n",
    "            'num_scms': len(training_scms),\n",
    "            'seed': RANDOM_SEED,\n",
    "            'variable_range': list(config.experiment.scm_generation.variable_range),\n",
    "            'structure_types': list(config.experiment.scm_generation.structure_types)\n",
    "        }\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"\\nüíæ Saved SCM metadata to: {scm_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train GRPO Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-23 10:07:41,846][causal_bayes_opt.training.enriched_trainer][INFO] - Starting enriched GRPO training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting GRPO Policy Training\n",
      "======================================================================\n",
      "üîß Training mode: QUICK\n",
      "üéØ Optimization: MINIMIZE\n",
      "üìä Total episodes: 96\n",
      "‚öñÔ∏è Reward weights: {'optimization': 0.8, 'discovery': 0.1, 'efficiency': 0.1}\n",
      "‚úÖ Surrogate integration: ACTIVE\n",
      "======================================================================\n",
      "\n",
      "üèÉ Starting Training Loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-23 10:08:05,610][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000023709518\n",
      "[2025-07-23 10:08:05,755][causal_bayes_opt.training.enriched_trainer][INFO] - Episode 0: reward=0.617, intervention_rate=1.000, scm=fork_3var, F1=0.000, P(Parents)=0.000, SHD=2\n",
      "[2025-07-23 10:08:05,861][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 10):\n",
      "[2025-07-23 10:08:05,862][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-7.99504128e-02 -1.00000000e+09]\n",
      "[2025-07-23 10:08:05,862][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "[2025-07-23 10:08:05,863][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:08:05,883][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:08:05,883][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.98\n",
      "[2025-07-23 10:08:05,883][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [1. 0.]\n",
      "[2025-07-23 10:08:05,884][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X2 (index 0)\n",
      "[2025-07-23 10:08:05,884][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:08:05,884][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.1808, Std: 1.2082\n",
      "[2025-07-23 10:08:05,885][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.49\n",
      "[2025-07-23 10:08:05,885][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 3.7480\n",
      "[2025-07-23 10:08:05,885][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 10):\n",
      "[2025-07-23 10:08:05,886][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (0, 3.7480460249806007)\n",
      "[2025-07-23 10:08:05,886][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X2'}\n",
      "[2025-07-23 10:08:05,886][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X2': 3.7480460249806007}\n",
      "[2025-07-23 10:08:05,887][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X1\n",
      "[2025-07-23 10:08:05,887][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3748046024980601}\n",
      "[2025-07-23 10:08:05,887][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.874805\n",
      "[2025-07-23 10:08:05,887][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.874805\n",
      "[2025-07-23 10:08:05,888][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:08:05,888][causal_bayes_opt.training.enriched_trainer][INFO] -   üí∞ HIGH REWARD: Policy achieved high reward (0.875) - good performance!\n",
      "[2025-07-23 10:08:07,632][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000004016585\n",
      "[2025-07-23 10:08:07,844][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 20):\n",
      "[2025-07-23 10:08:07,844][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-7.19403393e-02 -1.00000000e+09]\n",
      "[2025-07-23 10:08:07,844][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "[2025-07-23 10:08:07,845][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:08:07,847][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:08:07,847][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.97\n",
      "[2025-07-23 10:08:07,847][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [1. 0.]\n",
      "[2025-07-23 10:08:07,848][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X2 (index 0)\n",
      "[2025-07-23 10:08:07,848][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:08:07,848][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2288, Std: 1.2038\n",
      "[2025-07-23 10:08:07,848][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.49\n",
      "[2025-07-23 10:08:07,849][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -0.2725\n",
      "[2025-07-23 10:08:07,849][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 20):\n",
      "[2025-07-23 10:08:07,849][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (0, -0.27252331241813793)\n",
      "[2025-07-23 10:08:07,850][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X2'}\n",
      "[2025-07-23 10:08:07,850][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X2': -0.27252331241813793}\n",
      "[2025-07-23 10:08:07,850][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X1\n",
      "[2025-07-23 10:08:07,850][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.027252331241813796}\n",
      "[2025-07-23 10:08:07,851][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.527252\n",
      "[2025-07-23 10:08:07,851][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.527252\n",
      "[2025-07-23 10:08:07,851][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:08:09,511][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000041266723\n",
      "[2025-07-23 10:08:09,826][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 30):\n",
      "[2025-07-23 10:08:09,826][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-5.77440991e-02 -1.00000000e+09]\n",
      "[2025-07-23 10:08:09,826][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "[2025-07-23 10:08:09,827][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:08:09,829][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:08:09,829][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.95\n",
      "[2025-07-23 10:08:09,829][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [1. 0.]\n",
      "[2025-07-23 10:08:09,830][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X2 (index 0)\n",
      "[2025-07-23 10:08:09,830][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:08:09,830][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.1612, Std: 1.2090\n",
      "[2025-07-23 10:08:09,831][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.48\n",
      "[2025-07-23 10:08:09,831][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -1.5061\n",
      "[2025-07-23 10:08:09,831][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 30):\n",
      "[2025-07-23 10:08:09,832][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (0, -1.5060889037482672)\n",
      "[2025-07-23 10:08:09,832][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X2'}\n",
      "[2025-07-23 10:08:09,832][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X2': -1.5060889037482672}\n",
      "[2025-07-23 10:08:09,833][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X1\n",
      "[2025-07-23 10:08:09,833][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.15060889037482672}\n",
      "[2025-07-23 10:08:09,833][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.650609\n",
      "[2025-07-23 10:08:09,833][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.650609\n",
      "[2025-07-23 10:08:09,834][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:08:11,354][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000094162711\n",
      "[2025-07-23 10:08:11,767][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 40):\n",
      "[2025-07-23 10:08:11,768][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-8.07146573e-02 -1.00000000e+09]\n",
      "[2025-07-23 10:08:11,768][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "[2025-07-23 10:08:11,769][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:08:11,771][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:08:11,771][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.94\n",
      "[2025-07-23 10:08:11,771][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [1. 0.]\n",
      "[2025-07-23 10:08:11,772][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X2 (index 0)\n",
      "[2025-07-23 10:08:11,772][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:08:11,772][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.1809, Std: 1.2098\n",
      "[2025-07-23 10:08:11,772][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.48\n",
      "[2025-07-23 10:08:11,773][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 1.2790\n",
      "[2025-07-23 10:08:11,773][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 40):\n",
      "[2025-07-23 10:08:11,774][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (0, 1.2790026065581919)\n",
      "[2025-07-23 10:08:11,774][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X2'}\n",
      "[2025-07-23 10:08:11,774][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X2': 1.2790026065581919}\n",
      "[2025-07-23 10:08:11,774][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X1\n",
      "[2025-07-23 10:08:11,775][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.1279002606558192}\n",
      "[2025-07-23 10:08:11,775][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.627900\n",
      "[2025-07-23 10:08:11,776][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.627900\n",
      "[2025-07-23 10:08:11,776][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:08:13,217][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000143580652\n",
      "[2025-07-23 10:08:13,218][causal_bayes_opt.training.enriched_trainer][INFO] - Policy Learning Diagnostics (update 5):\n",
      "[2025-07-23 10:08:13,218][causal_bayes_opt.training.enriched_trainer][INFO] -   Action magnitudes: max=2.277215\n",
      "[2025-07-23 10:08:13,218][causal_bayes_opt.training.enriched_trainer][INFO] -   Mean reward: 0.678\n",
      "[2025-07-23 10:08:13,218][causal_bayes_opt.training.enriched_trainer][INFO] -   Policy param change: 0.00014358\n",
      "[2025-07-23 10:08:13,219][causal_bayes_opt.training.enriched_trainer][INFO] -   Parameter norm change: 0.00014358\n",
      "[2025-07-23 10:08:13,219][causal_bayes_opt.training.enriched_trainer][INFO] -   Rewards: min=0.610, max=0.728, group_baseline=0.678\n",
      "[2025-07-23 10:08:13,219][causal_bayes_opt.training.enriched_trainer][INFO] -   GRPO losses: policy=0.326363, entropy=-2.326892\n",
      "[2025-07-23 10:08:13,219][causal_bayes_opt.training.enriched_trainer][INFO] -   Gradient norm: 0.25399254\n",
      "[2025-07-23 10:08:13,220][causal_bayes_opt.training.enriched_trainer][INFO] -   Learning rate: 0.001000\n",
      "[2025-07-23 10:08:13,220][causal_bayes_opt.training.enriched_trainer][INFO] -   KL penalty: 0.000000, approx_kl: 2.837715\n",
      "[2025-07-23 10:08:15,115][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000202222973\n",
      "[2025-07-23 10:08:15,227][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 50):\n",
      "[2025-07-23 10:08:15,228][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -5.75226841e-02]\n",
      "[2025-07-23 10:08:15,228][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X1', 'X0'], Target: X2\n",
      "[2025-07-23 10:08:15,228][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:08:15,231][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:08:15,231][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.91\n",
      "[2025-07-23 10:08:15,231][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0. 1.]\n",
      "[2025-07-23 10:08:15,232][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X1 (index 1)\n",
      "[2025-07-23 10:08:15,232][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:08:15,232][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.1598, Std: 1.2095\n",
      "[2025-07-23 10:08:15,233][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.47\n",
      "[2025-07-23 10:08:15,233][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 2.1635\n",
      "[2025-07-23 10:08:15,233][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 50):\n",
      "[2025-07-23 10:08:15,233][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (1, 2.1634628331250436)\n",
      "[2025-07-23 10:08:15,234][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X1'}\n",
      "[2025-07-23 10:08:15,234][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X1': 2.1634628331250436}\n",
      "[2025-07-23 10:08:15,234][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:08:15,235][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.21634628331250438}\n",
      "[2025-07-23 10:08:15,235][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.716346\n",
      "[2025-07-23 10:08:15,235][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.716346\n",
      "[2025-07-23 10:08:15,235][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:08:16,975][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000236179267\n",
      "[2025-07-23 10:08:17,189][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 60):\n",
      "[2025-07-23 10:08:17,190][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -3.21613099e-02]\n",
      "[2025-07-23 10:08:17,190][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X1', 'X0'], Target: X2\n",
      "[2025-07-23 10:08:17,190][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:08:17,192][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:08:17,193][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.89\n",
      "[2025-07-23 10:08:17,193][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0. 1.]\n",
      "[2025-07-23 10:08:17,193][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X1 (index 1)\n",
      "[2025-07-23 10:08:17,193][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:08:17,194][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.1912, Std: 1.2136\n",
      "[2025-07-23 10:08:17,194][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.46\n",
      "[2025-07-23 10:08:17,194][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -2.3813\n",
      "[2025-07-23 10:08:17,195][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 60):\n",
      "[2025-07-23 10:08:17,195][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (1, -2.381334616028972)\n",
      "[2025-07-23 10:08:17,195][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X1'}\n",
      "[2025-07-23 10:08:17,196][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X1': -2.381334616028972}\n",
      "[2025-07-23 10:08:17,196][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:08:17,196][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.23813346160289722}\n",
      "[2025-07-23 10:08:17,196][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.738133\n",
      "[2025-07-23 10:08:17,197][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.738133\n",
      "[2025-07-23 10:08:17,197][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:08:18,891][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000260623120\n",
      "[2025-07-23 10:08:19,205][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 70):\n",
      "[2025-07-23 10:08:19,206][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -5.89867136e-02]\n",
      "[2025-07-23 10:08:19,206][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X1', 'X0'], Target: X2\n",
      "[2025-07-23 10:08:19,207][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:08:19,208][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:08:19,209][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.88\n",
      "[2025-07-23 10:08:19,209][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0. 1.]\n",
      "[2025-07-23 10:08:19,209][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X1 (index 1)\n",
      "[2025-07-23 10:08:19,209][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:08:19,210][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.1489, Std: 1.2252\n",
      "[2025-07-23 10:08:19,210][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.46\n",
      "[2025-07-23 10:08:19,210][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -0.7709\n",
      "[2025-07-23 10:08:19,211][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 70):\n",
      "[2025-07-23 10:08:19,211][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (1, -0.7709236387227035)\n",
      "[2025-07-23 10:08:19,211][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X1'}\n",
      "[2025-07-23 10:08:19,212][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X1': -0.7709236387227035}\n",
      "[2025-07-23 10:08:19,212][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:08:19,212][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.07709236387227036}\n",
      "[2025-07-23 10:08:19,213][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.577092\n",
      "[2025-07-23 10:08:19,213][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.577092\n",
      "[2025-07-23 10:08:19,213][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:08:20,899][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000261114680\n",
      "[2025-07-23 10:08:21,315][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 80):\n",
      "[2025-07-23 10:08:21,316][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -1.21741027e-01]\n",
      "[2025-07-23 10:08:21,316][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X1', 'X0'], Target: X2\n",
      "[2025-07-23 10:08:21,316][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:08:21,319][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:08:21,319][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.86\n",
      "[2025-07-23 10:08:21,319][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0. 1.]\n",
      "[2025-07-23 10:08:21,319][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X1 (index 1)\n",
      "[2025-07-23 10:08:21,320][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:08:21,320][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.1564, Std: 1.2170\n",
      "[2025-07-23 10:08:21,320][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.45\n",
      "[2025-07-23 10:08:21,321][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 1.4960\n",
      "[2025-07-23 10:08:21,321][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 80):\n",
      "[2025-07-23 10:08:21,321][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (1, 1.4960428748858154)\n",
      "[2025-07-23 10:08:21,322][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X1'}\n",
      "[2025-07-23 10:08:21,322][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X1': 1.4960428748858154}\n",
      "[2025-07-23 10:08:21,322][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:08:21,323][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.14960428748858154}\n",
      "[2025-07-23 10:08:21,323][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.649604\n",
      "[2025-07-23 10:08:21,323][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.649604\n",
      "[2025-07-23 10:08:21,323][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:08:22,763][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000277536554\n",
      "[2025-07-23 10:08:22,764][causal_bayes_opt.training.enriched_trainer][INFO] - Policy Learning Diagnostics (update 10):\n",
      "[2025-07-23 10:08:22,764][causal_bayes_opt.training.enriched_trainer][INFO] -   Action magnitudes: max=3.323395\n",
      "[2025-07-23 10:08:22,765][causal_bayes_opt.training.enriched_trainer][INFO] -   Mean reward: 0.616\n",
      "[2025-07-23 10:08:22,766][causal_bayes_opt.training.enriched_trainer][INFO] -   Policy param change: 0.00027754\n",
      "[2025-07-23 10:08:22,766][causal_bayes_opt.training.enriched_trainer][INFO] -   Parameter norm change: 0.00027754\n",
      "[2025-07-23 10:08:22,767][causal_bayes_opt.training.enriched_trainer][INFO] -   Rewards: min=0.502, max=0.832, group_baseline=0.616\n",
      "[2025-07-23 10:08:22,768][causal_bayes_opt.training.enriched_trainer][INFO] -   GRPO losses: policy=0.333640, entropy=-2.414673\n",
      "[2025-07-23 10:08:22,768][causal_bayes_opt.training.enriched_trainer][INFO] -   Gradient norm: 0.15810794\n",
      "[2025-07-23 10:08:22,768][causal_bayes_opt.training.enriched_trainer][INFO] -   Learning rate: 0.001000\n",
      "[2025-07-23 10:08:22,769][causal_bayes_opt.training.enriched_trainer][INFO] -   KL penalty: 0.000000, approx_kl: 2.694846\n",
      "[2025-07-23 10:08:24,692][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000290203590\n",
      "[2025-07-23 10:08:24,700][causal_bayes_opt.training.enriched_trainer][INFO] - Episode 10: reward=0.620, intervention_rate=1.000, scm=collider_3var, F1=0.000, P(Parents)=0.000, SHD=2\n",
      "[2025-07-23 10:08:24,805][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 90):\n",
      "[2025-07-23 10:08:24,805][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-8.83282902e-02 -1.00000000e+09]\n",
      "[2025-07-23 10:08:24,806][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "[2025-07-23 10:08:24,806][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:08:24,808][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:08:24,808][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.83\n",
      "[2025-07-23 10:08:24,809][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [1. 0.]\n",
      "[2025-07-23 10:08:24,809][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X2 (index 0)\n",
      "[2025-07-23 10:08:24,809][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:08:24,810][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.1575, Std: 1.2365\n",
      "[2025-07-23 10:08:24,810][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.44\n",
      "[2025-07-23 10:08:24,810][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 1.6215\n",
      "[2025-07-23 10:08:24,811][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 90):\n",
      "[2025-07-23 10:08:24,811][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (0, 1.6214552972338747)\n",
      "[2025-07-23 10:08:24,811][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X2'}\n",
      "[2025-07-23 10:08:24,811][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X2': 1.6214552972338747}\n",
      "[2025-07-23 10:08:24,812][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X1\n",
      "[2025-07-23 10:08:24,812][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.16214552972338747}\n",
      "[2025-07-23 10:08:24,812][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.662146\n",
      "[2025-07-23 10:08:24,813][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.662146\n",
      "[2025-07-23 10:08:24,813][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:08:26,527][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000281035385\n",
      "[2025-07-23 10:08:26,745][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 100):\n",
      "[2025-07-23 10:08:26,746][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-5.32302651e-02 -1.00000000e+09]\n",
      "[2025-07-23 10:08:26,746][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "[2025-07-23 10:08:26,746][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:08:26,749][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:08:26,749][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.81\n",
      "[2025-07-23 10:08:26,749][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [1. 0.]\n",
      "[2025-07-23 10:08:26,749][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X2 (index 0)\n",
      "[2025-07-23 10:08:26,750][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:08:26,750][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.1325, Std: 1.2284\n",
      "[2025-07-23 10:08:26,750][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.44\n",
      "[2025-07-23 10:08:26,751][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -0.8360\n",
      "[2025-07-23 10:08:26,751][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 100):\n",
      "[2025-07-23 10:08:26,751][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (0, -0.8359950048077998)\n",
      "[2025-07-23 10:08:26,752][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X2'}\n",
      "[2025-07-23 10:08:26,752][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X2': -0.8359950048077998}\n",
      "[2025-07-23 10:08:26,752][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X1\n",
      "[2025-07-23 10:08:26,753][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.08359950048077998}\n",
      "[2025-07-23 10:08:26,753][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.583600\n",
      "[2025-07-23 10:08:26,753][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.583600\n",
      "[2025-07-23 10:08:26,753][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:08:26,754][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.661, trend=-0.291\n",
      "[2025-07-23 10:08:28,395][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000279344384\n",
      "[2025-07-23 10:08:28,726][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 110):\n",
      "[2025-07-23 10:08:28,727][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-8.37239988e-02 -1.00000000e+09]\n",
      "[2025-07-23 10:08:28,727][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "[2025-07-23 10:08:28,727][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:08:28,729][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:08:28,729][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.80\n",
      "[2025-07-23 10:08:28,729][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [1. 0.]\n",
      "[2025-07-23 10:08:28,730][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X2 (index 0)\n",
      "[2025-07-23 10:08:28,730][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:08:28,730][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.1714, Std: 1.2657\n",
      "[2025-07-23 10:08:28,730][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.43\n",
      "[2025-07-23 10:08:28,731][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 2.9826\n",
      "[2025-07-23 10:08:28,731][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 110):\n",
      "[2025-07-23 10:08:28,731][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (0, 2.982629852820048)\n",
      "[2025-07-23 10:08:28,732][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X2'}\n",
      "[2025-07-23 10:08:28,732][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X2': 2.982629852820048}\n",
      "[2025-07-23 10:08:28,732][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X1\n",
      "[2025-07-23 10:08:28,732][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.29826298528200484}\n",
      "[2025-07-23 10:08:28,733][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.798263\n",
      "[2025-07-23 10:08:28,733][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.798263\n",
      "[2025-07-23 10:08:28,733][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:08:28,733][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.653, trend=+0.271\n",
      "[2025-07-23 10:08:30,298][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000272615837\n",
      "[2025-07-23 10:08:30,718][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 120):\n",
      "[2025-07-23 10:08:30,718][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [ 3.03832585e-03 -1.00000000e+09]\n",
      "[2025-07-23 10:08:30,718][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "[2025-07-23 10:08:30,719][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:08:30,721][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:08:30,721][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.78\n",
      "[2025-07-23 10:08:30,721][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [1. 0.]\n",
      "[2025-07-23 10:08:30,722][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X2 (index 0)\n",
      "[2025-07-23 10:08:30,722][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:08:30,722][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.1846, Std: 1.2547\n",
      "[2025-07-23 10:08:30,722][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.43\n",
      "[2025-07-23 10:08:30,723][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 1.6259\n",
      "[2025-07-23 10:08:30,723][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 120):\n",
      "[2025-07-23 10:08:30,723][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (0, 1.6258579761382494)\n",
      "[2025-07-23 10:08:30,724][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X2'}\n",
      "[2025-07-23 10:08:30,724][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X2': 1.6258579761382494}\n",
      "[2025-07-23 10:08:30,724][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X1\n",
      "[2025-07-23 10:08:30,725][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.16258579761382497}\n",
      "[2025-07-23 10:08:30,725][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.662586\n",
      "[2025-07-23 10:08:30,725][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.662586\n",
      "[2025-07-23 10:08:30,726][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:08:30,726][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.667, trend=+0.012\n",
      "[2025-07-23 10:08:32,202][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000277652912\n",
      "[2025-07-23 10:08:32,203][causal_bayes_opt.training.enriched_trainer][INFO] - Policy Learning Diagnostics (update 15):\n",
      "[2025-07-23 10:08:32,203][causal_bayes_opt.training.enriched_trainer][INFO] -   Action magnitudes: max=4.707749\n",
      "[2025-07-23 10:08:32,204][causal_bayes_opt.training.enriched_trainer][INFO] -   Mean reward: 0.721\n",
      "[2025-07-23 10:08:32,204][causal_bayes_opt.training.enriched_trainer][INFO] -   Policy param change: 0.00027765\n",
      "[2025-07-23 10:08:32,204][causal_bayes_opt.training.enriched_trainer][INFO] -   Parameter norm change: 0.00027765\n",
      "[2025-07-23 10:08:32,204][causal_bayes_opt.training.enriched_trainer][INFO] -   Rewards: min=0.559, max=0.971, group_baseline=0.721\n",
      "[2025-07-23 10:08:32,205][causal_bayes_opt.training.enriched_trainer][INFO] -   GRPO losses: policy=0.337140, entropy=-2.457093\n",
      "[2025-07-23 10:08:32,205][causal_bayes_opt.training.enriched_trainer][INFO] -   Gradient norm: 0.08487509\n",
      "[2025-07-23 10:08:32,205][causal_bayes_opt.training.enriched_trainer][INFO] -   Learning rate: 0.001000\n",
      "[2025-07-23 10:08:32,205][causal_bayes_opt.training.enriched_trainer][INFO] -   KL penalty: 0.000000, approx_kl: 3.633241\n",
      "[2025-07-23 10:08:34,039][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000293219642\n",
      "[2025-07-23 10:08:34,150][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 130):\n",
      "[2025-07-23 10:08:34,151][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-2.89889861e-02 -1.00000000e+09]\n",
      "[2025-07-23 10:08:34,151][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "[2025-07-23 10:08:34,151][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:08:34,153][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:08:34,154][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.75\n",
      "[2025-07-23 10:08:34,154][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [1. 0.]\n",
      "[2025-07-23 10:08:34,154][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X2 (index 0)\n",
      "[2025-07-23 10:08:34,155][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:08:34,155][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.1755, Std: 1.2564\n",
      "[2025-07-23 10:08:34,155][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.42\n",
      "[2025-07-23 10:08:34,155][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 0.6550\n",
      "[2025-07-23 10:08:34,156][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 130):\n",
      "[2025-07-23 10:08:34,156][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (0, 0.6549801569254297)\n",
      "[2025-07-23 10:08:34,156][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X2'}\n",
      "[2025-07-23 10:08:34,157][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X2': 0.6549801569254297}\n",
      "[2025-07-23 10:08:34,157][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X1\n",
      "[2025-07-23 10:08:34,157][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.06549801569254297}\n",
      "[2025-07-23 10:08:34,158][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.565498\n",
      "[2025-07-23 10:08:34,158][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.565498\n",
      "[2025-07-23 10:08:34,158][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:08:34,158][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.658, trend=-0.062\n",
      "[2025-07-23 10:08:35,903][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000306752646\n",
      "[2025-07-23 10:08:36,115][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 140):\n",
      "[2025-07-23 10:08:36,116][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.34013484e-01 -1.00000000e+09]\n",
      "[2025-07-23 10:08:36,116][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "[2025-07-23 10:08:36,116][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:08:36,118][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:08:36,119][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.73\n",
      "[2025-07-23 10:08:36,119][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [1. 0.]\n",
      "[2025-07-23 10:08:36,119][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X2 (index 0)\n",
      "[2025-07-23 10:08:36,119][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:08:36,120][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2021, Std: 1.3427\n",
      "[2025-07-23 10:08:36,120][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.41\n",
      "[2025-07-23 10:08:36,120][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 1.6682\n",
      "[2025-07-23 10:08:36,121][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 140):\n",
      "[2025-07-23 10:08:36,121][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (0, 1.668171982769142)\n",
      "[2025-07-23 10:08:36,121][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X2'}\n",
      "[2025-07-23 10:08:36,121][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X2': 1.668171982769142}\n",
      "[2025-07-23 10:08:36,122][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X1\n",
      "[2025-07-23 10:08:36,122][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.1668171982769142}\n",
      "[2025-07-23 10:08:36,122][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.666817\n",
      "[2025-07-23 10:08:36,122][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.666817\n",
      "[2025-07-23 10:08:36,123][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:08:36,123][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.662, trend=-0.050\n",
      "[2025-07-23 10:08:37,768][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000337518761\n",
      "[2025-07-23 10:08:38,125][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 150):\n",
      "[2025-07-23 10:08:38,125][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-5.77455592e-02 -1.00000000e+09]\n",
      "[2025-07-23 10:08:38,126][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "[2025-07-23 10:08:38,126][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:08:38,128][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:08:38,128][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.72\n",
      "[2025-07-23 10:08:38,129][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [1. 0.]\n",
      "[2025-07-23 10:08:38,129][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X2 (index 0)\n",
      "[2025-07-23 10:08:38,129][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:08:38,130][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2161, Std: 1.3727\n",
      "[2025-07-23 10:08:38,130][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.41\n",
      "[2025-07-23 10:08:38,130][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 0.7668\n",
      "[2025-07-23 10:08:38,131][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 150):\n",
      "[2025-07-23 10:08:38,131][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (0, 0.7667539512829875)\n",
      "[2025-07-23 10:08:38,132][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X2'}\n",
      "[2025-07-23 10:08:38,132][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X2': 0.7667539512829875}\n",
      "[2025-07-23 10:08:38,132][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X1\n",
      "[2025-07-23 10:08:38,133][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.07667539512829875}\n",
      "[2025-07-23 10:08:38,133][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.576675\n",
      "[2025-07-23 10:08:38,133][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.576675\n",
      "[2025-07-23 10:08:38,134][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:08:38,134][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.648, trend=-0.161\n",
      "[2025-07-23 10:08:39,665][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000346205886\n",
      "[2025-07-23 10:08:40,090][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 160):\n",
      "[2025-07-23 10:08:40,091][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-5.16076397e-02 -1.00000000e+09]\n",
      "[2025-07-23 10:08:40,091][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "[2025-07-23 10:08:40,091][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:08:40,093][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:08:40,093][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.70\n",
      "[2025-07-23 10:08:40,094][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [1. 0.]\n",
      "[2025-07-23 10:08:40,094][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X2 (index 0)\n",
      "[2025-07-23 10:08:40,094][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:08:40,095][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2136, Std: 1.3950\n",
      "[2025-07-23 10:08:40,095][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.40\n",
      "[2025-07-23 10:08:40,095][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 0.4001\n",
      "[2025-07-23 10:08:40,096][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 160):\n",
      "[2025-07-23 10:08:40,096][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (0, 0.4001445186486539)\n",
      "[2025-07-23 10:08:40,096][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X2'}\n",
      "[2025-07-23 10:08:40,096][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X2': 0.4001445186486539}\n",
      "[2025-07-23 10:08:40,097][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X1\n",
      "[2025-07-23 10:08:40,097][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.040014451864865394}\n",
      "[2025-07-23 10:08:40,097][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.540014\n",
      "[2025-07-23 10:08:40,098][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.540014\n",
      "[2025-07-23 10:08:40,098][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:08:40,098][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.628, trend=-0.037\n",
      "[2025-07-23 10:08:41,579][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000347624699\n",
      "[2025-07-23 10:08:41,580][causal_bayes_opt.training.enriched_trainer][INFO] - Policy Learning Diagnostics (update 20):\n",
      "[2025-07-23 10:08:41,580][causal_bayes_opt.training.enriched_trainer][INFO] -   Action magnitudes: max=4.626502\n",
      "[2025-07-23 10:08:41,580][causal_bayes_opt.training.enriched_trainer][INFO] -   Mean reward: 0.636\n",
      "[2025-07-23 10:08:41,580][causal_bayes_opt.training.enriched_trainer][INFO] -   Policy param change: 0.00034762\n",
      "[2025-07-23 10:08:41,581][causal_bayes_opt.training.enriched_trainer][INFO] -   Parameter norm change: 0.00034762\n",
      "[2025-07-23 10:08:41,581][causal_bayes_opt.training.enriched_trainer][INFO] -   Rewards: min=0.526, max=0.963, group_baseline=0.636\n",
      "[2025-07-23 10:08:41,581][causal_bayes_opt.training.enriched_trainer][INFO] -   GRPO losses: policy=0.289483, entropy=-2.507391\n",
      "[2025-07-23 10:08:41,582][causal_bayes_opt.training.enriched_trainer][INFO] -   Gradient norm: 0.07850288\n",
      "[2025-07-23 10:08:41,582][causal_bayes_opt.training.enriched_trainer][INFO] -   Learning rate: 0.001000\n",
      "[2025-07-23 10:08:41,582][causal_bayes_opt.training.enriched_trainer][INFO] -   KL penalty: 0.000000, approx_kl: 2.882129\n",
      "[2025-07-23 10:08:57,117][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000349338282\n",
      "[2025-07-23 10:08:57,180][causal_bayes_opt.training.enriched_trainer][INFO] - Episode 20: reward=0.622, intervention_rate=1.000, scm=fork_4var, F1=0.000, P(Parents)=0.000, SHD=3\n",
      "[2025-07-23 10:08:57,308][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 170):\n",
      "[2025-07-23 10:08:57,308][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -9.30258618e-02 -1.36405167e-01]\n",
      "[2025-07-23 10:08:57,309][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "[2025-07-23 10:08:57,309][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:08:57,311][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:08:57,311][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.67\n",
      "[2025-07-23 10:08:57,312][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.         0.50648626 0.49351374]\n",
      "[2025-07-23 10:08:57,312][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X1 (index 2)\n",
      "[2025-07-23 10:08:57,312][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:08:57,312][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2170, Std: 1.4298\n",
      "[2025-07-23 10:08:57,313][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.39\n",
      "[2025-07-23 10:08:57,313][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 3.2401\n",
      "[2025-07-23 10:08:57,314][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 170):\n",
      "[2025-07-23 10:08:57,314][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (2, 3.2401375244173085)\n",
      "[2025-07-23 10:08:57,314][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X1'}\n",
      "[2025-07-23 10:08:57,315][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X1': 3.2401375244173085}\n",
      "[2025-07-23 10:08:57,315][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:08:57,315][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.32401375244173086}\n",
      "[2025-07-23 10:08:57,315][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.824014\n",
      "[2025-07-23 10:08:57,315][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.824014\n",
      "[2025-07-23 10:08:57,316][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:08:57,316][causal_bayes_opt.training.enriched_trainer][INFO] -   üí∞ HIGH REWARD: Policy achieved high reward (0.824) - good performance!\n",
      "[2025-07-23 10:08:57,316][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.653, trend=+0.174\n",
      "[2025-07-23 10:08:59,571][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000348354904\n",
      "[2025-07-23 10:08:59,833][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 180):\n",
      "[2025-07-23 10:08:59,833][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -1.16647811e-01 -1.51093160e-01]\n",
      "[2025-07-23 10:08:59,834][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "[2025-07-23 10:08:59,834][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:08:59,836][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:08:59,836][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.66\n",
      "[2025-07-23 10:08:59,837][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.         0.50519911 0.49480089]\n",
      "[2025-07-23 10:08:59,837][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X1 (index 2)\n",
      "[2025-07-23 10:08:59,837][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:08:59,838][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2236, Std: 1.4441\n",
      "[2025-07-23 10:08:59,838][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.39\n",
      "[2025-07-23 10:08:59,838][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -0.3949\n",
      "[2025-07-23 10:08:59,839][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 180):\n",
      "[2025-07-23 10:08:59,839][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (2, -0.3949258039316763)\n",
      "[2025-07-23 10:08:59,839][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X1'}\n",
      "[2025-07-23 10:08:59,839][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X1': -0.3949258039316763}\n",
      "[2025-07-23 10:08:59,840][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:08:59,840][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.03949258039316764}\n",
      "[2025-07-23 10:08:59,840][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.539493\n",
      "[2025-07-23 10:08:59,841][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.539493\n",
      "[2025-07-23 10:08:59,841][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:08:59,841][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.642, trend=-0.123\n",
      "[2025-07-23 10:09:01,962][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000359841819\n",
      "[2025-07-23 10:09:02,359][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 190):\n",
      "[2025-07-23 10:09:02,359][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09  9.93610580e-04  3.13060254e-02]\n",
      "[2025-07-23 10:09:02,360][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "[2025-07-23 10:09:02,360][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:09:02,362][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:09:02,363][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.64\n",
      "[2025-07-23 10:09:02,363][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.        0.4953811 0.5046189]\n",
      "[2025-07-23 10:09:02,363][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X1 (index 2)\n",
      "[2025-07-23 10:09:02,364][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:09:02,365][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.1937, Std: 1.4396\n",
      "[2025-07-23 10:09:02,365][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.38\n",
      "[2025-07-23 10:09:02,366][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 0.5553\n",
      "[2025-07-23 10:09:02,366][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 190):\n",
      "[2025-07-23 10:09:02,366][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (2, 0.5552668215719805)\n",
      "[2025-07-23 10:09:02,367][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X1'}\n",
      "[2025-07-23 10:09:02,367][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X1': 0.5552668215719805}\n",
      "[2025-07-23 10:09:02,367][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:09:02,368][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.055526682157198054}\n",
      "[2025-07-23 10:09:02,368][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.555527\n",
      "[2025-07-23 10:09:02,368][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.555527\n",
      "[2025-07-23 10:09:02,368][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:09:02,368][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.631, trend=-0.028\n",
      "[2025-07-23 10:09:04,376][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000383438752\n",
      "[2025-07-23 10:09:04,895][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 200):\n",
      "[2025-07-23 10:09:04,895][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -1.06969021e-01 -3.01744864e-03]\n",
      "[2025-07-23 10:09:04,896][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "[2025-07-23 10:09:04,896][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:09:04,898][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:09:04,898][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.62\n",
      "[2025-07-23 10:09:04,899][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.        0.4840129 0.5159871]\n",
      "[2025-07-23 10:09:04,899][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X3 (index 1)\n",
      "[2025-07-23 10:09:04,899][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:09:04,900][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2231, Std: 1.4794\n",
      "[2025-07-23 10:09:04,900][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.38\n",
      "[2025-07-23 10:09:04,900][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -1.0959\n",
      "[2025-07-23 10:09:04,901][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 200):\n",
      "[2025-07-23 10:09:04,901][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (1, -1.0959102092328747)\n",
      "[2025-07-23 10:09:04,901][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X3'}\n",
      "[2025-07-23 10:09:04,901][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X3': -1.0959102092328747}\n",
      "[2025-07-23 10:09:04,902][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:09:04,902][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.10959102092328749}\n",
      "[2025-07-23 10:09:04,902][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.609591\n",
      "[2025-07-23 10:09:04,902][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.609591\n",
      "[2025-07-23 10:09:04,903][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:09:04,903][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.634, trend=-0.189\n",
      "[2025-07-23 10:09:06,830][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000369412590\n",
      "[2025-07-23 10:09:06,831][causal_bayes_opt.training.enriched_trainer][INFO] - Policy Learning Diagnostics (update 25):\n",
      "[2025-07-23 10:09:06,831][causal_bayes_opt.training.enriched_trainer][INFO] -   Action magnitudes: max=2.905573\n",
      "[2025-07-23 10:09:06,831][causal_bayes_opt.training.enriched_trainer][INFO] -   Mean reward: 0.650\n",
      "[2025-07-23 10:09:06,831][causal_bayes_opt.training.enriched_trainer][INFO] -   Policy param change: 0.00036941\n",
      "[2025-07-23 10:09:06,832][causal_bayes_opt.training.enriched_trainer][INFO] -   Parameter norm change: 0.00036941\n",
      "[2025-07-23 10:09:06,832][causal_bayes_opt.training.enriched_trainer][INFO] -   Rewards: min=0.564, max=0.791, group_baseline=0.650\n",
      "[2025-07-23 10:09:06,832][causal_bayes_opt.training.enriched_trainer][INFO] -   GRPO losses: policy=0.310368, entropy=-2.966290\n",
      "[2025-07-23 10:09:06,833][causal_bayes_opt.training.enriched_trainer][INFO] -   Gradient norm: 0.16205182\n",
      "[2025-07-23 10:09:06,833][causal_bayes_opt.training.enriched_trainer][INFO] -   Learning rate: 0.001000\n",
      "[2025-07-23 10:09:06,833][causal_bayes_opt.training.enriched_trainer][INFO] -   KL penalty: 0.000000, approx_kl: 2.959424\n",
      "[2025-07-23 10:09:09,245][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000371982993\n",
      "[2025-07-23 10:09:09,379][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 210):\n",
      "[2025-07-23 10:09:09,380][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.03911700e-01 -1.00000000e+09 -1.48587913e-01]\n",
      "[2025-07-23 10:09:09,380][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X1', 'X0'], Target: X3\n",
      "[2025-07-23 10:09:09,381][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:09:09,383][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:09:09,383][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.59\n",
      "[2025-07-23 10:09:09,384][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.50700757 0.         0.49299243]\n",
      "[2025-07-23 10:09:09,384][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X1 (index 2)\n",
      "[2025-07-23 10:09:09,384][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:09:09,384][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2389, Std: 1.5061\n",
      "[2025-07-23 10:09:09,385][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.36\n",
      "[2025-07-23 10:09:09,385][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 1.1597\n",
      "[2025-07-23 10:09:09,386][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 210):\n",
      "[2025-07-23 10:09:09,386][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (2, 1.1596731041916657)\n",
      "[2025-07-23 10:09:09,386][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X1'}\n",
      "[2025-07-23 10:09:09,387][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X1': 1.1596731041916657}\n",
      "[2025-07-23 10:09:09,387][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X3\n",
      "[2025-07-23 10:09:09,387][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.11596731041916658}\n",
      "[2025-07-23 10:09:09,387][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.615967\n",
      "[2025-07-23 10:09:09,388][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.615967\n",
      "[2025-07-23 10:09:09,388][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:09:09,388][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.616, trend=-0.047\n",
      "[2025-07-23 10:09:11,643][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000370495791\n",
      "[2025-07-23 10:09:11,910][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 220):\n",
      "[2025-07-23 10:09:11,911][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-4.08619862e-02 -1.00000000e+09 -1.53341722e-01]\n",
      "[2025-07-23 10:09:11,911][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X1', 'X0'], Target: X3\n",
      "[2025-07-23 10:09:11,911][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:09:11,913][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:09:11,914][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.58\n",
      "[2025-07-23 10:09:11,914][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.51781103 0.         0.48218897]\n",
      "[2025-07-23 10:09:11,914][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X2 (index 0)\n",
      "[2025-07-23 10:09:11,914][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:09:11,915][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2147, Std: 1.5136\n",
      "[2025-07-23 10:09:11,915][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.36\n",
      "[2025-07-23 10:09:11,915][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 2.9490\n",
      "[2025-07-23 10:09:11,916][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 220):\n",
      "[2025-07-23 10:09:11,916][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (0, 2.949026716231295)\n",
      "[2025-07-23 10:09:11,916][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X2'}\n",
      "[2025-07-23 10:09:11,916][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X2': 2.949026716231295}\n",
      "[2025-07-23 10:09:11,917][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X3\n",
      "[2025-07-23 10:09:11,917][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.2949026716231295}\n",
      "[2025-07-23 10:09:11,917][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.794903\n",
      "[2025-07-23 10:09:11,918][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.794903\n",
      "[2025-07-23 10:09:11,918][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:09:11,918][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.629, trend=+0.229\n",
      "[2025-07-23 10:09:14,060][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000338249817\n",
      "[2025-07-23 10:09:14,458][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 230):\n",
      "[2025-07-23 10:09:14,459][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.34433094e-01 -1.00000000e+09 -1.09809425e-01]\n",
      "[2025-07-23 10:09:14,459][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X1', 'X0'], Target: X3\n",
      "[2025-07-23 10:09:14,460][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:09:14,462][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:09:14,462][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.56\n",
      "[2025-07-23 10:09:14,462][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.49606029 0.         0.50393971]\n",
      "[2025-07-23 10:09:14,462][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X2 (index 0)\n",
      "[2025-07-23 10:09:14,463][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:09:14,463][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2520, Std: 1.5437\n",
      "[2025-07-23 10:09:14,463][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.35\n",
      "[2025-07-23 10:09:14,463][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 0.2160\n",
      "[2025-07-23 10:09:14,464][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 230):\n",
      "[2025-07-23 10:09:14,464][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (0, 0.21601273570936216)\n",
      "[2025-07-23 10:09:14,465][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X2'}\n",
      "[2025-07-23 10:09:14,465][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X2': 0.21601273570936216}\n",
      "[2025-07-23 10:09:14,465][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X3\n",
      "[2025-07-23 10:09:14,466][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.02160127357093622}\n",
      "[2025-07-23 10:09:14,466][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.521601\n",
      "[2025-07-23 10:09:14,466][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.521601\n",
      "[2025-07-23 10:09:14,466][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:09:14,467][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.624, trend=-0.145\n",
      "[2025-07-23 10:09:16,493][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000323637500\n",
      "[2025-07-23 10:09:17,020][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 240):\n",
      "[2025-07-23 10:09:17,021][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.26633447e-01 -1.00000000e+09 -9.70714304e-02]\n",
      "[2025-07-23 10:09:17,021][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X1', 'X0'], Target: X3\n",
      "[2025-07-23 10:09:17,021][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:09:17,023][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:09:17,024][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.55\n",
      "[2025-07-23 10:09:17,024][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.49522245 0.         0.50477755]\n",
      "[2025-07-23 10:09:17,024][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X1 (index 2)\n",
      "[2025-07-23 10:09:17,024][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:09:17,025][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2129, Std: 1.5128\n",
      "[2025-07-23 10:09:17,025][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.35\n",
      "[2025-07-23 10:09:17,025][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -1.3160\n",
      "[2025-07-23 10:09:17,026][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 240):\n",
      "[2025-07-23 10:09:17,026][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (2, -1.3159558159364009)\n",
      "[2025-07-23 10:09:17,026][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X1'}\n",
      "[2025-07-23 10:09:17,026][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X1': -1.3159558159364009}\n",
      "[2025-07-23 10:09:17,027][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X3\n",
      "[2025-07-23 10:09:17,027][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.1315955815936401}\n",
      "[2025-07-23 10:09:17,028][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.631596\n",
      "[2025-07-23 10:09:17,028][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.631596\n",
      "[2025-07-23 10:09:17,028][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:09:17,029][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.621, trend=+0.055\n",
      "[2025-07-23 10:09:18,905][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000312547585\n",
      "[2025-07-23 10:09:18,906][causal_bayes_opt.training.enriched_trainer][INFO] - Policy Learning Diagnostics (update 30):\n",
      "[2025-07-23 10:09:18,906][causal_bayes_opt.training.enriched_trainer][INFO] -   Action magnitudes: max=3.314612\n",
      "[2025-07-23 10:09:18,906][causal_bayes_opt.training.enriched_trainer][INFO] -   Mean reward: 0.649\n",
      "[2025-07-23 10:09:18,906][causal_bayes_opt.training.enriched_trainer][INFO] -   Policy param change: 0.00031255\n",
      "[2025-07-23 10:09:18,907][causal_bayes_opt.training.enriched_trainer][INFO] -   Parameter norm change: 0.00031255\n",
      "[2025-07-23 10:09:18,907][causal_bayes_opt.training.enriched_trainer][INFO] -   Rewards: min=0.546, max=0.831, group_baseline=0.649\n",
      "[2025-07-23 10:09:18,907][causal_bayes_opt.training.enriched_trainer][INFO] -   GRPO losses: policy=0.309304, entropy=-3.027211\n",
      "[2025-07-23 10:09:18,908][causal_bayes_opt.training.enriched_trainer][INFO] -   Gradient norm: 0.13966846\n",
      "[2025-07-23 10:09:18,908][causal_bayes_opt.training.enriched_trainer][INFO] -   Learning rate: 0.001000\n",
      "[2025-07-23 10:09:18,908][causal_bayes_opt.training.enriched_trainer][INFO] -   KL penalty: 0.000000, approx_kl: 500000003.167095\n",
      "[2025-07-23 10:09:21,326][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000290553690\n",
      "[2025-07-23 10:09:21,334][causal_bayes_opt.training.enriched_trainer][INFO] - Episode 30: reward=0.623, intervention_rate=1.000, scm=collider_4var, F1=0.000, P(Parents)=0.000, SHD=3\n",
      "[2025-07-23 10:09:21,465][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 250):\n",
      "[2025-07-23 10:09:21,465][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -1.96848978e-02 -1.20037248e-01]\n",
      "[2025-07-23 10:09:21,465][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "[2025-07-23 10:09:21,466][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:09:21,468][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:09:21,468][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.52\n",
      "[2025-07-23 10:09:21,469][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.         0.51654692 0.48345308]\n",
      "[2025-07-23 10:09:21,469][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X1 (index 2)\n",
      "[2025-07-23 10:09:21,469][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:09:21,469][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2609, Std: 1.5778\n",
      "[2025-07-23 10:09:21,470][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.34\n",
      "[2025-07-23 10:09:21,470][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -0.4364\n",
      "[2025-07-23 10:09:21,470][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 250):\n",
      "[2025-07-23 10:09:21,471][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (2, -0.43638993003023197)\n",
      "[2025-07-23 10:09:21,471][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X1'}\n",
      "[2025-07-23 10:09:21,471][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X1': -0.43638993003023197}\n",
      "[2025-07-23 10:09:21,472][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:09:21,472][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.0436389930030232}\n",
      "[2025-07-23 10:09:21,472][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.543639\n",
      "[2025-07-23 10:09:21,472][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.543639\n",
      "[2025-07-23 10:09:21,473][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:09:21,473][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.618, trend=+0.004\n",
      "[2025-07-23 10:09:23,814][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000271859053\n",
      "[2025-07-23 10:09:24,078][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 260):\n",
      "[2025-07-23 10:09:24,079][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -1.15961720e-01 -1.06960539e-01]\n",
      "[2025-07-23 10:09:24,079][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "[2025-07-23 10:09:24,079][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:09:24,082][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:09:24,082][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.50\n",
      "[2025-07-23 10:09:24,082][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.         0.49849981 0.50150019]\n",
      "[2025-07-23 10:09:24,082][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X1 (index 2)\n",
      "[2025-07-23 10:09:24,083][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:09:24,083][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2563, Std: 1.6457\n",
      "[2025-07-23 10:09:24,083][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.33\n",
      "[2025-07-23 10:09:24,084][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -4.9980\n",
      "[2025-07-23 10:09:24,084][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 260):\n",
      "[2025-07-23 10:09:24,084][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (2, -4.998041598402094)\n",
      "[2025-07-23 10:09:24,085][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X1'}\n",
      "[2025-07-23 10:09:24,085][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X1': -4.998041598402094}\n",
      "[2025-07-23 10:09:24,085][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:09:24,086][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.4998041598402094}\n",
      "[2025-07-23 10:09:24,086][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.999804\n",
      "[2025-07-23 10:09:24,086][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.999804\n",
      "[2025-07-23 10:09:24,086][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:09:24,086][causal_bayes_opt.training.enriched_trainer][INFO] -   üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "[2025-07-23 10:09:24,087][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.664, trend=+0.176\n",
      "[2025-07-23 10:09:26,206][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000276923015\n",
      "[2025-07-23 10:09:26,590][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 270):\n",
      "[2025-07-23 10:09:26,591][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -6.01420846e-02 -3.13780670e-02]\n",
      "[2025-07-23 10:09:26,591][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "[2025-07-23 10:09:26,591][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:09:26,593][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:09:26,594][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.48\n",
      "[2025-07-23 10:09:26,594][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.         0.49515569 0.50484431]\n",
      "[2025-07-23 10:09:26,594][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X3 (index 1)\n",
      "[2025-07-23 10:09:26,595][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:09:26,595][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2397, Std: 1.5919\n",
      "[2025-07-23 10:09:26,596][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.33\n",
      "[2025-07-23 10:09:26,596][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 0.8843\n",
      "[2025-07-23 10:09:26,597][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 270):\n",
      "[2025-07-23 10:09:26,597][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (1, 0.8842779995214055)\n",
      "[2025-07-23 10:09:26,597][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X3'}\n",
      "[2025-07-23 10:09:26,597][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X3': 0.8842779995214055}\n",
      "[2025-07-23 10:09:26,598][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:09:26,598][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.08842779995214056}\n",
      "[2025-07-23 10:09:26,598][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.588428\n",
      "[2025-07-23 10:09:26,598][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.588428\n",
      "[2025-07-23 10:09:26,599][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:09:26,599][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.640, trend=+0.049\n",
      "[2025-07-23 10:09:28,623][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000258325590\n",
      "[2025-07-23 10:09:29,143][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 280):\n",
      "[2025-07-23 10:09:29,143][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -9.98224767e-02 -1.35482950e-01]\n",
      "[2025-07-23 10:09:29,144][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "[2025-07-23 10:09:29,144][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:09:29,146][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:09:29,147][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.47\n",
      "[2025-07-23 10:09:29,147][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.         0.50606957 0.49393043]\n",
      "[2025-07-23 10:09:29,147][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X3 (index 1)\n",
      "[2025-07-23 10:09:29,147][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:09:29,148][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2615, Std: 1.6212\n",
      "[2025-07-23 10:09:29,148][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.32\n",
      "[2025-07-23 10:09:29,148][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 1.4709\n",
      "[2025-07-23 10:09:29,149][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 280):\n",
      "[2025-07-23 10:09:29,149][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (1, 1.4708942455357974)\n",
      "[2025-07-23 10:09:29,149][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X3'}\n",
      "[2025-07-23 10:09:29,149][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X3': 1.4708942455357974}\n",
      "[2025-07-23 10:09:29,150][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:09:29,150][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.14708942455357973}\n",
      "[2025-07-23 10:09:29,150][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.647089\n",
      "[2025-07-23 10:09:29,150][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.647089\n",
      "[2025-07-23 10:09:29,151][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:09:29,151][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.651, trend=+0.092\n",
      "[2025-07-23 10:09:31,039][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000202050847\n",
      "[2025-07-23 10:09:31,040][causal_bayes_opt.training.enriched_trainer][INFO] - Policy Learning Diagnostics (update 35):\n",
      "[2025-07-23 10:09:31,040][causal_bayes_opt.training.enriched_trainer][INFO] -   Action magnitudes: max=2.789751\n",
      "[2025-07-23 10:09:31,040][causal_bayes_opt.training.enriched_trainer][INFO] -   Mean reward: 0.662\n",
      "[2025-07-23 10:09:31,040][causal_bayes_opt.training.enriched_trainer][INFO] -   Policy param change: 0.00020205\n",
      "[2025-07-23 10:09:31,041][causal_bayes_opt.training.enriched_trainer][INFO] -   Parameter norm change: 0.00020205\n",
      "[2025-07-23 10:09:31,041][causal_bayes_opt.training.enriched_trainer][INFO] -   Rewards: min=0.515, max=0.779, group_baseline=0.662\n",
      "[2025-07-23 10:09:31,041][causal_bayes_opt.training.enriched_trainer][INFO] -   GRPO losses: policy=0.328037, entropy=-3.095444\n",
      "[2025-07-23 10:09:31,042][causal_bayes_opt.training.enriched_trainer][INFO] -   Gradient norm: 0.14096201\n",
      "[2025-07-23 10:09:31,042][causal_bayes_opt.training.enriched_trainer][INFO] -   Learning rate: 0.001000\n",
      "[2025-07-23 10:09:31,042][causal_bayes_opt.training.enriched_trainer][INFO] -   KL penalty: 0.000000, approx_kl: 3.034322\n",
      "[2025-07-23 10:09:33,515][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000211711505\n",
      "[2025-07-23 10:09:33,654][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 290):\n",
      "[2025-07-23 10:09:33,655][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -1.41581989e-02 -1.01752028e-01]\n",
      "[2025-07-23 10:09:33,655][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "[2025-07-23 10:09:33,655][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:09:33,658][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:09:33,658][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.44\n",
      "[2025-07-23 10:09:33,658][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.       0.515229 0.484771]\n",
      "[2025-07-23 10:09:33,658][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X3 (index 1)\n",
      "[2025-07-23 10:09:33,659][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:09:33,659][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.1962, Std: 1.5712\n",
      "[2025-07-23 10:09:33,659][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.31\n",
      "[2025-07-23 10:09:33,659][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -0.4040\n",
      "[2025-07-23 10:09:33,660][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 290):\n",
      "[2025-07-23 10:09:33,660][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (1, -0.40395935726493415)\n",
      "[2025-07-23 10:09:33,660][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X3'}\n",
      "[2025-07-23 10:09:33,661][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X3': -0.40395935726493415}\n",
      "[2025-07-23 10:09:33,661][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:09:33,661][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.040395935726493415}\n",
      "[2025-07-23 10:09:33,661][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.540396\n",
      "[2025-07-23 10:09:33,662][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.540396\n",
      "[2025-07-23 10:09:33,662][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:09:33,662][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.649, trend=-0.069\n",
      "[2025-07-23 10:09:35,886][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000206927413\n",
      "[2025-07-23 10:09:36,150][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 300):\n",
      "[2025-07-23 10:09:36,150][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -1.36142765e-01 -5.86089839e-02]\n",
      "[2025-07-23 10:09:36,151][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "[2025-07-23 10:09:36,151][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:09:36,153][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:09:36,153][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.42\n",
      "[2025-07-23 10:09:36,154][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.         0.48637106 0.51362894]\n",
      "[2025-07-23 10:09:36,154][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X1 (index 2)\n",
      "[2025-07-23 10:09:36,154][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:09:36,155][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2490, Std: 1.7113\n",
      "[2025-07-23 10:09:36,155][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.31\n",
      "[2025-07-23 10:09:36,155][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -0.4891\n",
      "[2025-07-23 10:09:36,156][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 300):\n",
      "[2025-07-23 10:09:36,156][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (2, -0.48912272767358067)\n",
      "[2025-07-23 10:09:36,156][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X1'}\n",
      "[2025-07-23 10:09:36,157][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X1': -0.48912272767358067}\n",
      "[2025-07-23 10:09:36,157][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:09:36,157][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.04891227276735807}\n",
      "[2025-07-23 10:09:36,157][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.548912\n",
      "[2025-07-23 10:09:36,158][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.548912\n",
      "[2025-07-23 10:09:36,158][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:09:36,158][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.643, trend=-0.067\n",
      "[2025-07-23 10:09:38,260][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000232550266\n",
      "[2025-07-23 10:09:38,653][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 310):\n",
      "[2025-07-23 10:09:38,653][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -1.05143499e-01 -1.24756856e-01]\n",
      "[2025-07-23 10:09:38,654][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "[2025-07-23 10:09:38,654][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:09:38,656][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:09:38,657][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.41\n",
      "[2025-07-23 10:09:38,657][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.         0.50348676 0.49651324]\n",
      "[2025-07-23 10:09:38,657][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X3 (index 1)\n",
      "[2025-07-23 10:09:38,657][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:09:38,658][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2599, Std: 1.7475\n",
      "[2025-07-23 10:09:38,658][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.30\n",
      "[2025-07-23 10:09:38,658][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 1.3829\n",
      "[2025-07-23 10:09:38,659][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 310):\n",
      "[2025-07-23 10:09:38,659][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (1, 1.3829205909073174)\n",
      "[2025-07-23 10:09:38,659][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X3'}\n",
      "[2025-07-23 10:09:38,660][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X3': 1.3829205909073174}\n",
      "[2025-07-23 10:09:38,660][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:09:38,660][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.13829205909073175}\n",
      "[2025-07-23 10:09:38,660][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.638292\n",
      "[2025-07-23 10:09:38,661][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.638292\n",
      "[2025-07-23 10:09:38,661][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:09:38,661][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.645, trend=-0.157\n",
      "[2025-07-23 10:09:40,651][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000247608117\n",
      "[2025-07-23 10:09:41,166][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 320):\n",
      "[2025-07-23 10:09:41,167][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -2.33851392e-02 -7.09176945e-02]\n",
      "[2025-07-23 10:09:41,168][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "[2025-07-23 10:09:41,168][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:09:41,170][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:09:41,171][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.39\n",
      "[2025-07-23 10:09:41,171][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.         0.50854435 0.49145565]\n",
      "[2025-07-23 10:09:41,171][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X1 (index 2)\n",
      "[2025-07-23 10:09:41,171][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:09:41,172][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2686, Std: 1.7412\n",
      "[2025-07-23 10:09:41,172][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.30\n",
      "[2025-07-23 10:09:41,172][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 0.5614\n",
      "[2025-07-23 10:09:41,173][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 320):\n",
      "[2025-07-23 10:09:41,173][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (2, 0.561417290680783)\n",
      "[2025-07-23 10:09:41,173][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X1'}\n",
      "[2025-07-23 10:09:41,174][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X1': 0.561417290680783}\n",
      "[2025-07-23 10:09:41,174][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:09:41,174][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.05614172906807831}\n",
      "[2025-07-23 10:09:41,174][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.556142\n",
      "[2025-07-23 10:09:41,175][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.556142\n",
      "[2025-07-23 10:09:41,175][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:09:41,175][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.622, trend=+0.035\n",
      "[2025-07-23 10:09:43,420][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000257379210\n",
      "[2025-07-23 10:09:43,421][causal_bayes_opt.training.enriched_trainer][INFO] - Policy Learning Diagnostics (update 40):\n",
      "[2025-07-23 10:09:43,421][causal_bayes_opt.training.enriched_trainer][INFO] -   Action magnitudes: max=5.993095\n",
      "[2025-07-23 10:09:43,421][causal_bayes_opt.training.enriched_trainer][INFO] -   Mean reward: 0.653\n",
      "[2025-07-23 10:09:43,421][causal_bayes_opt.training.enriched_trainer][INFO] -   Policy param change: 0.00025738\n",
      "[2025-07-23 10:09:43,422][causal_bayes_opt.training.enriched_trainer][INFO] -   Parameter norm change: 0.00025738\n",
      "[2025-07-23 10:09:43,423][causal_bayes_opt.training.enriched_trainer][INFO] -   Rewards: min=0.506, max=1.000, group_baseline=0.653\n",
      "[2025-07-23 10:09:43,423][causal_bayes_opt.training.enriched_trainer][INFO] -   GRPO losses: policy=0.326476, entropy=-3.165834\n",
      "[2025-07-23 10:09:43,423][causal_bayes_opt.training.enriched_trainer][INFO] -   Gradient norm: 0.10150611\n",
      "[2025-07-23 10:09:43,424][causal_bayes_opt.training.enriched_trainer][INFO] -   Learning rate: 0.001000\n",
      "[2025-07-23 10:09:43,424][causal_bayes_opt.training.enriched_trainer][INFO] -   KL penalty: 0.000000, approx_kl: 3.440585\n",
      "[2025-07-23 10:09:59,903][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000268943721\n",
      "[2025-07-23 10:09:59,978][causal_bayes_opt.training.enriched_trainer][INFO] - Episode 40: reward=0.616, intervention_rate=1.000, scm=fork_5var, F1=0.000, P(Parents)=0.000, SHD=4\n",
      "[2025-07-23 10:10:00,127][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 330):\n",
      "[2025-07-23 10:10:00,127][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -1.02019516e-01 -1.62255975e-02 -9.86490898e-02]\n",
      "[2025-07-23 10:10:00,128][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1'], Target: X2\n",
      "[2025-07-23 10:10:00,128][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:10:00,130][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:10:00,131][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.36\n",
      "[2025-07-23 10:10:00,131][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.         0.32598462 0.34722152 0.32679386]\n",
      "[2025-07-23 10:10:00,131][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X3 (index 1)\n",
      "[2025-07-23 10:10:00,132][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:10:00,132][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2534, Std: 1.6943\n",
      "[2025-07-23 10:10:00,132][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.29\n",
      "[2025-07-23 10:10:00,132][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 2.7075\n",
      "[2025-07-23 10:10:00,133][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 330):\n",
      "[2025-07-23 10:10:00,133][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (1, 2.707451321518597)\n",
      "[2025-07-23 10:10:00,133][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X3'}\n",
      "[2025-07-23 10:10:00,134][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X3': 2.707451321518597}\n",
      "[2025-07-23 10:10:00,134][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:10:00,134][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.2707451321518597}\n",
      "[2025-07-23 10:10:00,135][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.770745\n",
      "[2025-07-23 10:10:00,135][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.770745\n",
      "[2025-07-23 10:10:00,135][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:10:00,136][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.647, trend=+0.139\n",
      "[2025-07-23 10:10:02,962][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000257210536\n",
      "[2025-07-23 10:10:03,258][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 340):\n",
      "[2025-07-23 10:10:03,259][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -8.15757882e-02 -1.45727591e-01 -1.08743400e-01]\n",
      "[2025-07-23 10:10:03,259][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1'], Target: X2\n",
      "[2025-07-23 10:10:03,260][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:10:03,262][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:10:03,262][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.34\n",
      "[2025-07-23 10:10:03,262][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.         0.34090529 0.32501256 0.33408215]\n",
      "[2025-07-23 10:10:03,262][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X3 (index 1)\n",
      "[2025-07-23 10:10:03,263][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:10:03,263][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.1824, Std: 1.5021\n",
      "[2025-07-23 10:10:03,263][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.28\n",
      "[2025-07-23 10:10:03,264][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 0.0587\n",
      "[2025-07-23 10:10:03,264][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 340):\n",
      "[2025-07-23 10:10:03,265][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (1, 0.05874390598312797)\n",
      "[2025-07-23 10:10:03,265][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X3'}\n",
      "[2025-07-23 10:10:03,265][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X3': 0.05874390598312797}\n",
      "[2025-07-23 10:10:03,265][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:10:03,266][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.005874390598312797}\n",
      "[2025-07-23 10:10:03,266][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.505874\n",
      "[2025-07-23 10:10:03,266][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.505874\n",
      "[2025-07-23 10:10:03,266][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:10:03,267][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.634, trend=-0.038\n",
      "[2025-07-23 10:10:05,830][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000244313762\n",
      "[2025-07-23 10:10:06,279][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 350):\n",
      "[2025-07-23 10:10:06,280][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -1.20470826e-01 -7.39357408e-02 -9.55561724e-02]\n",
      "[2025-07-23 10:10:06,280][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1'], Target: X2\n",
      "[2025-07-23 10:10:06,281][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:10:06,283][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:10:06,283][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.33\n",
      "[2025-07-23 10:10:06,283][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.         0.32737558 0.33904955 0.33357487]\n",
      "[2025-07-23 10:10:06,284][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X0 (index 2)\n",
      "[2025-07-23 10:10:06,284][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:10:06,284][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2734, Std: 1.7902\n",
      "[2025-07-23 10:10:06,285][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.28\n",
      "[2025-07-23 10:10:06,285][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 1.2100\n",
      "[2025-07-23 10:10:06,285][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 350):\n",
      "[2025-07-23 10:10:06,286][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (2, 1.2100449175562245)\n",
      "[2025-07-23 10:10:06,286][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X0'}\n",
      "[2025-07-23 10:10:06,286][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X0': 1.2100449175562245}\n",
      "[2025-07-23 10:10:06,287][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:10:06,287][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.12100449175562245}\n",
      "[2025-07-23 10:10:06,287][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.621004\n",
      "[2025-07-23 10:10:06,287][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.621004\n",
      "[2025-07-23 10:10:06,288][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:10:06,288][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.642, trend=-0.379\n",
      "[2025-07-23 10:10:08,790][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000218920252\n",
      "[2025-07-23 10:10:09,372][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 360):\n",
      "[2025-07-23 10:10:09,373][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -1.23537809e-01 -1.48717414e-01 -9.66648464e-02]\n",
      "[2025-07-23 10:10:09,373][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1'], Target: X2\n",
      "[2025-07-23 10:10:09,374][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:10:09,376][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:10:09,376][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.31\n",
      "[2025-07-23 10:10:09,377][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.         0.33314632 0.326816   0.34003768]\n",
      "[2025-07-23 10:10:09,377][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X0 (index 2)\n",
      "[2025-07-23 10:10:09,377][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:10:09,378][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2279, Std: 1.7590\n",
      "[2025-07-23 10:10:09,378][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.27\n",
      "[2025-07-23 10:10:09,378][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -2.0689\n",
      "[2025-07-23 10:10:09,378][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 360):\n",
      "[2025-07-23 10:10:09,379][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (2, -2.0689323236783395)\n",
      "[2025-07-23 10:10:09,379][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X0'}\n",
      "[2025-07-23 10:10:09,380][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X0': -2.0689323236783395}\n",
      "[2025-07-23 10:10:09,380][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:10:09,380][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.20689323236783397}\n",
      "[2025-07-23 10:10:09,380][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.706893\n",
      "[2025-07-23 10:10:09,381][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.706893\n",
      "[2025-07-23 10:10:09,381][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:10:09,381][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.612, trend=+0.118\n",
      "[2025-07-23 10:10:11,671][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000194728486\n",
      "[2025-07-23 10:10:11,672][causal_bayes_opt.training.enriched_trainer][INFO] - Policy Learning Diagnostics (update 45):\n",
      "[2025-07-23 10:10:11,672][causal_bayes_opt.training.enriched_trainer][INFO] -   Action magnitudes: max=2.200567\n",
      "[2025-07-23 10:10:11,672][causal_bayes_opt.training.enriched_trainer][INFO] -   Mean reward: 0.645\n",
      "[2025-07-23 10:10:11,672][causal_bayes_opt.training.enriched_trainer][INFO] -   Policy param change: 0.00019473\n",
      "[2025-07-23 10:10:11,673][causal_bayes_opt.training.enriched_trainer][INFO] -   Parameter norm change: 0.00019473\n",
      "[2025-07-23 10:10:11,673][causal_bayes_opt.training.enriched_trainer][INFO] -   Rewards: min=0.566, max=0.720, group_baseline=0.645\n",
      "[2025-07-23 10:10:11,673][causal_bayes_opt.training.enriched_trainer][INFO] -   GRPO losses: policy=0.336601, entropy=-3.523215\n",
      "[2025-07-23 10:10:11,674][causal_bayes_opt.training.enriched_trainer][INFO] -   Gradient norm: 0.08272881\n",
      "[2025-07-23 10:10:11,674][causal_bayes_opt.training.enriched_trainer][INFO] -   Learning rate: 0.001000\n",
      "[2025-07-23 10:10:11,674][causal_bayes_opt.training.enriched_trainer][INFO] -   KL penalty: 0.000000, approx_kl: 500000003.387996\n",
      "[2025-07-23 10:10:14,606][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000190860494\n",
      "[2025-07-23 10:10:14,763][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 370):\n",
      "[2025-07-23 10:10:14,764][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.32020199e-01 -1.27003913e-01 -3.55227418e-02 -1.00000000e+09]\n",
      "[2025-07-23 10:10:14,764][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1'], Target: X4\n",
      "[2025-07-23 10:10:14,765][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X4' at index 3, logit: -1000000000.0\n",
      "[2025-07-23 10:10:14,767][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:10:14,767][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.28\n",
      "[2025-07-23 10:10:14,768][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.32444919 0.32572195 0.34982885 0.        ]\n",
      "[2025-07-23 10:10:14,768][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X0 (index 2)\n",
      "[2025-07-23 10:10:14,768][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:10:14,769][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2843, Std: 1.8987\n",
      "[2025-07-23 10:10:14,769][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.26\n",
      "[2025-07-23 10:10:14,769][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 0.1627\n",
      "[2025-07-23 10:10:14,770][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 370):\n",
      "[2025-07-23 10:10:14,770][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (2, 0.16272316172352008)\n",
      "[2025-07-23 10:10:14,770][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X0'}\n",
      "[2025-07-23 10:10:14,771][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X0': 0.16272316172352008}\n",
      "[2025-07-23 10:10:14,771][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X4\n",
      "[2025-07-23 10:10:14,771][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.01627231617235201}\n",
      "[2025-07-23 10:10:14,771][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.516272\n",
      "[2025-07-23 10:10:14,772][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.516272\n",
      "[2025-07-23 10:10:14,772][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:10:14,772][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.605, trend=-0.131\n",
      "[2025-07-23 10:10:17,593][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000184387269\n",
      "[2025-07-23 10:10:17,894][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 380):\n",
      "[2025-07-23 10:10:17,895][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-7.96238246e-02 -1.06466174e-01 -7.09609870e-02 -1.00000000e+09]\n",
      "[2025-07-23 10:10:17,895][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1'], Target: X4\n",
      "[2025-07-23 10:10:17,896][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X4' at index 3, logit: -1000000000.0\n",
      "[2025-07-23 10:10:17,898][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:10:17,898][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.27\n",
      "[2025-07-23 10:10:17,898][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.33490933 0.32788111 0.33720955 0.        ]\n",
      "[2025-07-23 10:10:17,899][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X3 (index 1)\n",
      "[2025-07-23 10:10:17,899][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:10:17,899][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2593, Std: 1.6658\n",
      "[2025-07-23 10:10:17,899][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.26\n",
      "[2025-07-23 10:10:17,900][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -0.7533\n",
      "[2025-07-23 10:10:17,900][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 380):\n",
      "[2025-07-23 10:10:17,901][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (1, -0.7532546167617984)\n",
      "[2025-07-23 10:10:17,901][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X3'}\n",
      "[2025-07-23 10:10:17,901][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X3': -0.7532546167617984}\n",
      "[2025-07-23 10:10:17,902][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X4\n",
      "[2025-07-23 10:10:17,902][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.07532546167617984}\n",
      "[2025-07-23 10:10:17,902][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.575325\n",
      "[2025-07-23 10:10:17,902][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.575325\n",
      "[2025-07-23 10:10:17,903][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:10:17,903][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.598, trend=+0.035\n",
      "[2025-07-23 10:10:20,484][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000206840598\n",
      "[2025-07-23 10:10:20,927][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 390):\n",
      "[2025-07-23 10:10:20,928][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.47392142e-01 -1.29992506e-01 -1.03045389e-01 -1.00000000e+09]\n",
      "[2025-07-23 10:10:20,928][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1'], Target: X4\n",
      "[2025-07-23 10:10:20,929][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X4' at index 3, logit: -1000000000.0\n",
      "[2025-07-23 10:10:20,931][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:10:20,931][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.25\n",
      "[2025-07-23 10:10:20,932][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.32785474 0.33245029 0.33969496 0.        ]\n",
      "[2025-07-23 10:10:20,932][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X2 (index 0)\n",
      "[2025-07-23 10:10:20,933][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:10:20,933][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.1653, Std: 1.7022\n",
      "[2025-07-23 10:10:20,933][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.25\n",
      "[2025-07-23 10:10:20,933][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -2.0740\n",
      "[2025-07-23 10:10:20,934][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 390):\n",
      "[2025-07-23 10:10:20,934][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (0, -2.0740350878879443)\n",
      "[2025-07-23 10:10:20,935][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X2'}\n",
      "[2025-07-23 10:10:20,935][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X2': -2.0740350878879443}\n",
      "[2025-07-23 10:10:20,935][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X4\n",
      "[2025-07-23 10:10:20,935][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.20740350878879443}\n",
      "[2025-07-23 10:10:20,936][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.707404\n",
      "[2025-07-23 10:10:20,936][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.707404\n",
      "[2025-07-23 10:10:20,936][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:10:20,937][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.615, trend=+0.158\n",
      "[2025-07-23 10:10:23,529][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000227564299\n",
      "[2025-07-23 10:10:24,159][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 400):\n",
      "[2025-07-23 10:10:24,159][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-6.89360574e-02 -1.36795539e-01 -7.20866945e-02 -1.00000000e+09]\n",
      "[2025-07-23 10:10:24,159][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1'], Target: X4\n",
      "[2025-07-23 10:10:24,160][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X4' at index 3, logit: -1000000000.0\n",
      "[2025-07-23 10:10:24,162][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:10:24,162][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.23\n",
      "[2025-07-23 10:10:24,162][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.33967854 0.32150881 0.33881265 0.        ]\n",
      "[2025-07-23 10:10:24,163][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X3 (index 1)\n",
      "[2025-07-23 10:10:24,163][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:10:24,163][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2608, Std: 1.8202\n",
      "[2025-07-23 10:10:24,163][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.24\n",
      "[2025-07-23 10:10:24,164][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -3.1084\n",
      "[2025-07-23 10:10:24,164][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 400):\n",
      "[2025-07-23 10:10:24,165][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (1, -3.1084346094792377)\n",
      "[2025-07-23 10:10:24,165][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X3'}\n",
      "[2025-07-23 10:10:24,165][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X3': -3.1084346094792377}\n",
      "[2025-07-23 10:10:24,165][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X4\n",
      "[2025-07-23 10:10:24,166][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3108434609479238}\n",
      "[2025-07-23 10:10:24,166][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.810843\n",
      "[2025-07-23 10:10:24,166][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.810843\n",
      "[2025-07-23 10:10:24,166][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:10:24,167][causal_bayes_opt.training.enriched_trainer][INFO] -   üí∞ HIGH REWARD: Policy achieved high reward (0.811) - good performance!\n",
      "[2025-07-23 10:10:24,167][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.641, trend=+0.173\n",
      "[2025-07-23 10:10:26,586][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000266150615\n",
      "[2025-07-23 10:10:26,586][causal_bayes_opt.training.enriched_trainer][INFO] - Policy Learning Diagnostics (update 50):\n",
      "[2025-07-23 10:10:26,587][causal_bayes_opt.training.enriched_trainer][INFO] -   Action magnitudes: max=4.951922\n",
      "[2025-07-23 10:10:26,587][causal_bayes_opt.training.enriched_trainer][INFO] -   Mean reward: 0.724\n",
      "[2025-07-23 10:10:26,587][causal_bayes_opt.training.enriched_trainer][INFO] -   Policy param change: 0.00026615\n",
      "[2025-07-23 10:10:26,587][causal_bayes_opt.training.enriched_trainer][INFO] -   Parameter norm change: 0.00026615\n",
      "[2025-07-23 10:10:26,588][causal_bayes_opt.training.enriched_trainer][INFO] -   Rewards: min=0.548, max=0.995, group_baseline=0.724\n",
      "[2025-07-23 10:10:26,588][causal_bayes_opt.training.enriched_trainer][INFO] -   GRPO losses: policy=0.356712, entropy=-3.601575\n",
      "[2025-07-23 10:10:26,588][causal_bayes_opt.training.enriched_trainer][INFO] -   Gradient norm: 0.11498445\n",
      "[2025-07-23 10:10:26,589][causal_bayes_opt.training.enriched_trainer][INFO] -   Learning rate: 0.001000\n",
      "[2025-07-23 10:10:26,589][causal_bayes_opt.training.enriched_trainer][INFO] -   KL penalty: 0.000000, approx_kl: 250000003.818747\n",
      "[2025-07-23 10:10:29,512][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000299761052\n",
      "[2025-07-23 10:10:29,521][causal_bayes_opt.training.enriched_trainer][INFO] - Episode 50: reward=0.708, intervention_rate=1.000, scm=collider_5var, F1=0.000, P(Parents)=0.000, SHD=3\n",
      "[2025-07-23 10:10:29,529][causal_bayes_opt.training.modular_trainer][INFO] - Saved checkpoint: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/checkpoints/grpo_training/enriched_grpo_episode_50/checkpoint.pkl\n",
      "[2025-07-23 10:10:29,679][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 410):\n",
      "[2025-07-23 10:10:29,679][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -1.78944751e-01 -1.25296729e-01 -1.28971900e-01]\n",
      "[2025-07-23 10:10:29,680][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1'], Target: X2\n",
      "[2025-07-23 10:10:29,680][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:10:29,682][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:10:29,683][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.20\n",
      "[2025-07-23 10:10:29,683][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.         0.32383312 0.33859981 0.33756707]\n",
      "[2025-07-23 10:10:29,683][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X0 (index 2)\n",
      "[2025-07-23 10:10:29,683][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:10:29,684][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2934, Std: 1.8336\n",
      "[2025-07-23 10:10:29,684][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.23\n",
      "[2025-07-23 10:10:29,684][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -0.6499\n",
      "[2025-07-23 10:10:29,685][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 410):\n",
      "[2025-07-23 10:10:29,685][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (2, -0.6498564909354567)\n",
      "[2025-07-23 10:10:29,685][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X0'}\n",
      "[2025-07-23 10:10:29,686][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X0': -0.6498564909354567}\n",
      "[2025-07-23 10:10:29,686][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:10:29,686][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.06498564909354568}\n",
      "[2025-07-23 10:10:29,687][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.564986\n",
      "[2025-07-23 10:10:29,687][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.564986\n",
      "[2025-07-23 10:10:29,687][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:10:29,687][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.634, trend=+0.009\n",
      "[2025-07-23 10:10:32,413][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000313207544\n",
      "[2025-07-23 10:10:32,716][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 420):\n",
      "[2025-07-23 10:10:32,716][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -5.69129930e-02 -1.19245214e-01 -1.42174495e-01]\n",
      "[2025-07-23 10:10:32,717][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1'], Target: X2\n",
      "[2025-07-23 10:10:32,717][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:10:32,719][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:10:32,719][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.19\n",
      "[2025-07-23 10:10:32,720][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.         0.34727271 0.32951441 0.32321289]\n",
      "[2025-07-23 10:10:32,720][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X0 (index 2)\n",
      "[2025-07-23 10:10:32,720][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:10:32,721][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2940, Std: 2.0337\n",
      "[2025-07-23 10:10:32,721][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.23\n",
      "[2025-07-23 10:10:32,721][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 0.4429\n",
      "[2025-07-23 10:10:32,722][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 420):\n",
      "[2025-07-23 10:10:32,723][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (2, 0.4429187367045888)\n",
      "[2025-07-23 10:10:32,723][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X0'}\n",
      "[2025-07-23 10:10:32,723][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X0': 0.4429187367045888}\n",
      "[2025-07-23 10:10:32,723][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:10:32,724][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.044291873670458885}\n",
      "[2025-07-23 10:10:32,724][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.544292\n",
      "[2025-07-23 10:10:32,724][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.544292\n",
      "[2025-07-23 10:10:32,724][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:10:32,725][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.632, trend=-0.226\n",
      "[2025-07-23 10:10:35,353][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000310516175\n",
      "[2025-07-23 10:10:35,806][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 430):\n",
      "[2025-07-23 10:10:35,806][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -1.62384506e-01 -1.18076000e-01 -1.33703541e-01]\n",
      "[2025-07-23 10:10:35,807][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1'], Target: X2\n",
      "[2025-07-23 10:10:35,807][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:10:35,809][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:10:35,809][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.17\n",
      "[2025-07-23 10:10:35,810][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.         0.32644425 0.33902339 0.33453236]\n",
      "[2025-07-23 10:10:35,810][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X3 (index 1)\n",
      "[2025-07-23 10:10:35,810][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:10:35,811][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2205, Std: 1.8426\n",
      "[2025-07-23 10:10:35,811][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.22\n",
      "[2025-07-23 10:10:35,812][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 4.2686\n",
      "[2025-07-23 10:10:35,812][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 430):\n",
      "[2025-07-23 10:10:35,812][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (1, 4.268563820006647)\n",
      "[2025-07-23 10:10:35,813][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X3'}\n",
      "[2025-07-23 10:10:35,813][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X3': 4.268563820006647}\n",
      "[2025-07-23 10:10:35,813][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:10:35,813][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.4268563820006647}\n",
      "[2025-07-23 10:10:35,814][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.926856\n",
      "[2025-07-23 10:10:35,814][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.926856\n",
      "[2025-07-23 10:10:35,815][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:10:35,815][causal_bayes_opt.training.enriched_trainer][INFO] -   üí∞ HIGH REWARD: Policy achieved high reward (0.927) - good performance!\n",
      "[2025-07-23 10:10:35,815][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.648, trend=+0.421\n",
      "[2025-07-23 10:10:38,270][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000309054172\n",
      "[2025-07-23 10:10:38,911][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 440):\n",
      "[2025-07-23 10:10:38,912][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -1.69391694e-01 -1.85825588e-01 -9.63455113e-02]\n",
      "[2025-07-23 10:10:38,912][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1'], Target: X2\n",
      "[2025-07-23 10:10:38,912][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:10:38,915][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:10:38,915][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.16\n",
      "[2025-07-23 10:10:38,915][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.         0.32775057 0.32312516 0.34912427]\n",
      "[2025-07-23 10:10:38,916][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X4 (index 3)\n",
      "[2025-07-23 10:10:38,916][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:10:38,916][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2658, Std: 1.9341\n",
      "[2025-07-23 10:10:38,916][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.22\n",
      "[2025-07-23 10:10:38,917][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -3.0527\n",
      "[2025-07-23 10:10:38,917][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 440):\n",
      "[2025-07-23 10:10:38,918][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (3, -3.052667000896786)\n",
      "[2025-07-23 10:10:38,918][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X4'}\n",
      "[2025-07-23 10:10:38,918][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X4': -3.052667000896786}\n",
      "[2025-07-23 10:10:38,919][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:10:38,919][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.30526670008967866}\n",
      "[2025-07-23 10:10:38,919][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.805267\n",
      "[2025-07-23 10:10:38,919][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.805267\n",
      "[2025-07-23 10:10:38,920][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:10:38,920][causal_bayes_opt.training.enriched_trainer][INFO] -   üí∞ HIGH REWARD: Policy achieved high reward (0.805) - good performance!\n",
      "[2025-07-23 10:10:38,920][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.678, trend=+0.184\n",
      "[2025-07-23 10:10:41,214][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000305932382\n",
      "[2025-07-23 10:10:41,214][causal_bayes_opt.training.enriched_trainer][INFO] - Policy Learning Diagnostics (update 55):\n",
      "[2025-07-23 10:10:41,215][causal_bayes_opt.training.enriched_trainer][INFO] -   Action magnitudes: max=5.221530\n",
      "[2025-07-23 10:10:41,215][causal_bayes_opt.training.enriched_trainer][INFO] -   Mean reward: 0.693\n",
      "[2025-07-23 10:10:41,215][causal_bayes_opt.training.enriched_trainer][INFO] -   Policy param change: 0.00030593\n",
      "[2025-07-23 10:10:41,215][causal_bayes_opt.training.enriched_trainer][INFO] -   Parameter norm change: 0.00030593\n",
      "[2025-07-23 10:10:41,216][causal_bayes_opt.training.enriched_trainer][INFO] -   Rewards: min=0.508, max=1.000, group_baseline=0.693\n",
      "[2025-07-23 10:10:41,216][causal_bayes_opt.training.enriched_trainer][INFO] -   GRPO losses: policy=0.345632, entropy=-3.684640\n",
      "[2025-07-23 10:10:41,217][causal_bayes_opt.training.enriched_trainer][INFO] -   Gradient norm: 0.07753381\n",
      "[2025-07-23 10:10:41,217][causal_bayes_opt.training.enriched_trainer][INFO] -   Learning rate: 0.001000\n",
      "[2025-07-23 10:10:41,217][causal_bayes_opt.training.enriched_trainer][INFO] -   KL penalty: 0.000000, approx_kl: 500000003.722558\n",
      "[2025-07-23 10:10:44,101][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000290604695\n",
      "[2025-07-23 10:10:44,258][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 450):\n",
      "[2025-07-23 10:10:44,259][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -1.65175204e-01 -1.33966402e-01 -1.17601502e-01]\n",
      "[2025-07-23 10:10:44,259][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1'], Target: X2\n",
      "[2025-07-23 10:10:44,260][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:10:44,262][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:10:44,262][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.12\n",
      "[2025-07-23 10:10:44,262][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.         0.32559247 0.33475123 0.3396563 ]\n",
      "[2025-07-23 10:10:44,262][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X3 (index 1)\n",
      "[2025-07-23 10:10:44,263][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:10:44,263][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.3472, Std: 1.8132\n",
      "[2025-07-23 10:10:44,263][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.21\n",
      "[2025-07-23 10:10:44,264][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -4.4283\n",
      "[2025-07-23 10:10:44,264][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 450):\n",
      "[2025-07-23 10:10:44,264][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (1, -4.428263116886064)\n",
      "[2025-07-23 10:10:44,265][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X3'}\n",
      "[2025-07-23 10:10:44,265][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X3': -4.428263116886064}\n",
      "[2025-07-23 10:10:44,265][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:10:44,266][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.4428263116886064}\n",
      "[2025-07-23 10:10:44,266][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.942826\n",
      "[2025-07-23 10:10:44,266][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.942826\n",
      "[2025-07-23 10:10:44,267][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:10:44,267][causal_bayes_opt.training.enriched_trainer][INFO] -   üí∞ HIGH REWARD: Policy achieved high reward (0.943) - good performance!\n",
      "[2025-07-23 10:10:44,267][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.710, trend=+0.236\n",
      "[2025-07-23 10:10:47,052][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000297178510\n",
      "[2025-07-23 10:10:47,344][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 460):\n",
      "[2025-07-23 10:10:47,345][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -2.04800725e-01 -1.38907024e-01 -1.74074038e-01]\n",
      "[2025-07-23 10:10:47,345][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1'], Target: X2\n",
      "[2025-07-23 10:10:47,346][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:10:47,348][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:10:47,348][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.11\n",
      "[2025-07-23 10:10:47,349][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.         0.32369991 0.34350925 0.33279084]\n",
      "[2025-07-23 10:10:47,349][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X4 (index 3)\n",
      "[2025-07-23 10:10:47,349][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:10:47,349][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2509, Std: 2.0566\n",
      "[2025-07-23 10:10:47,350][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.20\n",
      "[2025-07-23 10:10:47,350][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 1.3610\n",
      "[2025-07-23 10:10:47,351][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 460):\n",
      "[2025-07-23 10:10:47,351][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (3, 1.361008850184344)\n",
      "[2025-07-23 10:10:47,351][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X4'}\n",
      "[2025-07-23 10:10:47,351][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X4': 1.361008850184344}\n",
      "[2025-07-23 10:10:47,352][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:10:47,352][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.1361008850184344}\n",
      "[2025-07-23 10:10:47,352][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.636101\n",
      "[2025-07-23 10:10:47,352][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.636101\n",
      "[2025-07-23 10:10:47,353][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:10:47,353][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.703, trend=+0.120\n",
      "[2025-07-23 10:10:49,944][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000297397613\n",
      "[2025-07-23 10:10:50,399][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 470):\n",
      "[2025-07-23 10:10:50,399][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -1.93218977e-01 -6.45072528e-02 -7.80253041e-02]\n",
      "[2025-07-23 10:10:50,399][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1'], Target: X2\n",
      "[2025-07-23 10:10:50,400][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:10:50,402][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:10:50,402][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.09\n",
      "[2025-07-23 10:10:50,403][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.         0.30902833 0.3476208  0.34335087]\n",
      "[2025-07-23 10:10:50,403][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X4 (index 3)\n",
      "[2025-07-23 10:10:50,404][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:10:50,404][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.3314, Std: 2.3031\n",
      "[2025-07-23 10:10:50,404][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.20\n",
      "[2025-07-23 10:10:50,405][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 1.0570\n",
      "[2025-07-23 10:10:50,405][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 470):\n",
      "[2025-07-23 10:10:50,405][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (3, 1.0569756682233253)\n",
      "[2025-07-23 10:10:50,406][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X4'}\n",
      "[2025-07-23 10:10:50,406][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X4': 1.0569756682233253}\n",
      "[2025-07-23 10:10:50,406][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:10:50,407][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.10569756682233254}\n",
      "[2025-07-23 10:10:50,407][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.605698\n",
      "[2025-07-23 10:10:50,407][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.605698\n",
      "[2025-07-23 10:10:50,407][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:10:50,408][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.712, trend=+0.030\n",
      "[2025-07-23 10:10:52,836][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000315827220\n",
      "[2025-07-23 10:10:53,437][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 480):\n",
      "[2025-07-23 10:10:53,438][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -1.56932570e-01 -2.08586784e-01 -2.20869820e-01]\n",
      "[2025-07-23 10:10:53,438][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1'], Target: X2\n",
      "[2025-07-23 10:10:53,439][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:10:53,441][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:10:53,441][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.08\n",
      "[2025-07-23 10:10:53,441][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.         0.34534697 0.32919111 0.32546193]\n",
      "[2025-07-23 10:10:53,442][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X4 (index 3)\n",
      "[2025-07-23 10:10:53,442][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:10:53,442][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2916, Std: 2.1868\n",
      "[2025-07-23 10:10:53,443][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.19\n",
      "[2025-07-23 10:10:53,443][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 4.2437\n",
      "[2025-07-23 10:10:53,443][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 480):\n",
      "[2025-07-23 10:10:53,444][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (3, 4.243714024761434)\n",
      "[2025-07-23 10:10:53,444][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X4'}\n",
      "[2025-07-23 10:10:53,444][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X4': 4.243714024761434}\n",
      "[2025-07-23 10:10:53,445][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:10:53,445][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.42437140247614336}\n",
      "[2025-07-23 10:10:53,445][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.924371\n",
      "[2025-07-23 10:10:53,446][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.924371\n",
      "[2025-07-23 10:10:53,446][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:10:53,446][causal_bayes_opt.training.enriched_trainer][INFO] -   üí∞ HIGH REWARD: Policy achieved high reward (0.924) - good performance!\n",
      "[2025-07-23 10:10:53,446][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.747, trend=+0.217\n",
      "[2025-07-23 10:10:55,805][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000363603976\n",
      "[2025-07-23 10:10:55,806][causal_bayes_opt.training.enriched_trainer][INFO] - Policy Learning Diagnostics (update 60):\n",
      "[2025-07-23 10:10:55,806][causal_bayes_opt.training.enriched_trainer][INFO] -   Action magnitudes: max=7.161930\n",
      "[2025-07-23 10:10:55,807][causal_bayes_opt.training.enriched_trainer][INFO] -   Mean reward: 0.773\n",
      "[2025-07-23 10:10:55,807][causal_bayes_opt.training.enriched_trainer][INFO] -   Policy param change: 0.00036360\n",
      "[2025-07-23 10:10:55,808][causal_bayes_opt.training.enriched_trainer][INFO] -   Parameter norm change: 0.00036360\n",
      "[2025-07-23 10:10:55,808][causal_bayes_opt.training.enriched_trainer][INFO] -   Rewards: min=0.563, max=1.000, group_baseline=0.773\n",
      "[2025-07-23 10:10:55,808][causal_bayes_opt.training.enriched_trainer][INFO] -   GRPO losses: policy=0.385107, entropy=-3.773072\n",
      "[2025-07-23 10:10:55,809][causal_bayes_opt.training.enriched_trainer][INFO] -   Gradient norm: 0.11377941\n",
      "[2025-07-23 10:10:55,809][causal_bayes_opt.training.enriched_trainer][INFO] -   Learning rate: 0.001000\n",
      "[2025-07-23 10:10:55,809][causal_bayes_opt.training.enriched_trainer][INFO] -   KL penalty: 0.000000, approx_kl: 250000004.335731\n",
      "[2025-07-23 10:11:13,848][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000381034105\n",
      "[2025-07-23 10:11:13,919][causal_bayes_opt.training.enriched_trainer][INFO] - Episode 60: reward=0.693, intervention_rate=1.000, scm=fork_6var, F1=0.000, P(Parents)=0.000, SHD=5\n",
      "[2025-07-23 10:11:14,088][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 490):\n",
      "[2025-07-23 10:11:14,089][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.70339933e-01 -1.00000000e+09 -1.51391591e-01 -1.19932671e-01\n",
      " -1.32648520e-01]\n",
      "[2025-07-23 10:11:14,089][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1', 'X5'], Target: X3\n",
      "[2025-07-23 10:11:14,089][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:11:14,091][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:11:14,092][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.05\n",
      "[2025-07-23 10:11:14,092][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.24364971 0.         0.2480999  0.25566853 0.25258185]\n",
      "[2025-07-23 10:11:14,092][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X1 (index 4)\n",
      "[2025-07-23 10:11:14,092][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:11:14,093][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.3485, Std: 2.4015\n",
      "[2025-07-23 10:11:14,093][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.18\n",
      "[2025-07-23 10:11:14,093][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 1.7568\n",
      "[2025-07-23 10:11:14,094][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 490):\n",
      "[2025-07-23 10:11:14,094][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (4, 1.7568243191957236)\n",
      "[2025-07-23 10:11:14,095][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X1'}\n",
      "[2025-07-23 10:11:14,095][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X1': 1.7568243191957236}\n",
      "[2025-07-23 10:11:14,095][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X3\n",
      "[2025-07-23 10:11:14,096][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.17568243191957236}\n",
      "[2025-07-23 10:11:14,096][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.675682\n",
      "[2025-07-23 10:11:14,096][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.675682\n",
      "[2025-07-23 10:11:14,096][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:11:14,097][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.744, trend=-0.135\n",
      "[2025-07-23 10:11:17,335][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000379700423\n",
      "[2025-07-23 10:11:17,687][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 500):\n",
      "[2025-07-23 10:11:17,688][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-2.40015021e-01 -1.00000000e+09 -1.48944125e-01 -1.69401356e-01\n",
      " -1.53630611e-01]\n",
      "[2025-07-23 10:11:17,689][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1', 'X5'], Target: X3\n",
      "[2025-07-23 10:11:17,689][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:11:17,691][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:11:17,691][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.03\n",
      "[2025-07-23 10:11:17,692][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.23526224 0.         0.25698353 0.2519359  0.25581833]\n",
      "[2025-07-23 10:11:17,692][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X4 (index 3)\n",
      "[2025-07-23 10:11:17,692][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:11:17,692][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2146, Std: 2.0795\n",
      "[2025-07-23 10:11:17,693][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.18\n",
      "[2025-07-23 10:11:17,693][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 0.1771\n",
      "[2025-07-23 10:11:17,694][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 500):\n",
      "[2025-07-23 10:11:17,694][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (3, 0.17707025024276682)\n",
      "[2025-07-23 10:11:17,694][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X4'}\n",
      "[2025-07-23 10:11:17,695][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X4': 0.17707025024276682}\n",
      "[2025-07-23 10:11:17,695][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X3\n",
      "[2025-07-23 10:11:17,695][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.017707025024276683}\n",
      "[2025-07-23 10:11:17,695][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.517707\n",
      "[2025-07-23 10:11:17,696][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.517707\n",
      "[2025-07-23 10:11:17,696][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:11:17,696][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.714, trend=-0.047\n",
      "[2025-07-23 10:11:20,775][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000384194332\n",
      "[2025-07-23 10:11:21,283][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 510):\n",
      "[2025-07-23 10:11:21,284][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.66730548e-01 -1.00000000e+09 -1.50369847e-01 -1.93356079e-01\n",
      " -1.59760700e-01]\n",
      "[2025-07-23 10:11:21,284][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1', 'X5'], Target: X3\n",
      "[2025-07-23 10:11:21,284][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:11:21,287][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:11:21,287][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.02\n",
      "[2025-07-23 10:11:21,287][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.25017197 0.         0.25423462 0.2436987  0.25189471]\n",
      "[2025-07-23 10:11:21,287][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X2 (index 0)\n",
      "[2025-07-23 10:11:21,288][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:11:21,288][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2146, Std: 2.0215\n",
      "[2025-07-23 10:11:21,288][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.17\n",
      "[2025-07-23 10:11:21,289][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 0.2031\n",
      "[2025-07-23 10:11:21,289][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 510):\n",
      "[2025-07-23 10:11:21,289][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (0, 0.203098900538846)\n",
      "[2025-07-23 10:11:21,290][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X2'}\n",
      "[2025-07-23 10:11:21,290][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X2': 0.203098900538846}\n",
      "[2025-07-23 10:11:21,290][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X3\n",
      "[2025-07-23 10:11:21,291][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.020309890053884602}\n",
      "[2025-07-23 10:11:21,291][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.520310\n",
      "[2025-07-23 10:11:21,291][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.520310\n",
      "[2025-07-23 10:11:21,291][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:11:21,292][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.710, trend=-0.024\n",
      "[2025-07-23 10:11:24,253][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000325401735\n",
      "[2025-07-23 10:11:24,977][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 520):\n",
      "[2025-07-23 10:11:24,978][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-2.13467584e-01 -1.00000000e+09 -1.43399898e-01 -2.12846514e-01\n",
      " -1.91328050e-01]\n",
      "[2025-07-23 10:11:24,978][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1', 'X5'], Target: X3\n",
      "[2025-07-23 10:11:24,978][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:11:24,981][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:11:24,981][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.00\n",
      "[2025-07-23 10:11:24,981][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.24416516 0.         0.26188685 0.24431685 0.24963114]\n",
      "[2025-07-23 10:11:24,981][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X2 (index 0)\n",
      "[2025-07-23 10:11:24,982][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:11:24,982][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.3064, Std: 2.2590\n",
      "[2025-07-23 10:11:24,982][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.17\n",
      "[2025-07-23 10:11:24,983][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 2.7067\n",
      "[2025-07-23 10:11:24,983][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 520):\n",
      "[2025-07-23 10:11:24,984][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (0, 2.7066867751454087)\n",
      "[2025-07-23 10:11:24,984][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X2'}\n",
      "[2025-07-23 10:11:24,984][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X2': 2.7066867751454087}\n",
      "[2025-07-23 10:11:24,985][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X3\n",
      "[2025-07-23 10:11:24,985][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.2706686775145409}\n",
      "[2025-07-23 10:11:24,985][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.770669\n",
      "[2025-07-23 10:11:24,985][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.770669\n",
      "[2025-07-23 10:11:24,986][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:11:24,986][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.733, trend=-0.156\n",
      "[2025-07-23 10:11:27,831][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000293936234\n",
      "[2025-07-23 10:11:27,832][causal_bayes_opt.training.enriched_trainer][INFO] - Policy Learning Diagnostics (update 65):\n",
      "[2025-07-23 10:11:27,832][causal_bayes_opt.training.enriched_trainer][INFO] -   Action magnitudes: max=9.000145\n",
      "[2025-07-23 10:11:27,833][causal_bayes_opt.training.enriched_trainer][INFO] -   Mean reward: 0.776\n",
      "[2025-07-23 10:11:27,833][causal_bayes_opt.training.enriched_trainer][INFO] -   Policy param change: 0.00029394\n",
      "[2025-07-23 10:11:27,833][causal_bayes_opt.training.enriched_trainer][INFO] -   Parameter norm change: 0.00029394\n",
      "[2025-07-23 10:11:27,834][causal_bayes_opt.training.enriched_trainer][INFO] -   Rewards: min=0.586, max=1.000, group_baseline=0.776\n",
      "[2025-07-23 10:11:27,834][causal_bayes_opt.training.enriched_trainer][INFO] -   GRPO losses: policy=0.367494, entropy=-4.094507\n",
      "[2025-07-23 10:11:27,834][causal_bayes_opt.training.enriched_trainer][INFO] -   Gradient norm: 0.08627722\n",
      "[2025-07-23 10:11:27,834][causal_bayes_opt.training.enriched_trainer][INFO] -   Learning rate: 0.001000\n",
      "[2025-07-23 10:11:27,835][causal_bayes_opt.training.enriched_trainer][INFO] -   KL penalty: 0.000000, approx_kl: 125000005.166530\n",
      "[2025-07-23 10:11:31,220][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000278580084\n",
      "[2025-07-23 10:11:31,395][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 530):\n",
      "[2025-07-23 10:11:31,396][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-0.19189148 -0.14388281 -0.13187713 -0.20447454 -0.07814488]\n",
      "[2025-07-23 10:11:31,396][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1', 'X5'], Target: X5\n",
      "[2025-07-23 10:11:31,420][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X5' at index 5, logit: -0.0781448776124136\n",
      "[2025-07-23 10:11:31,420][causal_bayes_opt.training.enriched_trainer][WARNING] - ‚ö†Ô∏è Target variable not properly masked!\n",
      "[2025-07-23 10:11:31,422][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:11:31,422][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 0.97\n",
      "[2025-07-23 10:11:31,423][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.19133639 0.2010574  0.2035646  0.1888672  0.21517442]\n",
      "[2025-07-23 10:11:31,423][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X0 (index 2)\n",
      "[2025-07-23 10:11:31,424][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:11:31,424][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.2887, Std: 2.5000\n",
      "[2025-07-23 10:11:31,424][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.16\n",
      "[2025-07-23 10:11:31,424][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 2.5760\n",
      "[2025-07-23 10:11:31,425][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 530):\n",
      "[2025-07-23 10:11:31,425][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (2, 2.5759550447769053)\n",
      "[2025-07-23 10:11:31,426][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X0'}\n",
      "[2025-07-23 10:11:31,426][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X0': 2.5759550447769053}\n",
      "[2025-07-23 10:11:31,426][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X5\n",
      "[2025-07-23 10:11:31,426][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.25759550447769053}\n",
      "[2025-07-23 10:11:31,427][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.757596\n",
      "[2025-07-23 10:11:31,427][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.757596\n",
      "[2025-07-23 10:11:31,427][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:11:31,427][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.716, trend=-0.048\n",
      "[2025-07-23 10:11:34,604][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000237174233\n",
      "[2025-07-23 10:11:34,950][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 540):\n",
      "[2025-07-23 10:11:34,951][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-0.14131871 -0.18178472 -0.08875604 -0.18042634 -0.21482559]\n",
      "[2025-07-23 10:11:34,951][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1', 'X5'], Target: X5\n",
      "[2025-07-23 10:11:34,952][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X5' at index 5, logit: -0.21482558508926097\n",
      "[2025-07-23 10:11:34,952][causal_bayes_opt.training.enriched_trainer][WARNING] - ‚ö†Ô∏è Target variable not properly masked!\n",
      "[2025-07-23 10:11:34,954][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:11:34,955][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 0.95\n",
      "[2025-07-23 10:11:34,955][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.20405225 0.19557031 0.21562134 0.19584923 0.18890687]\n",
      "[2025-07-23 10:11:34,955][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X0 (index 2)\n",
      "[2025-07-23 10:11:34,956][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:11:34,956][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.3232, Std: 2.5605\n",
      "[2025-07-23 10:11:34,956][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.15\n",
      "[2025-07-23 10:11:34,956][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 0.6632\n",
      "[2025-07-23 10:11:34,957][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 540):\n",
      "[2025-07-23 10:11:34,957][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (2, 0.6632248816384265)\n",
      "[2025-07-23 10:11:34,957][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X0'}\n",
      "[2025-07-23 10:11:34,957][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X0': 0.6632248816384265}\n",
      "[2025-07-23 10:11:34,958][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X5\n",
      "[2025-07-23 10:11:34,958][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.06632248816384266}\n",
      "[2025-07-23 10:11:34,958][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.566322\n",
      "[2025-07-23 10:11:34,959][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.566322\n",
      "[2025-07-23 10:11:34,959][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:11:34,959][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.692, trend=-0.377\n",
      "[2025-07-23 10:11:38,066][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000231422964\n",
      "[2025-07-23 10:11:38,575][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 550):\n",
      "[2025-07-23 10:11:38,576][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-0.20603759 -0.18189015 -0.20145684 -0.16862963 -0.20671786]\n",
      "[2025-07-23 10:11:38,576][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1', 'X5'], Target: X5\n",
      "[2025-07-23 10:11:38,576][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X5' at index 5, logit: -0.2067178635036729\n",
      "[2025-07-23 10:11:38,577][causal_bayes_opt.training.enriched_trainer][WARNING] - ‚ö†Ô∏è Target variable not properly masked!\n",
      "[2025-07-23 10:11:38,579][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:11:38,579][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 0.94\n",
      "[2025-07-23 10:11:38,580][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.19720081 0.20234614 0.19816671 0.20522857 0.19705776]\n",
      "[2025-07-23 10:11:38,580][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X1 (index 4)\n",
      "[2025-07-23 10:11:38,580][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:11:38,581][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.3195, Std: 2.5689\n",
      "[2025-07-23 10:11:38,581][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.15\n",
      "[2025-07-23 10:11:38,581][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -3.8384\n",
      "[2025-07-23 10:11:38,582][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 550):\n",
      "[2025-07-23 10:11:38,582][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (4, -3.8383507534245553)\n",
      "[2025-07-23 10:11:38,582][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X1'}\n",
      "[2025-07-23 10:11:38,583][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X1': -3.8383507534245553}\n",
      "[2025-07-23 10:11:38,583][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X5\n",
      "[2025-07-23 10:11:38,583][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.38383507534245553}\n",
      "[2025-07-23 10:11:38,583][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.883835\n",
      "[2025-07-23 10:11:38,584][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.883835\n",
      "[2025-07-23 10:11:38,584][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:11:38,584][causal_bayes_opt.training.enriched_trainer][INFO] -   üí∞ HIGH REWARD: Policy achieved high reward (0.884) - good performance!\n",
      "[2025-07-23 10:11:38,584][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.686, trend=+0.248\n",
      "[2025-07-23 10:11:41,438][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000284893283\n",
      "[2025-07-23 10:11:42,118][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 560):\n",
      "[2025-07-23 10:11:42,119][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-0.17029794 -0.14072337 -0.21873196 -0.15173004 -0.199796  ]\n",
      "[2025-07-23 10:11:42,119][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1', 'X5'], Target: X5\n",
      "[2025-07-23 10:11:42,120][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X5' at index 5, logit: -0.19979600068376172\n",
      "[2025-07-23 10:11:42,120][causal_bayes_opt.training.enriched_trainer][WARNING] - ‚ö†Ô∏è Target variable not properly masked!\n",
      "[2025-07-23 10:11:42,122][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:11:42,122][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 0.92\n",
      "[2025-07-23 10:11:42,123][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.20119619 0.2077554  0.19089851 0.20528966 0.19486025]\n",
      "[2025-07-23 10:11:42,123][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X2 (index 0)\n",
      "[2025-07-23 10:11:42,123][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:11:42,124][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.3520, Std: 2.3875\n",
      "[2025-07-23 10:11:42,124][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.14\n",
      "[2025-07-23 10:11:42,124][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -8.1565\n",
      "[2025-07-23 10:11:42,125][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 560):\n",
      "[2025-07-23 10:11:42,125][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (0, -8.15652382529382)\n",
      "[2025-07-23 10:11:42,126][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X2'}\n",
      "[2025-07-23 10:11:42,126][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X2': -8.15652382529382}\n",
      "[2025-07-23 10:11:42,126][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X5\n",
      "[2025-07-23 10:11:42,126][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "[2025-07-23 10:11:42,127][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 1.000000\n",
      "[2025-07-23 10:11:42,127][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 1.000000\n",
      "[2025-07-23 10:11:42,127][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:11:42,128][causal_bayes_opt.training.enriched_trainer][INFO] -   üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "[2025-07-23 10:11:42,128][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.722, trend=+0.394\n",
      "[2025-07-23 10:11:44,824][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000295211858\n",
      "[2025-07-23 10:11:44,825][causal_bayes_opt.training.enriched_trainer][INFO] - Policy Learning Diagnostics (update 70):\n",
      "[2025-07-23 10:11:44,825][causal_bayes_opt.training.enriched_trainer][INFO] -   Action magnitudes: max=8.156524\n",
      "[2025-07-23 10:11:44,826][causal_bayes_opt.training.enriched_trainer][INFO] -   Mean reward: 0.793\n",
      "[2025-07-23 10:11:44,826][causal_bayes_opt.training.enriched_trainer][INFO] -   Policy param change: 0.00029521\n",
      "[2025-07-23 10:11:44,826][causal_bayes_opt.training.enriched_trainer][INFO] -   Parameter norm change: 0.00029521\n",
      "[2025-07-23 10:11:44,826][causal_bayes_opt.training.enriched_trainer][INFO] -   Rewards: min=0.570, max=1.000, group_baseline=0.793\n",
      "[2025-07-23 10:11:44,827][causal_bayes_opt.training.enriched_trainer][INFO] -   GRPO losses: policy=0.337112, entropy=-4.196962\n",
      "[2025-07-23 10:11:44,827][causal_bayes_opt.training.enriched_trainer][INFO] -   Gradient norm: 0.09025378\n",
      "[2025-07-23 10:11:44,827][causal_bayes_opt.training.enriched_trainer][INFO] -   Learning rate: 0.001000\n",
      "[2025-07-23 10:11:44,828][causal_bayes_opt.training.enriched_trainer][INFO] -   KL penalty: 0.000000, approx_kl: 4.513535\n",
      "[2025-07-23 10:11:48,206][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000346676018\n",
      "[2025-07-23 10:11:48,214][causal_bayes_opt.training.enriched_trainer][INFO] - Episode 70: reward=0.720, intervention_rate=1.000, scm=collider_6var, F1=0.000, P(Parents)=0.000, SHD=3\n",
      "[2025-07-23 10:11:48,385][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 570):\n",
      "[2025-07-23 10:11:48,386][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-9.32723970e-02 -1.00000000e+09 -1.51293670e-01 -1.63829489e-01\n",
      " -2.23393245e-01]\n",
      "[2025-07-23 10:11:48,386][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1', 'X5'], Target: X3\n",
      "[2025-07-23 10:11:48,387][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:11:48,389][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:11:48,389][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 0.89\n",
      "[2025-07-23 10:11:48,389][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.26846822 0.         0.25153594 0.24802029 0.23197555]\n",
      "[2025-07-23 10:11:48,389][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X0 (index 2)\n",
      "[2025-07-23 10:11:48,389][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:11:48,390][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.3534, Std: 2.8704\n",
      "[2025-07-23 10:11:48,390][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.13\n",
      "[2025-07-23 10:11:48,390][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 1.5618\n",
      "[2025-07-23 10:11:48,391][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 570):\n",
      "[2025-07-23 10:11:48,391][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (2, 1.5617853193552746)\n",
      "[2025-07-23 10:11:48,391][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X0'}\n",
      "[2025-07-23 10:11:48,392][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X0': 1.5617853193552746}\n",
      "[2025-07-23 10:11:48,392][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X3\n",
      "[2025-07-23 10:11:48,392][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.15617853193552747}\n",
      "[2025-07-23 10:11:48,393][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.656179\n",
      "[2025-07-23 10:11:48,393][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.656179\n",
      "[2025-07-23 10:11:48,393][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:11:48,393][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.727, trend=-0.268\n",
      "[2025-07-23 10:11:51,568][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000309779256\n",
      "[2025-07-23 10:11:51,904][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 580):\n",
      "[2025-07-23 10:11:51,905][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-2.02907897e-01 -1.00000000e+09 -2.50265834e-01 -1.04938818e-01\n",
      " -2.19869853e-01]\n",
      "[2025-07-23 10:11:51,905][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1', 'X5'], Target: X3\n",
      "[2025-07-23 10:11:51,905][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:11:51,908][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:11:51,908][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 0.88\n",
      "[2025-07-23 10:11:51,908][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.24712164 0.         0.2341021  0.27639897 0.2423773 ]\n",
      "[2025-07-23 10:11:51,908][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X0 (index 2)\n",
      "[2025-07-23 10:11:51,909][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:11:51,909][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.3680, Std: 2.9795\n",
      "[2025-07-23 10:11:51,909][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.12\n",
      "[2025-07-23 10:11:51,909][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -4.1931\n",
      "[2025-07-23 10:11:51,910][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 580):\n",
      "[2025-07-23 10:11:51,910][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (2, -4.1931287368843355)\n",
      "[2025-07-23 10:11:51,911][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X0'}\n",
      "[2025-07-23 10:11:51,911][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X0': -4.1931287368843355}\n",
      "[2025-07-23 10:11:51,912][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X3\n",
      "[2025-07-23 10:11:51,912][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.41931287368843356}\n",
      "[2025-07-23 10:11:51,912][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.919313\n",
      "[2025-07-23 10:11:51,913][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.919313\n",
      "[2025-07-23 10:11:51,913][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:11:51,913][causal_bayes_opt.training.enriched_trainer][INFO] -   üí∞ HIGH REWARD: Policy achieved high reward (0.919) - good performance!\n",
      "[2025-07-23 10:11:51,913][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.727, trend=+0.244\n",
      "[2025-07-23 10:11:54,936][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000343935833\n",
      "[2025-07-23 10:11:55,439][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 590):\n",
      "[2025-07-23 10:11:55,440][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.53693065e-01 -1.00000000e+09 -2.21672878e-01 -1.89523556e-01\n",
      " -2.04638891e-01]\n",
      "[2025-07-23 10:11:55,440][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1', 'X5'], Target: X3\n",
      "[2025-07-23 10:11:55,441][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:11:55,442][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:11:55,443][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 0.86\n",
      "[2025-07-23 10:11:55,443][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.26140045 0.         0.24151938 0.25072578 0.24635439]\n",
      "[2025-07-23 10:11:55,443][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X0 (index 2)\n",
      "[2025-07-23 10:11:55,444][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:11:55,444][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.3019, Std: 2.6431\n",
      "[2025-07-23 10:11:55,444][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.12\n",
      "[2025-07-23 10:11:55,445][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 4.9553\n",
      "[2025-07-23 10:11:55,445][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 590):\n",
      "[2025-07-23 10:11:55,446][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (2, 4.955262087911175)\n",
      "[2025-07-23 10:11:55,446][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X0'}\n",
      "[2025-07-23 10:11:55,446][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X0': 4.955262087911175}\n",
      "[2025-07-23 10:11:55,446][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X3\n",
      "[2025-07-23 10:11:55,447][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.4955262087911175}\n",
      "[2025-07-23 10:11:55,447][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.995526\n",
      "[2025-07-23 10:11:55,447][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.995526\n",
      "[2025-07-23 10:11:55,447][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:11:55,448][causal_bayes_opt.training.enriched_trainer][INFO] -   üí∞ HIGH REWARD: Policy achieved high reward (0.996) - good performance!\n",
      "[2025-07-23 10:11:55,448][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.759, trend=+0.478\n",
      "[2025-07-23 10:11:58,361][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000357121909\n",
      "[2025-07-23 10:11:59,044][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 600):\n",
      "[2025-07-23 10:11:59,045][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.42806398e-01 -1.00000000e+09 -1.24648050e-01 -2.03489114e-01\n",
      " -2.24557869e-01]\n",
      "[2025-07-23 10:11:59,046][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1', 'X5'], Target: X3\n",
      "[2025-07-23 10:11:59,046][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X3' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:11:59,048][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:11:59,048][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 0.84\n",
      "[2025-07-23 10:11:59,049][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.25906638 0.         0.26470217 0.24108849 0.23514296]\n",
      "[2025-07-23 10:11:59,049][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X0 (index 2)\n",
      "[2025-07-23 10:11:59,049][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:11:59,050][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.3641, Std: 2.7684\n",
      "[2025-07-23 10:11:59,050][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.11\n",
      "[2025-07-23 10:11:59,050][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 1.3130\n",
      "[2025-07-23 10:11:59,051][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 600):\n",
      "[2025-07-23 10:11:59,051][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (2, 1.3130402371179675)\n",
      "[2025-07-23 10:11:59,051][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X0'}\n",
      "[2025-07-23 10:11:59,052][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X0': 1.3130402371179675}\n",
      "[2025-07-23 10:11:59,052][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X3\n",
      "[2025-07-23 10:11:59,052][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.13130402371179675}\n",
      "[2025-07-23 10:11:59,052][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.631304\n",
      "[2025-07-23 10:11:59,053][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.631304\n",
      "[2025-07-23 10:11:59,053][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:11:59,053][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.770, trend=+0.111\n",
      "[2025-07-23 10:12:01,968][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000372331400\n",
      "[2025-07-23 10:12:01,968][causal_bayes_opt.training.enriched_trainer][INFO] - Policy Learning Diagnostics (update 75):\n",
      "[2025-07-23 10:12:01,968][causal_bayes_opt.training.enriched_trainer][INFO] -   Action magnitudes: max=6.597422\n",
      "[2025-07-23 10:12:01,969][causal_bayes_opt.training.enriched_trainer][INFO] -   Mean reward: 0.836\n",
      "[2025-07-23 10:12:01,969][causal_bayes_opt.training.enriched_trainer][INFO] -   Policy param change: 0.00037233\n",
      "[2025-07-23 10:12:01,969][causal_bayes_opt.training.enriched_trainer][INFO] -   Parameter norm change: 0.00037233\n",
      "[2025-07-23 10:12:01,970][causal_bayes_opt.training.enriched_trainer][INFO] -   Rewards: min=0.631, max=1.000, group_baseline=0.836\n",
      "[2025-07-23 10:12:01,970][causal_bayes_opt.training.enriched_trainer][INFO] -   GRPO losses: policy=0.348188, entropy=-4.304667\n",
      "[2025-07-23 10:12:01,970][causal_bayes_opt.training.enriched_trainer][INFO] -   Gradient norm: 0.08793269\n",
      "[2025-07-23 10:12:01,971][causal_bayes_opt.training.enriched_trainer][INFO] -   Learning rate: 0.001000\n",
      "[2025-07-23 10:12:01,971][causal_bayes_opt.training.enriched_trainer][INFO] -   KL penalty: 0.000000, approx_kl: 125000004.407092\n",
      "[2025-07-23 10:12:05,557][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000386437405\n",
      "[2025-07-23 10:12:05,736][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 610):\n",
      "[2025-07-23 10:12:05,736][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.57103345e-01 -1.16631284e-01 -1.31725022e-01 -1.00000000e+09\n",
      " -1.10730893e-01]\n",
      "[2025-07-23 10:12:05,737][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1', 'X5'], Target: X4\n",
      "[2025-07-23 10:12:05,737][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X4' at index 3, logit: -1000000000.0\n",
      "[2025-07-23 10:12:05,739][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:12:05,740][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 0.81\n",
      "[2025-07-23 10:12:05,740][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.24145637 0.25378833 0.24911725 0.         0.25563805]\n",
      "[2025-07-23 10:12:05,740][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X3 (index 1)\n",
      "[2025-07-23 10:12:05,741][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:12:05,741][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.3933, Std: 3.3128\n",
      "[2025-07-23 10:12:05,741][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.10\n",
      "[2025-07-23 10:12:05,741][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 3.3166\n",
      "[2025-07-23 10:12:05,742][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 610):\n",
      "[2025-07-23 10:12:05,742][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (1, 3.3165798748232533)\n",
      "[2025-07-23 10:12:05,743][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X3'}\n",
      "[2025-07-23 10:12:05,743][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X3': 3.3165798748232533}\n",
      "[2025-07-23 10:12:05,743][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X4\n",
      "[2025-07-23 10:12:05,744][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.33165798748232533}\n",
      "[2025-07-23 10:12:05,744][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.831658\n",
      "[2025-07-23 10:12:05,744][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.831658\n",
      "[2025-07-23 10:12:05,744][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:12:05,745][causal_bayes_opt.training.enriched_trainer][INFO] -   üí∞ HIGH REWARD: Policy achieved high reward (0.832) - good performance!\n",
      "[2025-07-23 10:12:05,745][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.801, trend=+0.061\n",
      "[2025-07-23 10:12:08,985][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000386553409\n",
      "[2025-07-23 10:12:09,363][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 620):\n",
      "[2025-07-23 10:12:09,363][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.60936125e-01 -1.62313293e-01 -1.80580098e-01 -1.00000000e+09\n",
      " -1.74551323e-01]\n",
      "[2025-07-23 10:12:09,364][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1', 'X5'], Target: X4\n",
      "[2025-07-23 10:12:09,364][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X4' at index 3, logit: -1000000000.0\n",
      "[2025-07-23 10:12:09,366][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:12:09,367][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 0.80\n",
      "[2025-07-23 10:12:09,367][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.2527178  0.25228143 0.24656415 0.         0.24843661]\n",
      "[2025-07-23 10:12:09,367][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X3 (index 1)\n",
      "[2025-07-23 10:12:09,368][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:12:09,368][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.3908, Std: 3.3337\n",
      "[2025-07-23 10:12:09,368][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.10\n",
      "[2025-07-23 10:12:09,368][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 2.2004\n",
      "[2025-07-23 10:12:09,369][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 620):\n",
      "[2025-07-23 10:12:09,369][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (1, 2.2004050890001015)\n",
      "[2025-07-23 10:12:09,370][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X3'}\n",
      "[2025-07-23 10:12:09,370][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X3': 2.2004050890001015}\n",
      "[2025-07-23 10:12:09,370][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X4\n",
      "[2025-07-23 10:12:09,371][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.22004050890001015}\n",
      "[2025-07-23 10:12:09,371][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.720041\n",
      "[2025-07-23 10:12:09,371][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.720041\n",
      "[2025-07-23 10:12:09,371][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:12:09,372][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.796, trend=-0.038\n",
      "[2025-07-23 10:12:12,506][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000370294393\n",
      "[2025-07-23 10:12:13,048][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 630):\n",
      "[2025-07-23 10:12:13,049][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.58007206e-01 -1.14829201e-01 -1.06036040e-01 -1.00000000e+09\n",
      " -1.78617308e-01]\n",
      "[2025-07-23 10:12:13,049][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1', 'X5'], Target: X4\n",
      "[2025-07-23 10:12:13,050][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X4' at index 3, logit: -1000000000.0\n",
      "[2025-07-23 10:12:13,052][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:12:13,053][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 0.78\n",
      "[2025-07-23 10:12:13,053][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.24392783 0.25778869 0.26070656 0.         0.23757692]\n",
      "[2025-07-23 10:12:13,053][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X2 (index 0)\n",
      "[2025-07-23 10:12:13,053][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:12:13,054][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.3226, Std: 3.2501\n",
      "[2025-07-23 10:12:13,054][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.09\n",
      "[2025-07-23 10:12:13,054][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 0.6623\n",
      "[2025-07-23 10:12:13,055][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 630):\n",
      "[2025-07-23 10:12:13,056][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (0, 0.6622556064962224)\n",
      "[2025-07-23 10:12:13,056][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X2'}\n",
      "[2025-07-23 10:12:13,056][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X2': 0.6622556064962224}\n",
      "[2025-07-23 10:12:13,056][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X4\n",
      "[2025-07-23 10:12:13,057][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.06622556064962225}\n",
      "[2025-07-23 10:12:13,057][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.566226\n",
      "[2025-07-23 10:12:13,057][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.566226\n",
      "[2025-07-23 10:12:13,058][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:12:13,058][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.777, trend=-0.000\n",
      "[2025-07-23 10:12:16,116][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000373479320\n",
      "[2025-07-23 10:12:16,825][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 640):\n",
      "[2025-07-23 10:12:16,825][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.31530718e-01 -1.77086412e-01 -1.63450942e-01 -1.00000000e+09\n",
      " -1.65319132e-01]\n",
      "[2025-07-23 10:12:16,826][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X3', 'X0', 'X4', 'X1', 'X5'], Target: X4\n",
      "[2025-07-23 10:12:16,826][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X4' at index 3, logit: -1000000000.0\n",
      "[2025-07-23 10:12:16,828][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:12:16,829][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 0.77\n",
      "[2025-07-23 10:12:16,829][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0.25918637 0.24421429 0.24860261 0.         0.24799673]\n",
      "[2025-07-23 10:12:16,829][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X1 (index 4)\n",
      "[2025-07-23 10:12:16,829][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:12:16,830][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.3613, Std: 3.3182\n",
      "[2025-07-23 10:12:16,830][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.09\n",
      "[2025-07-23 10:12:16,830][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 2.4490\n",
      "[2025-07-23 10:12:16,831][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 640):\n",
      "[2025-07-23 10:12:16,831][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (4, 2.4489897670434777)\n",
      "[2025-07-23 10:12:16,831][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X1'}\n",
      "[2025-07-23 10:12:16,832][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X1': 2.4489897670434777}\n",
      "[2025-07-23 10:12:16,832][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X4\n",
      "[2025-07-23 10:12:16,832][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.2448989767043478}\n",
      "[2025-07-23 10:12:16,833][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.744899\n",
      "[2025-07-23 10:12:16,833][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.744899\n",
      "[2025-07-23 10:12:16,833][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:12:16,833][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.795, trend=-0.139\n",
      "[2025-07-23 10:12:19,666][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000396388210\n",
      "[2025-07-23 10:12:19,666][causal_bayes_opt.training.enriched_trainer][INFO] - Policy Learning Diagnostics (update 80):\n",
      "[2025-07-23 10:12:19,666][causal_bayes_opt.training.enriched_trainer][INFO] -   Action magnitudes: max=4.625168\n",
      "[2025-07-23 10:12:19,667][causal_bayes_opt.training.enriched_trainer][INFO] -   Mean reward: 0.728\n",
      "[2025-07-23 10:12:19,667][causal_bayes_opt.training.enriched_trainer][INFO] -   Policy param change: 0.00039639\n",
      "[2025-07-23 10:12:19,667][causal_bayes_opt.training.enriched_trainer][INFO] -   Parameter norm change: 0.00039639\n",
      "[2025-07-23 10:12:19,668][causal_bayes_opt.training.enriched_trainer][INFO] -   Rewards: min=0.562, max=0.963, group_baseline=0.728\n",
      "[2025-07-23 10:12:19,668][causal_bayes_opt.training.enriched_trainer][INFO] -   GRPO losses: policy=0.309738, entropy=-4.418379\n",
      "[2025-07-23 10:12:19,668][causal_bayes_opt.training.enriched_trainer][INFO] -   Gradient norm: 0.06563814\n",
      "[2025-07-23 10:12:19,669][causal_bayes_opt.training.enriched_trainer][INFO] -   Learning rate: 0.001000\n",
      "[2025-07-23 10:12:19,669][causal_bayes_opt.training.enriched_trainer][INFO] -   KL penalty: 0.000000, approx_kl: 250000004.094884\n",
      "[2025-07-23 10:12:21,721][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000432952821\n",
      "[2025-07-23 10:12:21,729][causal_bayes_opt.training.enriched_trainer][INFO] - Episode 80: reward=0.806, intervention_rate=1.000, scm=fork_3var, F1=0.000, P(Parents)=0.000, SHD=2\n",
      "[2025-07-23 10:12:21,897][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 650):\n",
      "[2025-07-23 10:12:21,897][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.29860195e-01 -1.00000000e+09]\n",
      "[2025-07-23 10:12:21,898][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "[2025-07-23 10:12:21,898][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:12:21,901][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:12:21,901][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 0.73\n",
      "[2025-07-23 10:12:21,901][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [1. 0.]\n",
      "[2025-07-23 10:12:21,902][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X2 (index 0)\n",
      "[2025-07-23 10:12:21,902][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:12:21,903][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.4002, Std: 3.6250\n",
      "[2025-07-23 10:12:21,903][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.08\n",
      "[2025-07-23 10:12:21,903][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -0.6322\n",
      "[2025-07-23 10:12:21,904][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 650):\n",
      "[2025-07-23 10:12:21,904][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (0, -0.6321748189389849)\n",
      "[2025-07-23 10:12:21,904][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X2'}\n",
      "[2025-07-23 10:12:21,904][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X2': -0.6321748189389849}\n",
      "[2025-07-23 10:12:21,905][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X1\n",
      "[2025-07-23 10:12:21,905][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.06321748189389849}\n",
      "[2025-07-23 10:12:21,905][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.563217\n",
      "[2025-07-23 10:12:21,906][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.563217\n",
      "[2025-07-23 10:12:21,906][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:12:21,907][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.763, trend=-0.437\n",
      "[2025-07-23 10:12:23,800][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000420353312\n",
      "[2025-07-23 10:12:24,038][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 660):\n",
      "[2025-07-23 10:12:24,039][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-8.99937417e-02 -1.00000000e+09]\n",
      "[2025-07-23 10:12:24,039][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "[2025-07-23 10:12:24,040][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:12:24,043][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:12:24,043][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 0.72\n",
      "[2025-07-23 10:12:24,043][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [1. 0.]\n",
      "[2025-07-23 10:12:24,044][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X2 (index 0)\n",
      "[2025-07-23 10:12:24,044][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:12:24,045][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.4164, Std: 3.7447\n",
      "[2025-07-23 10:12:24,046][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.07\n",
      "[2025-07-23 10:12:24,046][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -7.3168\n",
      "[2025-07-23 10:12:24,047][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 660):\n",
      "[2025-07-23 10:12:24,047][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (0, -7.316820423071935)\n",
      "[2025-07-23 10:12:24,047][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X2'}\n",
      "[2025-07-23 10:12:24,047][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X2': -7.316820423071935}\n",
      "[2025-07-23 10:12:24,048][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X1\n",
      "[2025-07-23 10:12:24,048][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "[2025-07-23 10:12:24,048][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 1.000000\n",
      "[2025-07-23 10:12:24,048][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 1.000000\n",
      "[2025-07-23 10:12:24,049][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:12:24,049][causal_bayes_opt.training.enriched_trainer][INFO] -   üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "[2025-07-23 10:12:24,049][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.763, trend=+0.344\n",
      "[2025-07-23 10:12:25,816][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000421474175\n",
      "[2025-07-23 10:12:26,171][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 670):\n",
      "[2025-07-23 10:12:26,172][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.46348947e-01 -1.00000000e+09]\n",
      "[2025-07-23 10:12:26,172][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "[2025-07-23 10:12:26,172][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:12:26,175][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:12:26,175][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 0.70\n",
      "[2025-07-23 10:12:26,175][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [1. 0.]\n",
      "[2025-07-23 10:12:26,176][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X2 (index 0)\n",
      "[2025-07-23 10:12:26,176][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:12:26,176][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.4243, Std: 3.8882\n",
      "[2025-07-23 10:12:26,177][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.07\n",
      "[2025-07-23 10:12:26,177][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 1.3707\n",
      "[2025-07-23 10:12:26,177][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 670):\n",
      "[2025-07-23 10:12:26,178][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (0, 1.370652900121811)\n",
      "[2025-07-23 10:12:26,178][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X2'}\n",
      "[2025-07-23 10:12:26,178][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X2': 1.370652900121811}\n",
      "[2025-07-23 10:12:26,179][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X1\n",
      "[2025-07-23 10:12:26,179][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.13706529001218112}\n",
      "[2025-07-23 10:12:26,179][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.637065\n",
      "[2025-07-23 10:12:26,179][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.637065\n",
      "[2025-07-23 10:12:26,179][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:12:26,180][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.761, trend=-0.282\n",
      "[2025-07-23 10:12:27,755][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000425990932\n",
      "[2025-07-23 10:12:28,205][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 680):\n",
      "[2025-07-23 10:12:28,206][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-8.42139038e-02 -1.00000000e+09]\n",
      "[2025-07-23 10:12:28,206][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "[2025-07-23 10:12:28,207][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:12:28,209][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:12:28,209][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 0.69\n",
      "[2025-07-23 10:12:28,210][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [1. 0.]\n",
      "[2025-07-23 10:12:28,210][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X2 (index 0)\n",
      "[2025-07-23 10:12:28,210][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:12:28,211][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.3955, Std: 3.5640\n",
      "[2025-07-23 10:12:28,211][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.06\n",
      "[2025-07-23 10:12:28,211][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -0.9601\n",
      "[2025-07-23 10:12:28,212][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 680):\n",
      "[2025-07-23 10:12:28,212][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (0, -0.9601035731439292)\n",
      "[2025-07-23 10:12:28,212][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X2'}\n",
      "[2025-07-23 10:12:28,213][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X2': -0.9601035731439292}\n",
      "[2025-07-23 10:12:28,213][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X1\n",
      "[2025-07-23 10:12:28,213][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.09601035731439293}\n",
      "[2025-07-23 10:12:28,214][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.596010\n",
      "[2025-07-23 10:12:28,214][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.596010\n",
      "[2025-07-23 10:12:28,214][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:12:28,215][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.729, trend=-0.400\n",
      "[2025-07-23 10:12:29,709][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000391603268\n",
      "[2025-07-23 10:12:29,710][causal_bayes_opt.training.enriched_trainer][INFO] - Policy Learning Diagnostics (update 85):\n",
      "[2025-07-23 10:12:29,710][causal_bayes_opt.training.enriched_trainer][INFO] -   Action magnitudes: max=4.576601\n",
      "[2025-07-23 10:12:29,710][causal_bayes_opt.training.enriched_trainer][INFO] -   Mean reward: 0.705\n",
      "[2025-07-23 10:12:29,711][causal_bayes_opt.training.enriched_trainer][INFO] -   Policy param change: 0.00039160\n",
      "[2025-07-23 10:12:29,711][causal_bayes_opt.training.enriched_trainer][INFO] -   Parameter norm change: 0.00039160\n",
      "[2025-07-23 10:12:29,711][causal_bayes_opt.training.enriched_trainer][INFO] -   Rewards: min=0.530, max=0.958, group_baseline=0.705\n",
      "[2025-07-23 10:12:29,712][causal_bayes_opt.training.enriched_trainer][INFO] -   GRPO losses: policy=0.350239, entropy=-3.630982\n",
      "[2025-07-23 10:12:29,712][causal_bayes_opt.training.enriched_trainer][INFO] -   Gradient norm: 0.04097654\n",
      "[2025-07-23 10:12:29,713][causal_bayes_opt.training.enriched_trainer][INFO] -   Learning rate: 0.001000\n",
      "[2025-07-23 10:12:29,713][causal_bayes_opt.training.enriched_trainer][INFO] -   KL penalty: 0.000000, approx_kl: 3.277268\n",
      "[2025-07-23 10:12:31,634][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000442539529\n",
      "[2025-07-23 10:12:31,754][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 690):\n",
      "[2025-07-23 10:12:31,755][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -1.21944781e-01]\n",
      "[2025-07-23 10:12:31,755][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X1', 'X0'], Target: X2\n",
      "[2025-07-23 10:12:31,756][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:12:31,758][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:12:31,759][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 0.66\n",
      "[2025-07-23 10:12:31,759][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0. 1.]\n",
      "[2025-07-23 10:12:31,759][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X1 (index 1)\n",
      "[2025-07-23 10:12:31,760][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:12:31,760][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.3355, Std: 3.2671\n",
      "[2025-07-23 10:12:31,760][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.05\n",
      "[2025-07-23 10:12:31,760][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -3.6797\n",
      "[2025-07-23 10:12:31,761][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 690):\n",
      "[2025-07-23 10:12:31,761][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (1, -3.679721123296076)\n",
      "[2025-07-23 10:12:31,761][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X1'}\n",
      "[2025-07-23 10:12:31,762][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X1': -3.679721123296076}\n",
      "[2025-07-23 10:12:31,762][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:12:31,762][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.3679721123296076}\n",
      "[2025-07-23 10:12:31,763][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.867972\n",
      "[2025-07-23 10:12:31,763][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.867972\n",
      "[2025-07-23 10:12:31,763][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:12:31,763][causal_bayes_opt.training.enriched_trainer][INFO] -   üí∞ HIGH REWARD: Policy achieved high reward (0.868) - good performance!\n",
      "[2025-07-23 10:12:31,764][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.716, trend=+0.237\n",
      "[2025-07-23 10:12:33,638][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000525199940\n",
      "[2025-07-23 10:12:33,871][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 700):\n",
      "[2025-07-23 10:12:33,872][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -1.33382609e-01]\n",
      "[2025-07-23 10:12:33,872][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X1', 'X0'], Target: X2\n",
      "[2025-07-23 10:12:33,873][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:12:33,875][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:12:33,875][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 0.64\n",
      "[2025-07-23 10:12:33,876][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0. 1.]\n",
      "[2025-07-23 10:12:33,876][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X1 (index 1)\n",
      "[2025-07-23 10:12:33,876][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:12:33,876][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.4358, Std: 4.2661\n",
      "[2025-07-23 10:12:33,877][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.05\n",
      "[2025-07-23 10:12:33,877][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -4.2629\n",
      "[2025-07-23 10:12:33,877][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 700):\n",
      "[2025-07-23 10:12:33,878][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (1, -4.2628860373161945)\n",
      "[2025-07-23 10:12:33,878][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X1'}\n",
      "[2025-07-23 10:12:33,878][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X1': -4.2628860373161945}\n",
      "[2025-07-23 10:12:33,879][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:12:33,879][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.4262886037316195}\n",
      "[2025-07-23 10:12:33,879][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.926289\n",
      "[2025-07-23 10:12:33,879][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.926289\n",
      "[2025-07-23 10:12:33,880][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:12:33,880][causal_bayes_opt.training.enriched_trainer][INFO] -   üí∞ HIGH REWARD: Policy achieved high reward (0.926) - good performance!\n",
      "[2025-07-23 10:12:33,880][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.745, trend=+0.095\n",
      "[2025-07-23 10:12:35,601][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000595583229\n",
      "[2025-07-23 10:12:35,943][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 710):\n",
      "[2025-07-23 10:12:35,943][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -9.98191799e-02]\n",
      "[2025-07-23 10:12:35,944][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X1', 'X0'], Target: X2\n",
      "[2025-07-23 10:12:35,944][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:12:35,946][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:12:35,947][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 0.62\n",
      "[2025-07-23 10:12:35,947][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0. 1.]\n",
      "[2025-07-23 10:12:35,948][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X1 (index 1)\n",
      "[2025-07-23 10:12:35,948][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:12:35,948][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.4607, Std: 4.5497\n",
      "[2025-07-23 10:12:35,948][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.04\n",
      "[2025-07-23 10:12:35,949][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -6.8302\n",
      "[2025-07-23 10:12:35,949][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 710):\n",
      "[2025-07-23 10:12:35,949][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (1, -6.8301828635790605)\n",
      "[2025-07-23 10:12:35,950][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X1'}\n",
      "[2025-07-23 10:12:35,950][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X1': -6.8301828635790605}\n",
      "[2025-07-23 10:12:35,950][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:12:35,951][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.5}\n",
      "[2025-07-23 10:12:35,951][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 1.000000\n",
      "[2025-07-23 10:12:35,951][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 1.000000\n",
      "[2025-07-23 10:12:35,951][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:12:35,952][causal_bayes_opt.training.enriched_trainer][INFO] -   üí∞ HIGH REWARD: Policy achieved high reward (1.000) - good performance!\n",
      "[2025-07-23 10:12:35,952][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.762, trend=+0.280\n",
      "[2025-07-23 10:12:37,556][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000696878870\n",
      "[2025-07-23 10:12:38,203][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 720):\n",
      "[2025-07-23 10:12:38,204][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-1.00000000e+09 -1.09806682e-01]\n",
      "[2025-07-23 10:12:38,204][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X1', 'X0'], Target: X2\n",
      "[2025-07-23 10:12:38,204][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X2' at index 0, logit: -1000000000.0\n",
      "[2025-07-23 10:12:38,206][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:12:38,207][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 0.61\n",
      "[2025-07-23 10:12:38,207][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [0. 1.]\n",
      "[2025-07-23 10:12:38,207][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X1 (index 1)\n",
      "[2025-07-23 10:12:38,208][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:12:38,208][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.4386, Std: 4.4268\n",
      "[2025-07-23 10:12:38,208][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.04\n",
      "[2025-07-23 10:12:38,209][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -2.6706\n",
      "[2025-07-23 10:12:38,209][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 720):\n",
      "[2025-07-23 10:12:38,210][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (1, -2.670637602681309)\n",
      "[2025-07-23 10:12:38,210][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X1'}\n",
      "[2025-07-23 10:12:38,210][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X1': -2.670637602681309}\n",
      "[2025-07-23 10:12:38,211][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X2\n",
      "[2025-07-23 10:12:38,211][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.2670637602681309}\n",
      "[2025-07-23 10:12:38,211][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.767064\n",
      "[2025-07-23 10:12:38,212][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.767064\n",
      "[2025-07-23 10:12:38,213][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:12:38,216][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.767, trend=+0.201\n",
      "[2025-07-23 10:12:39,725][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000797486098\n",
      "[2025-07-23 10:12:39,725][causal_bayes_opt.training.enriched_trainer][INFO] - Policy Learning Diagnostics (update 90):\n",
      "[2025-07-23 10:12:39,726][causal_bayes_opt.training.enriched_trainer][INFO] -   Action magnitudes: max=6.489645\n",
      "[2025-07-23 10:12:39,726][causal_bayes_opt.training.enriched_trainer][INFO] -   Mean reward: 0.774\n",
      "[2025-07-23 10:12:39,726][causal_bayes_opt.training.enriched_trainer][INFO] -   Policy param change: 0.00079749\n",
      "[2025-07-23 10:12:39,726][causal_bayes_opt.training.enriched_trainer][INFO] -   Parameter norm change: 0.00079749\n",
      "[2025-07-23 10:12:39,727][causal_bayes_opt.training.enriched_trainer][INFO] -   Rewards: min=0.516, max=1.000, group_baseline=0.774\n",
      "[2025-07-23 10:12:39,727][causal_bayes_opt.training.enriched_trainer][INFO] -   GRPO losses: policy=0.299161, entropy=-3.765862\n",
      "[2025-07-23 10:12:39,727][causal_bayes_opt.training.enriched_trainer][INFO] -   Gradient norm: 0.08629717\n",
      "[2025-07-23 10:12:39,728][causal_bayes_opt.training.enriched_trainer][INFO] -   Learning rate: 0.001000\n",
      "[2025-07-23 10:12:39,728][causal_bayes_opt.training.enriched_trainer][INFO] -   KL penalty: 0.000000, approx_kl: 3.527629\n",
      "[2025-07-23 10:12:41,652][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000778952184\n",
      "[2025-07-23 10:12:41,660][causal_bayes_opt.training.enriched_trainer][INFO] - Episode 90: reward=0.631, intervention_rate=1.000, scm=collider_3var, F1=0.000, P(Parents)=0.000, SHD=2\n",
      "[2025-07-23 10:12:41,785][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 730):\n",
      "[2025-07-23 10:12:41,785][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-3.68137553e-02 -1.00000000e+09]\n",
      "[2025-07-23 10:12:41,786][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "[2025-07-23 10:12:41,786][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:12:41,789][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:12:41,789][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 0.58\n",
      "[2025-07-23 10:12:41,790][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [1. 0.]\n",
      "[2025-07-23 10:12:41,790][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X2 (index 0)\n",
      "[2025-07-23 10:12:41,790][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:12:41,791][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.4635, Std: 4.9112\n",
      "[2025-07-23 10:12:41,791][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.03\n",
      "[2025-07-23 10:12:41,791][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 2.6909\n",
      "[2025-07-23 10:12:41,792][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 730):\n",
      "[2025-07-23 10:12:41,793][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (0, 2.69094900173249)\n",
      "[2025-07-23 10:12:41,793][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X2'}\n",
      "[2025-07-23 10:12:41,793][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X2': 2.69094900173249}\n",
      "[2025-07-23 10:12:41,793][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X1\n",
      "[2025-07-23 10:12:41,794][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.269094900173249}\n",
      "[2025-07-23 10:12:41,794][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.769095\n",
      "[2025-07-23 10:12:41,795][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.769095\n",
      "[2025-07-23 10:12:41,795][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:12:41,795][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.787, trend=+0.024\n",
      "[2025-07-23 10:12:43,589][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000790392729\n",
      "[2025-07-23 10:12:43,822][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 740):\n",
      "[2025-07-23 10:12:43,822][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-4.98027115e-02 -1.00000000e+09]\n",
      "[2025-07-23 10:12:43,823][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "[2025-07-23 10:12:43,823][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:12:43,825][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:12:43,826][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 0.56\n",
      "[2025-07-23 10:12:43,826][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [1. 0.]\n",
      "[2025-07-23 10:12:43,826][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X2 (index 0)\n",
      "[2025-07-23 10:12:43,827][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:12:43,827][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.3708, Std: 4.0143\n",
      "[2025-07-23 10:12:43,827][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.02\n",
      "[2025-07-23 10:12:43,828][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -0.4647\n",
      "[2025-07-23 10:12:43,828][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 740):\n",
      "[2025-07-23 10:12:43,828][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (0, -0.4647335253367269)\n",
      "[2025-07-23 10:12:43,829][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X2'}\n",
      "[2025-07-23 10:12:43,829][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X2': -0.4647335253367269}\n",
      "[2025-07-23 10:12:43,829][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X1\n",
      "[2025-07-23 10:12:43,829][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.04647335253367269}\n",
      "[2025-07-23 10:12:43,830][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.546473\n",
      "[2025-07-23 10:12:43,830][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.546473\n",
      "[2025-07-23 10:12:43,830][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:12:43,831][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.767, trend=-0.017\n",
      "[2025-07-23 10:12:45,652][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000812084089\n",
      "[2025-07-23 10:12:45,996][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 750):\n",
      "[2025-07-23 10:12:45,996][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [-5.02372618e-02 -1.00000000e+09]\n",
      "[2025-07-23 10:12:45,997][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "[2025-07-23 10:12:45,997][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:12:45,999][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:12:46,000][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 0.55\n",
      "[2025-07-23 10:12:46,000][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [1. 0.]\n",
      "[2025-07-23 10:12:46,000][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X2 (index 0)\n",
      "[2025-07-23 10:12:46,001][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:12:46,001][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.4086, Std: 4.2055\n",
      "[2025-07-23 10:12:46,001][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.02\n",
      "[2025-07-23 10:12:46,002][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 1.4231\n",
      "[2025-07-23 10:12:46,002][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 750):\n",
      "[2025-07-23 10:12:46,002][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (0, 1.4230704140727115)\n",
      "[2025-07-23 10:12:46,003][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X2'}\n",
      "[2025-07-23 10:12:46,003][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X2': 1.4230704140727115}\n",
      "[2025-07-23 10:12:46,003][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X1\n",
      "[2025-07-23 10:12:46,004][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.14230704140727116}\n",
      "[2025-07-23 10:12:46,004][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.642307\n",
      "[2025-07-23 10:12:46,004][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.642307\n",
      "[2025-07-23 10:12:46,005][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:12:46,005][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.775, trend=-0.358\n",
      "[2025-07-23 10:12:47,671][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000836198386\n",
      "[2025-07-23 10:12:48,183][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 760):\n",
      "[2025-07-23 10:12:48,184][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [ 9.9362655e-03 -1.0000000e+09]\n",
      "[2025-07-23 10:12:48,185][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "[2025-07-23 10:12:48,185][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:12:48,188][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:12:48,188][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 0.53\n",
      "[2025-07-23 10:12:48,188][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [1. 0.]\n",
      "[2025-07-23 10:12:48,189][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X2 (index 0)\n",
      "[2025-07-23 10:12:48,189][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:12:48,190][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.4124, Std: 4.6271\n",
      "[2025-07-23 10:12:48,190][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.01\n",
      "[2025-07-23 10:12:48,191][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: 0.9291\n",
      "[2025-07-23 10:12:48,192][causal_bayes_opt.training.enriched_trainer][INFO] - üîç PHASE 4 REWARD ANALYSIS (computation 760):\n",
      "[2025-07-23 10:12:48,192][causal_bayes_opt.training.enriched_trainer][INFO] -   Action: (0, 0.9290994896820581)\n",
      "[2025-07-23 10:12:48,194][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention targets: {'X2'}\n",
      "[2025-07-23 10:12:48,194][causal_bayes_opt.training.enriched_trainer][INFO] -   Intervention values: {'X2': 0.9290994896820581}\n",
      "[2025-07-23 10:12:48,194][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable: X1\n",
      "[2025-07-23 10:12:48,194][causal_bayes_opt.training.enriched_trainer][INFO] -   Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.09290994896820581}\n",
      "[2025-07-23 10:12:48,195][causal_bayes_opt.training.enriched_trainer][INFO] -   Total reward before clipping: 0.592910\n",
      "[2025-07-23 10:12:48,195][causal_bayes_opt.training.enriched_trainer][INFO] -   Final reward: 0.592910\n",
      "[2025-07-23 10:12:48,195][causal_bayes_opt.training.enriched_trainer][INFO] -   ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "[2025-07-23 10:12:48,196][causal_bayes_opt.training.enriched_trainer][INFO] -   REWARD TREND: mean=0.735, trend=-0.044\n",
      "[2025-07-23 10:12:49,867][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000848641237\n",
      "[2025-07-23 10:12:49,867][causal_bayes_opt.training.enriched_trainer][INFO] - Policy Learning Diagnostics (update 95):\n",
      "[2025-07-23 10:12:49,867][causal_bayes_opt.training.enriched_trainer][INFO] -   Action magnitudes: max=6.171475\n",
      "[2025-07-23 10:12:49,868][causal_bayes_opt.training.enriched_trainer][INFO] -   Mean reward: 0.670\n",
      "[2025-07-23 10:12:49,868][causal_bayes_opt.training.enriched_trainer][INFO] -   Policy param change: 0.00084864\n",
      "[2025-07-23 10:12:49,868][causal_bayes_opt.training.enriched_trainer][INFO] -   Parameter norm change: 0.00084864\n",
      "[2025-07-23 10:12:49,869][causal_bayes_opt.training.enriched_trainer][INFO] -   Rewards: min=0.541, max=1.000, group_baseline=0.670\n",
      "[2025-07-23 10:12:49,869][causal_bayes_opt.training.enriched_trainer][INFO] -   GRPO losses: policy=0.293564, entropy=-3.904596\n",
      "[2025-07-23 10:12:49,869][causal_bayes_opt.training.enriched_trainer][INFO] -   Gradient norm: 0.07185673\n",
      "[2025-07-23 10:12:49,870][causal_bayes_opt.training.enriched_trainer][INFO] -   Learning rate: 0.001000\n",
      "[2025-07-23 10:12:49,870][causal_bayes_opt.training.enriched_trainer][INFO] -   KL penalty: 0.000000, approx_kl: 3.506810\n",
      "[2025-07-23 10:12:51,829][causal_bayes_opt.training.enriched_trainer][INFO] - ‚úÖ Parameters changed - norm delta: 0.000838263826\n",
      "[2025-07-23 10:12:51,844][causal_bayes_opt.training.modular_trainer][INFO] - Saved checkpoint: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/checkpoints/grpo_training/enriched_grpo_final/checkpoint.pkl\n",
      "[2025-07-23 10:12:52,040][causal_bayes_opt.training.enriched_trainer][INFO] - Training completed in 310.0s\n",
      "[2025-07-23 10:12:52,040][causal_bayes_opt.training.enriched_trainer][INFO] - Final checkpoint: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/checkpoints/grpo_training/enriched_grpo_final\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Training completed!\n",
      "‚è±Ô∏è Training time: 5.2 minutes\n",
      "\n",
      "üìä Final Results:\n",
      "  Final reward (internal): 0.8106\n",
      "  Final target value: -0.8106 (‚Üì better)\n",
      "\n",
      "üìÅ Checkpoint saved to: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/checkpoints/grpo_training/enriched_grpo_final\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cell 5: Train GRPO policy with correct optimization direction\n",
    "\n",
    "This cell performs the actual training.\n",
    "Progress is saved periodically for resumption.\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "\n",
    "print(\"üöÄ Starting GRPO Policy Training\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"üîß Training mode: {TRAINING_MODE}\")\n",
    "print(f\"üéØ Optimization: {optimization_config.direction}\")\n",
    "print(f\"üìä Total episodes: {total_episodes}\")\n",
    "print(f\"‚öñÔ∏è Reward weights: {config.training.reward_weights}\")\n",
    "print(f\"‚úÖ Surrogate integration: ACTIVE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Configure trainer for optimization direction\n",
    "if hasattr(trainer, 'optimization_config'):\n",
    "    trainer.optimization_config = optimization_config\n",
    "else:\n",
    "    # Inject optimization config\n",
    "    trainer.config.optimization = optimization_config.__dict__\n",
    "\n",
    "# Set training SCMs\n",
    "if hasattr(trainer, 'set_training_scms'):\n",
    "    trainer.set_training_scms(training_scms)\n",
    "\n",
    "# Training loop with explicit error handling\n",
    "training_start_time = time.time()\n",
    "training_metrics = {}\n",
    "\n",
    "try:\n",
    "    print(\"\\nüèÉ Starting Training Loop...\")\n",
    "    \n",
    "    # Run training\n",
    "    training_metrics = trainer.train()\n",
    "    \n",
    "    training_end_time = time.time()\n",
    "    training_duration = training_end_time - training_start_time\n",
    "    \n",
    "    print(f\"\\n‚úÖ Training completed!\")\n",
    "    print(f\"‚è±Ô∏è Training time: {training_duration/60:.1f} minutes\")\n",
    "    \n",
    "    # Extract performance metrics\n",
    "    performance = training_metrics.get('performance', {})\n",
    "    final_reward = performance.get('final_reward', 0.0)\n",
    "    \n",
    "    # Convert reward to actual target value if minimizing\n",
    "    if optimization_config.is_minimizing:\n",
    "        final_target_value = optimization_config.convert_from_maximization(final_reward)\n",
    "        print(f\"\\nüìä Final Results:\")\n",
    "        print(f\"  Final reward (internal): {final_reward:.4f}\")\n",
    "        print(f\"  Final target value: {optimization_config.format_improvement(final_target_value)}\")\n",
    "    else:\n",
    "        print(f\"\\nüìä Final Results:\")\n",
    "        print(f\"  Final target value: {optimization_config.format_improvement(final_reward)}\")\n",
    "    \n",
    "    # Store optimization direction in metrics\n",
    "    training_metrics['optimization_direction'] = optimization_config.direction\n",
    "    training_metrics['duration_minutes'] = training_duration / 60\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚ö†Ô∏è Training interrupted by user\")\n",
    "    training_metrics['interrupted'] = True\n",
    "    training_metrics['duration_minutes'] = (time.time() - training_start_time) / 60\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Training failed with error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise NotebookError(f\"Training failed: {e}\")\n",
    "\n",
    "# Get checkpoint path\n",
    "checkpoint_path = training_metrics.get('checkpoint_path', checkpoint_dir / \"grpo_final\")\n",
    "print(f\"\\nüìÅ Checkpoint saved to: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Checkpoint with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "\"\"\"\nCell 6: Save checkpoint with complete metadata\n\nThis cell saves the trained model with all necessary metadata\nfor later evaluation and comparison.\n\"\"\"\nfrom omegaconf import OmegaConf\nprint(\"üíæ Saving Checkpoint with Metadata\")\nprint(\"=\" * 50)\n\n# Generate checkpoint name\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nopt_direction = optimization_config.direction.lower()\ncheckpoint_name = f\"grpo_{TRAINING_MODE.lower()}_{opt_direction}_{timestamp}\"\n\n# Extract actual model parameters from trainer\ntry:\n    checkpoint_data = {\n        'policy_params': trainer.policy_params,\n        'policy_config': {\n            'architecture': OmegaConf.to_container(config.training.architecture),\n            'state_config': OmegaConf.to_container(config.training.state_config),\n            'grpo_config': OmegaConf.to_container(config.training.grpo_config)\n        },\n        'training_metrics': training_metrics,\n        'optimization_config': optimization_config.__dict__\n    }\n    print(f\"‚úÖ Extracted model parameters from trainer\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è Warning: Could not extract model parameters: {e}\")\n    checkpoint_data = None\n\n# Create checkpoint metadata\nmetadata = CheckpointMetadata(\n    name=checkpoint_name,\n    path=checkpoint_dir / checkpoint_name,\n    optimization_config=optimization_config,\n    training_config={\n        'mode': TRAINING_MODE,\n        'objective': OPTIMIZATION_OBJECTIVE,\n        'config': OmegaConf.to_container(config.training),\n        'reward_weights': dict(config.training.reward_weights),\n        'scm_config': OmegaConf.to_container(config.experiment.scm_generation)\n    },\n    training_results={\n        'duration_minutes': training_metrics.get('duration_minutes', 0),\n        'final_performance': performance if 'performance' in locals() else {},\n        'episodes_completed': total_episodes if not training_metrics.get('interrupted', False) else starting_episode,\n        'success': not training_metrics.get('interrupted', False)\n    },\n    timestamp=timestamp\n)\n\n# Save checkpoint\ntry:\n    final_checkpoint_path = checkpoint_manager.save_checkpoint(\n        checkpoint_data=checkpoint_data,\n        metadata=metadata,\n        checkpoint_name=checkpoint_name\n    )\n    \n    print(f\"\\n‚úÖ Checkpoint saved successfully!\")\n    print(f\"üìÅ Location: {final_checkpoint_path}\")\n    print(f\"üìã Name: {checkpoint_name}\")\n    if checkpoint_data is not None:\n        print(f\"üìã Includes: Model parameters, config, and metrics\")\n    else:\n        print(f\"‚ö†Ô∏è Warning: Only metadata saved (no model parameters)\")\n    \n    # Display summary\n    print(f\"\\nüìä Training Summary:\")\n    print(f\"  Mode: {TRAINING_MODE}\")\n    print(f\"  Optimization: {optimization_config.direction}\")\n    print(f\"  Duration: {metadata.training_results['duration_minutes']:.1f} minutes\")\n    print(f\"  Episodes: {metadata.training_results['episodes_completed']}\")\n    print(f\"  Success: {'Yes' if metadata.training_results['success'] else 'No (interrupted)'}\")\n    \n    if 'final_reward' in performance:\n        final_value = performance['final_reward']\n        if optimization_config.is_minimizing:\n            final_value = optimization_config.convert_from_maximization(final_value)\n        print(f\"  Final target value: {optimization_config.format_improvement(final_value)}\")\n    \nexcept Exception as e:\n    raise NotebookError(f\"Failed to save checkpoint: {e}\")\n\n# Store checkpoint name for easy access\nTRAINED_CHECKPOINT = checkpoint_name\nprint(f\"\\nüí° Checkpoint name stored in variable: TRAINED_CHECKPOINT\")\nprint(f\"   Use this in evaluation notebook: '{TRAINED_CHECKPOINT}'\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Quick Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-23 10:12:52,167][causal_bayes_opt.training.enriched_trainer][INFO] - üîç Per-Variable Encoding - Policy Output (call 770):\n",
      "[2025-07-23 10:12:52,168][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable logits: [ 4.25992218e-03 -1.00000000e+09]\n",
      "[2025-07-23 10:12:52,168][causal_bayes_opt.training.enriched_trainer][INFO] -   Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "[2025-07-23 10:12:52,168][causal_bayes_opt.training.enriched_trainer][INFO] -   Target variable 'X1' at index 1, logit: -1000000000.0\n",
      "[2025-07-23 10:12:52,171][causal_bayes_opt.training.enriched_trainer][INFO] -   Variable selection:\n",
      "[2025-07-23 10:12:52,171][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.00\n",
      "[2025-07-23 10:12:52,171][causal_bayes_opt.training.enriched_trainer][INFO] -     Probabilities: [1. 0.]\n",
      "[2025-07-23 10:12:52,172][causal_bayes_opt.training.enriched_trainer][INFO] -     Selected: X2 (index 0)\n",
      "[2025-07-23 10:12:52,172][causal_bayes_opt.training.enriched_trainer][INFO] -   Value selection:\n",
      "[2025-07-23 10:12:52,172][causal_bayes_opt.training.enriched_trainer][INFO] -     Mean: 0.4715, Std: 5.5219\n",
      "[2025-07-23 10:12:52,172][causal_bayes_opt.training.enriched_trainer][INFO] -     Temperature: 1.00\n",
      "[2025-07-23 10:12:52,173][causal_bayes_opt.training.enriched_trainer][INFO] -     Sampled value: -7.1786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Quick Policy Validation\n",
      "==================================================\n",
      "\n",
      "Testing on 3 SCMs:\n",
      "----------------------------------------\n",
      "\n",
      "1. fork (3v):\n",
      "   Target: X1\n",
      "   Action: X2=-11.259\n",
      "   Magnitude: 11.259\n",
      "   Direction: Decrease (minimizing target)\n",
      "\n",
      "2. fork (3v):\n",
      "   Target: X1\n",
      "   Action: X2=-7.179\n",
      "   Magnitude: 7.179\n",
      "   Direction: Decrease (minimizing target)\n",
      "\n",
      "3. fork (4v):\n",
      "   Target: X2\n",
      "   Action: X1=-10.808\n",
      "   Magnitude: 10.808\n",
      "   Direction: Decrease (minimizing target)\n",
      "\n",
      "‚úÖ Validation complete!\n",
      "\n",
      "üéâ Training Complete!\n",
      "üìã Checkpoint: 'grpo_quick_minimize_20250723_101252'\n",
      "üîß Optimization: MINIMIZE\n",
      "\n",
      "üí° Next steps:\n",
      "   1. Use evaluation notebook to compare against baselines\n",
      "   2. Checkpoint name: 'grpo_quick_minimize_20250723_101252'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cell 7: Quick validation of trained policy\n",
    "\n",
    "Test the trained policy on a few SCMs to ensure it's working correctly.\n",
    "This cell can be run independently with a loaded checkpoint.\n",
    "\"\"\"\n",
    "\n",
    "print(\"üß™ Quick Policy Validation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Ensure we have a trainer\n",
    "if trainer is None:\n",
    "    raise NotebookError(\"No trainer available. Run training or load checkpoint first.\")\n",
    "\n",
    "# Test on a few SCMs\n",
    "test_key = random.PRNGKey(999)\n",
    "n_test = min(3, len(training_scms))\n",
    "\n",
    "print(f\"\\nTesting on {n_test} SCMs:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for i in range(n_test):\n",
    "    test_scm = training_scms[i]\n",
    "    test_meta = scm_metadata[i]\n",
    "    \n",
    "    try:\n",
    "        # Create test state\n",
    "        test_state = trainer._create_tensor_backed_state(test_scm, 0, 0.0)\n",
    "        enriched_input = trainer.state_converter.convert_state_to_enriched_input(test_state)\n",
    "        \n",
    "        # Get policy output\n",
    "        test_key, subkey = random.split(test_key)\n",
    "        target_idx = test_meta['variables'].index(test_meta['target'])\n",
    "        \n",
    "        policy_output = trainer.policy_fn.apply(\n",
    "            trainer.policy_params, subkey, enriched_input, target_idx, False\n",
    "        )\n",
    "        \n",
    "        # Convert to action\n",
    "        action = trainer._policy_output_to_action(policy_output, test_meta['variables'], test_meta['target'])\n",
    "        selected_var_idx, intervention_value = action\n",
    "        \n",
    "        print(f\"\\n{i+1}. {test_meta['structure_type']} ({test_meta['n_variables']}v):\")\n",
    "        print(f\"   Target: {test_meta['target']}\")\n",
    "        print(f\"   Action: {test_meta['variables'][selected_var_idx]}={intervention_value:.3f}\")\n",
    "        print(f\"   Magnitude: {abs(intervention_value):.3f}\")\n",
    "        \n",
    "        # Check if action makes sense for optimization direction\n",
    "        if optimization_config.is_minimizing:\n",
    "            print(f\"   Direction: {'Decrease' if intervention_value < 0 else 'Increase'} (minimizing target)\")\n",
    "        else:\n",
    "            print(f\"   Direction: {'Increase' if intervention_value > 0 else 'Decrease'} (maximizing target)\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n{i+1}. Failed to test: {e}\")\n",
    "        logger.warning(f\"Validation failed for SCM {i}: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ Validation complete!\")\n",
    "print(f\"\\nüéâ Training Complete!\")\n",
    "print(f\"üìã Checkpoint: '{TRAINED_CHECKPOINT}'\")\n",
    "print(f\"üîß Optimization: {optimization_config.direction}\")\n",
    "print(f\"\\nüí° Next steps:\")\n",
    "print(f\"   1. Use evaluation notebook to compare against baselines\")\n",
    "print(f\"   2. Checkpoint name: '{TRAINED_CHECKPOINT}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "**What we've accomplished:**\n",
    "1. ‚úÖ Configured training with explicit optimization direction\n",
    "2. ‚úÖ Trained GRPO policy with correct reward signals\n",
    "3. ‚úÖ Saved checkpoint with complete metadata\n",
    "4. ‚úÖ Validated policy behavior\n",
    "\n",
    "**Key improvements over original notebook:**\n",
    "- No silent failures - explicit errors when things go wrong\n",
    "- Independent cells - can resume training or load checkpoints\n",
    "- Optimization direction support - correctly handles minimization like PARENT_SCALE\n",
    "- Clean checkpoint management - all metadata preserved\n",
    "\n",
    "**Next steps:**\n",
    "1. Use `grpo_evaluation_modular.ipynb` to evaluate this checkpoint\n",
    "2. Compare minimization vs maximization policies\n",
    "3. Analyze how optimization direction affects performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal-bayes-opt-sr_Vb8Og-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}