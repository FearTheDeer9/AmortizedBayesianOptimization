{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the uncertainty decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 10 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      " /Users/jeandurand/Documents/Masters Thesis/causal_bayes_opt/ceo_venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning:IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# set the directory to the root\n",
    "os.chdir(\"/Users/jeandurand/Documents/Masters Thesis/causal_bayes_opt\")\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "from graphs.graph_6_nodes import Graph6Nodes\n",
    "from graphs.data_setup import setup_observational_interventional\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_O, D_I, exploration_set = setup_observational_interventional(\n",
    "                                graph_type=\"Graph6\",\n",
    "                                seed=18,\n",
    "                                n_obs=200,\n",
    "                                n_int=2,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_graph_edges = [\n",
    "    [\n",
    "        (\"A\", \"B\"),\n",
    "        (\"A\", \"C\"),\n",
    "        (\"A\", \"S\"),\n",
    "        (\"A\", \"As\"),\n",
    "        (\"A\", \"Y\"),\n",
    "        (\"B\", \"As\"),\n",
    "        (\"B\", \"C\"),\n",
    "        (\"B\", \"S\"),\n",
    "        (\"B\", \"Y\"),\n",
    "        (\"As\", \"C\"),\n",
    "        (\"As\", \"Y\"),\n",
    "        (\"S\", \"C\"),\n",
    "        (\"S\", \"Y\"),\n",
    "        (\"C\", \"Y\"),\n",
    "    ],\n",
    "    [\n",
    "        (\"A\", \"B\"),\n",
    "        (\"A\", \"C\"),\n",
    "        (\"A\", \"S\"),\n",
    "        (\"A\", \"As\"),\n",
    "        (\"A\", \"Y\"),\n",
    "        (\"B\", \"As\"),\n",
    "        (\"B\", \"C\"),\n",
    "        (\"B\", \"S\"),\n",
    "        (\"B\", \"Y\"),\n",
    "        (\"As\", \"C\"),\n",
    "        # (\"As\", \"Y\"),\n",
    "        (\"S\", \"C\"),\n",
    "        (\"S\", \"Y\"),\n",
    "        (\"C\", \"Y\"),\n",
    "    ],\n",
    "    [\n",
    "        (\"A\", \"B\"),\n",
    "        (\"A\", \"C\"),\n",
    "        (\"A\", \"S\"),\n",
    "        (\"A\", \"As\"),\n",
    "        (\"A\", \"Y\"),\n",
    "        (\"B\", \"As\"),\n",
    "        (\"B\", \"C\"),\n",
    "        (\"B\", \"S\"),\n",
    "        (\"B\", \"Y\"),\n",
    "        (\"As\", \"C\"),\n",
    "        (\"As\", \"Y\"),\n",
    "        (\"S\", \"C\"),\n",
    "        # (\"S\", \"Y\"),\n",
    "        (\"C\", \"Y\"),\n",
    "    ],\n",
    "    [\n",
    "        (\"A\", \"B\"),\n",
    "        (\"A\", \"C\"),\n",
    "        (\"A\", \"S\"),\n",
    "        (\"A\", \"As\"),\n",
    "        (\"A\", \"Y\"),\n",
    "        (\"B\", \"As\"),\n",
    "        (\"B\", \"C\"),\n",
    "        (\"B\", \"S\"),\n",
    "        (\"B\", \"Y\"),\n",
    "        (\"As\", \"C\"),\n",
    "        # (\"As\", \"Y\"),\n",
    "        (\"S\", \"C\"),\n",
    "        # (\"S\", \"Y\"),\n",
    "        (\"C\", \"Y\"),\n",
    "    ],\n",
    "    [\n",
    "        (\"A\", \"B\"),\n",
    "        (\"A\", \"C\"),\n",
    "        (\"A\", \"S\"),\n",
    "        (\"A\", \"As\"),\n",
    "        # (\"A\", \"Y\"),\n",
    "        (\"B\", \"As\"),\n",
    "        (\"B\", \"C\"),\n",
    "        (\"B\", \"S\"),\n",
    "        # (\"B\", \"Y\"),\n",
    "        (\"As\", \"C\"),\n",
    "        (\"As\", \"Y\"),\n",
    "        (\"S\", \"C\"),\n",
    "        (\"S\", \"Y\"),\n",
    "        (\"C\", \"Y\"),\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A taking marginal 3.1495069363449946\n",
      "B taking average 1.2816157129512349\n",
      "As taking average -4.085692987264675\n",
      "S taking average -4.312053545296077\n",
      "C taking average -4.082129994414914\n",
      "Y taking average 1.1513729136030004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'entropy': -6.897380964076437}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = Graph6Nodes()\n",
    "graph.mispecify_graph(all_graph_edges[0])\n",
    "graph.fit_samples_to_graph(D_O)\n",
    "graph.entropy_decomposition(D_O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A taking marginal 3.107267486753744\n",
      "B taking average 1.2816157129512349\n",
      "As taking average -4.085692987264675\n",
      "S taking average -4.312053545296077\n",
      "C taking average -4.082129994414914\n",
      "Y taking average 1.1513477224922042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'entropy': -6.939645604778484}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = Graph6Nodes()\n",
    "graph.mispecify_graph(all_graph_edges[1])\n",
    "graph.fit_samples_to_graph(D_O)\n",
    "graph.entropy_decomposition(D_O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A taking marginal 3.086071343993532\n",
      "B taking average 1.2816157129512349\n",
      "As taking average -4.085692987264675\n",
      "S taking average -4.312053545296077\n",
      "C taking average -4.082129994414914\n",
      "Y taking average 1.1513109340738819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'entropy': -6.960878535957017}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = Graph6Nodes()\n",
    "graph.mispecify_graph(all_graph_edges[2])\n",
    "graph.fit_samples_to_graph(D_O)\n",
    "graph.entropy_decomposition(D_O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A taking marginal 3.117347688800627\n",
      "B taking average 1.2816157129512349\n",
      "As taking average -4.085692987264675\n",
      "S taking average -4.312053545296077\n",
      "C taking average -4.082129994414914\n",
      "Y taking average 1.1512847857313548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'entropy': -6.92962833949245}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = Graph6Nodes()\n",
    "graph.mispecify_graph(all_graph_edges[3])\n",
    "graph.fit_samples_to_graph(D_O)\n",
    "graph.entropy_decomposition(D_O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A taking marginal 3.1149067322888975\n",
      "B taking average 1.2816157129512349\n",
      "As taking average -4.085692987264675\n",
      "S taking average -4.312053545296077\n",
      "C taking average -4.082129994414914\n",
      "Y taking average 0.9556849806975702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'entropy': -7.127669101037966}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = Graph6Nodes()\n",
    "graph.mispecify_graph(all_graph_edges[4])\n",
    "graph.fit_samples_to_graph(D_O)\n",
    "graph.entropy_decomposition(D_O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8871441197433323 2.02716573543071\n"
     ]
    }
   ],
   "source": [
    "from utils.sem_sampling import sample_model\n",
    "graph6 = Graph6Nodes()\n",
    "_, _, manipulative_variables = graph6.get_sets()\n",
    "variables = graph6.variables\n",
    "epistemic_uncertainty = 0\n",
    "aleatoric_uncertainty = 0\n",
    "for current_var in variables:\n",
    "    parents = graph6.parents[current_var]\n",
    "    if parents:\n",
    "        for i, var in enumerate(parents):\n",
    "            min_var = np.min(D_O[var])\n",
    "            max_var = np.max(D_O[var])\n",
    "            vals = np.linspace(start=min_var, stop=max_var, num=100)\n",
    "            variance = np.zeros(shape=100)\n",
    "            for j, val in enumerate(vals):\n",
    "                intervention = {var: val}\n",
    "                samples = sample_model(graph6.SEM, graph=graph6, interventions=intervention, sample_count=100)\n",
    "                variance[j] = np.var(samples[current_var])\n",
    "            if var in manipulative_variables:\n",
    "                epistemic_uncertainty += np.mean(variance)\n",
    "            else:\n",
    "                aleatoric_uncertainty += np.mean(variance)\n",
    "\n",
    "print(epistemic_uncertainty, aleatoric_uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_graph_edges = [\n",
    "    [\n",
    "        (\"A\", \"B\"),\n",
    "        (\"A\", \"C\"),\n",
    "        (\"A\", \"S\"),\n",
    "        (\"A\", \"As\"),\n",
    "        (\"A\", \"Y\"),\n",
    "        (\"B\", \"As\"),\n",
    "        (\"B\", \"C\"),\n",
    "        (\"B\", \"S\"),\n",
    "        (\"B\", \"Y\"),\n",
    "        (\"As\", \"C\"),\n",
    "        (\"As\", \"Y\"),\n",
    "        (\"S\", \"C\"),\n",
    "        (\"S\", \"Y\"),\n",
    "        (\"C\", \"Y\"),\n",
    "    ],\n",
    "    [\n",
    "        # (\"A\", \"B\"),\n",
    "        (\"A\", \"C\"),\n",
    "        (\"A\", \"S\"),\n",
    "        (\"A\", \"As\"),\n",
    "        (\"A\", \"Y\"),\n",
    "        (\"B\", \"As\"),\n",
    "        (\"B\", \"C\"),\n",
    "        (\"B\", \"S\"),\n",
    "        (\"B\", \"Y\"),\n",
    "        (\"As\", \"C\"),\n",
    "        (\"As\", \"Y\"),\n",
    "        (\"S\", \"C\"),\n",
    "        (\"S\", \"Y\"),\n",
    "        (\"C\", \"Y\"),\n",
    "    ],\n",
    "    [\n",
    "        (\"A\", \"B\"),\n",
    "        # (\"A\", \"C\"),\n",
    "        (\"A\", \"S\"),\n",
    "        (\"A\", \"As\"),\n",
    "        (\"A\", \"Y\"),\n",
    "        (\"B\", \"As\"),\n",
    "        (\"B\", \"C\"),\n",
    "        (\"B\", \"S\"),\n",
    "        (\"B\", \"Y\"),\n",
    "        (\"As\", \"C\"),\n",
    "        (\"As\", \"Y\"),\n",
    "        (\"S\", \"C\"),\n",
    "        (\"S\", \"Y\"),\n",
    "        (\"C\", \"Y\"),\n",
    "    ],\n",
    "    [\n",
    "        (\"A\", \"B\"),\n",
    "        (\"A\", \"C\"),\n",
    "        (\"A\", \"S\"),\n",
    "        (\"A\", \"As\"),\n",
    "        (\"A\", \"Y\"),\n",
    "        (\"B\", \"As\"),\n",
    "        # (\"B\", \"C\"),\n",
    "        (\"B\", \"S\"),\n",
    "        (\"B\", \"Y\"),\n",
    "        (\"As\", \"C\"),\n",
    "        (\"As\", \"Y\"),\n",
    "        (\"S\", \"C\"),\n",
    "        (\"S\", \"Y\"),\n",
    "        (\"C\", \"Y\"),\n",
    "    ],\n",
    "    [\n",
    "        (\"A\", \"B\"),\n",
    "        (\"A\", \"C\"),\n",
    "        (\"A\", \"S\"),\n",
    "        (\"A\", \"As\"),\n",
    "        # (\"A\", \"Y\"),\n",
    "        (\"B\", \"As\"),\n",
    "        (\"B\", \"C\"),\n",
    "        (\"B\", \"S\"),\n",
    "        (\"B\", \"Y\"),\n",
    "        (\"As\", \"C\"),\n",
    "        (\"As\", \"Y\"),\n",
    "        (\"S\", \"C\"),\n",
    "        (\"S\", \"Y\"),\n",
    "        (\"C\", \"Y\"),\n",
    "    ],\n",
    "    [\n",
    "        (\"A\", \"B\"),\n",
    "        (\"A\", \"C\"),\n",
    "        (\"A\", \"S\"),\n",
    "        (\"A\", \"As\"),\n",
    "        (\"A\", \"Y\"),\n",
    "        (\"B\", \"As\"),\n",
    "        (\"B\", \"C\"),\n",
    "        (\"B\", \"S\"),\n",
    "        # (\"B\", \"Y\"),\n",
    "        (\"As\", \"C\"),\n",
    "        (\"As\", \"Y\"),\n",
    "        (\"S\", \"C\"),\n",
    "        (\"S\", \"Y\"),\n",
    "        (\"C\", \"Y\"),\n",
    "    ],\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A taking marginal 3.0980361885402927\n",
      "B taking average 1.2816157129512349\n",
      "As taking average -4.085692987264675\n",
      "S taking average -4.312053545296077\n",
      "C taking average -4.082129994414914\n",
      "Y taking average 1.1513729136030004\n",
      "{'entropy': -6.9488517118811375}\n"
     ]
    }
   ],
   "source": [
    "graph = Graph6Nodes()\n",
    "graph.mispecify_graph(all_graph_edges[0])\n",
    "graph.fit_samples_to_graph(D_O)\n",
    "print(graph.entropy_decomposition(D_O))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A taking marginal 3.128063227296474\n",
      "B taking marginal 1.6843430444221479\n",
      "As taking average -4.085692987264675\n",
      "S taking average -4.312053545296077\n",
      "C taking average -4.082129994414914\n",
      "Y taking average 1.1513729136030004\n",
      "{'entropy': -6.516097341654044}\n"
     ]
    }
   ],
   "source": [
    "graph = Graph6Nodes()\n",
    "graph.mispecify_graph(all_graph_edges[1])\n",
    "graph.fit_samples_to_graph(D_O)\n",
    "print(graph.entropy_decomposition(D_O))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A taking marginal 3.115460511532651\n",
      "B taking average 1.2816157129512349\n",
      "As taking average -4.085692987264675\n",
      "S taking average -4.312053545296077\n",
      "C taking average -4.28009155448003\n",
      "Y taking average 1.1513729136030004\n",
      "{'entropy': -7.129388948953896}\n"
     ]
    }
   ],
   "source": [
    "graph = Graph6Nodes()\n",
    "graph.mispecify_graph(all_graph_edges[2])\n",
    "graph.fit_samples_to_graph(D_O)\n",
    "print(graph.entropy_decomposition(D_O))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A taking marginal 3.116163450497995\n",
      "B taking average 1.2816157129512349\n",
      "As taking average -4.085692987264675\n",
      "S taking average -4.312053545296077\n",
      "C taking average -4.160028154487202\n",
      "Y taking average 1.1513729136030004\n",
      "{'entropy': -7.008622609995723}\n"
     ]
    }
   ],
   "source": [
    "graph = Graph6Nodes()\n",
    "graph.mispecify_graph(all_graph_edges[3])\n",
    "graph.fit_samples_to_graph(D_O)\n",
    "print(graph.entropy_decomposition(D_O))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A taking marginal 3.0931929978674972\n",
      "B taking average 1.2816157129512349\n",
      "As taking average -4.085692987264675\n",
      "S taking average -4.312053545296077\n",
      "C taking average -4.082129994414914\n",
      "Y taking average 0.9915037865962453\n",
      "{'entropy': -7.11356402956069}\n"
     ]
    }
   ],
   "source": [
    "graph = Graph6Nodes()\n",
    "graph.mispecify_graph(all_graph_edges[4])\n",
    "graph.fit_samples_to_graph(D_O)\n",
    "print(graph.entropy_decomposition(D_O))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      " /Users/jeandurand/Documents/Masters Thesis/causal_bayes_opt/ceo_venv/lib/python3.10/site-packages/GPy/kern/src/stationary.py:168: RuntimeWarning:overflow encountered in divide\n",
      " /Users/jeandurand/Documents/Masters Thesis/causal_bayes_opt/ceo_venv/lib/python3.10/site-packages/GPy/kern/src/rbf.py:52: RuntimeWarning:overflow encountered in square\n",
      " /Users/jeandurand/Documents/Masters Thesis/causal_bayes_opt/ceo_venv/lib/python3.10/site-packages/GPy/kern/src/rbf.py:178: RuntimeWarning:invalid value encountered in multiply\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:SAFE OPTIMZATION: Resetting kernel lenghtscale\n",
      "INFO:root:SAFE OPTIMIZATION: resetting likelihood var to lower bound\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A taking marginal 3.094935850688196\n",
      "B taking average 1.2816157129512349\n",
      "As taking average -4.085692987264675\n",
      "S taking average -4.312053545296077\n",
      "C taking average -4.082129994414914\n",
      "Y taking average 1.0510856395204362\n",
      "{'entropy': -7.052239323815798}\n"
     ]
    }
   ],
   "source": [
    "graph = Graph6Nodes()\n",
    "graph.mispecify_graph(all_graph_edges[5])\n",
    "graph.fit_samples_to_graph(D_O)\n",
    "print(graph.entropy_decomposition(D_O))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to simulate the variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initializing the Toy Graph Structures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0054445477614542\n",
      "5.960521963648226\n",
      "1.5067409999910937\n",
      "8.472707511400774\n"
     ]
    }
   ],
   "source": [
    "from graphs.data_setup import setup_observational_interventional\n",
    "import numpy as np\n",
    "D_O, D_I, exploration_set = setup_observational_interventional(\n",
    "                                graph_type=\"Toy\",\n",
    "                                seed=20,\n",
    "                                n_obs=100000,\n",
    "                                n_int=2,\n",
    "                            )\n",
    "print(np.var(D_O[\"X\"]))\n",
    "print(np.var(D_O[\"Z\"]))\n",
    "print(np.var(D_O[\"Y\"]))\n",
    "print(np.var(D_O[\"X\"]) + np.var(D_O[\"Z\"]) + np.var(D_O[\"Y\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initializing the Toy Graph Structures\n",
      "INFO:root:Initializing the Toy Graph Structures\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:Getting the variables (mis and pomis) for the CBO algorithm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X taking marginal 1.6879516379219532\n",
      "Z taking average 1.324693227180057\n",
      "Y taking average 1.4628649319996372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'entropy': 4.4755097971016475}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphs.toy_graph import ToyGraph\n",
    "D_O, D_I, exploration_set = setup_observational_interventional(\n",
    "                                graph_type=\"Toy\",\n",
    "                                seed=20,\n",
    "                                n_obs=100,\n",
    "                                n_int=2,\n",
    "                            )\n",
    "\n",
    "all_graph_edges = [\n",
    "    [(\"X\", \"Z\"), (\"Z\", \"Y\")],\n",
    "    [(\"X\", \"Z\"), (\"X\", \"Y\")],\n",
    "    [(\"X\", \"Z\"), (\"Z\", \"Y\"), (\"X\", \"Y\")],\n",
    "    [(\"Z\", \"X\"), (\"Z\", \"Y\")],\n",
    "    [(\"X\", \"Y\"), (\"Z\", \"Y\")],\n",
    "    [(\"Z\", \"X\"), (\"X\", \"Y\"), (\"Z\", \"Y\")],\n",
    "    [(\"Z\", \"X\"), (\"X\", \"Y\")],\n",
    "]\n",
    "\n",
    "toy_graph = ToyGraph()\n",
    "toy_graph.mispecify_graph(all_graph_edges[0])\n",
    "toy_graph.fit_samples_to_graph(D_O)\n",
    "toy_graph.entropy_decomposition(D_O)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initializing the Toy Graph Structures\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:Getting the variables (mis and pomis) for the CBO algorithm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X taking marginal 1.712229417362218\n",
      "Z taking average 1.324693227180057\n",
      "Y taking average 1.6202421302877223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'entropy': 4.657164774829997}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_graph = ToyGraph()\n",
    "toy_graph.mispecify_graph(all_graph_edges[1])\n",
    "toy_graph.fit_samples_to_graph(D_O)\n",
    "toy_graph.entropy_decomposition(D_O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initializing the Toy Graph Structures\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:Getting the variables (mis and pomis) for the CBO algorithm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X taking marginal 1.7306955675584885\n",
      "Z taking average 1.324693227180057\n",
      "Y taking average 1.4508630009816101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'entropy': 4.506251795720156}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_graph = ToyGraph()\n",
    "toy_graph.mispecify_graph(all_graph_edges[2])\n",
    "toy_graph.fit_samples_to_graph(D_O)\n",
    "toy_graph.entropy_decomposition(D_O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initializing the Toy Graph Structures\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:Getting the variables (mis and pomis) for the CBO algorithm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X taking average 0.7909594578687132\n",
      "Z taking marginal 2.0421823232081255\n",
      "Y taking average 1.4628649319996372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'entropy': 4.296006713076476}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_graph = ToyGraph()\n",
    "toy_graph.mispecify_graph(all_graph_edges[3])\n",
    "toy_graph.fit_samples_to_graph(D_O)\n",
    "toy_graph.entropy_decomposition(D_O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initializing the Toy Graph Structures\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:Getting the variables (mis and pomis) for the CBO algorithm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X taking marginal 1.7301841399389823\n",
      "Z taking marginal 2.2026251312612706\n",
      "Y taking average 1.4508630009816086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'entropy': 5.383672272181862}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_graph = ToyGraph()\n",
    "toy_graph.mispecify_graph(all_graph_edges[4])\n",
    "toy_graph.fit_samples_to_graph(D_O)\n",
    "toy_graph.entropy_decomposition(D_O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initializing the Toy Graph Structures\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:Getting the variables (mis and pomis) for the CBO algorithm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X taking average 0.7909594578687132\n",
      "Z taking marginal 2.2940299519339358\n",
      "Y taking average 1.4508630009816086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'entropy': 4.5358524107842575}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_graph = ToyGraph()\n",
    "toy_graph.mispecify_graph(all_graph_edges[5])\n",
    "toy_graph.fit_samples_to_graph(D_O)\n",
    "toy_graph.entropy_decomposition(D_O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initializing the Toy Graph Structures\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:GP:initializing Y\n",
      "INFO:GP:initializing inference method\n",
      "INFO:GP:adding kernel and likelihood as parameters\n",
      "INFO:root:Getting the variables (mis and pomis) for the CBO algorithm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X taking average 0.7909594578687132\n",
      "Z taking marginal 2.169143874734186\n",
      "Y taking average 1.6202421302877223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'entropy': 4.580345462890621}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_graph = ToyGraph()\n",
    "toy_graph.mispecify_graph(all_graph_edges[6])\n",
    "toy_graph.fit_samples_to_graph(D_O)\n",
    "toy_graph.entropy_decomposition(D_O)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating the total variance in a similar way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 10 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      " /Users/jeandurand/Documents/Masters Thesis/causal_bayes_opt/ceo_venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning:IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "INFO:root:Initializing the Toy Graph Structures\n"
     ]
    }
   ],
   "source": [
    "from utils.sem_sampling import sample_model\n",
    "from graphs.data_setup import setup_observational_interventional\n",
    "from graphs.toy_graph import ToyGraph\n",
    "import numpy as np\n",
    "D_O, D_I, exploration_set = setup_observational_interventional(\n",
    "                                graph_type=\"Toy\",\n",
    "                                seed=20,\n",
    "                                n_obs=100,\n",
    "                                n_int=2,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(vals):\n\u001b[1;32m     15\u001b[0m     intervention \u001b[38;5;241m=\u001b[39m {var: val}\n\u001b[0;32m---> 16\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[43msample_model\u001b[49m(toy_graph\u001b[38;5;241m.\u001b[39mSEM, graph\u001b[38;5;241m=\u001b[39mtoy_graph, interventions\u001b[38;5;241m=\u001b[39mintervention, sample_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     17\u001b[0m     variance[j] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvar(samples[current_var])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m manipulative_variables:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_model' is not defined"
     ]
    }
   ],
   "source": [
    "toy_graph = Graph6Nodes()\n",
    "_, _, manipulative_variables = toy_graph.get_sets()\n",
    "variables = toy_graph.variables\n",
    "epistemic_uncertainty = 0\n",
    "aleatoric_uncertainty = 0\n",
    "for current_var in variables:\n",
    "    parents = toy_graph.parents[current_var]\n",
    "    if parents:\n",
    "        for i, var in enumerate(parents):\n",
    "            min_var = np.min(D_O[var])\n",
    "            max_var = np.max(D_O[var])\n",
    "            vals = np.linspace(start=min_var, stop=max_var, num=100)\n",
    "            variance = np.zeros(shape=100)\n",
    "            for j, val in enumerate(vals):\n",
    "                intervention = {var: val}\n",
    "                samples = sample_model(toy_graph.SEM, graph=toy_graph, interventions=intervention, sample_count=100)\n",
    "                variance[j] = np.var(samples[current_var])\n",
    "            if var in manipulative_variables:\n",
    "                epistemic_uncertainty += np.mean(variance)\n",
    "            else:\n",
    "                aleatoric_uncertainty += np.mean(variance)\n",
    "\n",
    "print(epistemic_uncertainty, aleatoric_uncertainty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the new environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initializing the Toy Graph Structures\n",
      "INFO:root:Sampling the observational data\n",
      "INFO:root:Sampling the interventional data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'As', 'S', 'C', 'Y']\n",
      "Expected degree: 2.3333333333333335\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "4\n",
      "5\n",
      "13.793962987074378\n",
      "13.786830929273181\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "# set the directory to the root\n",
    "os.chdir(\"/Users/jeandurand/Documents/Masters Thesis/causal_bayes_opt\")\n",
    "from graphs.toy_graph import ToyGraph\n",
    "from graphs.graph_6_nodes import Graph6Nodes\n",
    "from graphs.data_setup import setup_observational_interventional\n",
    "from diffcbed.envs.graph_to_env import GraphStructureEnv\n",
    "from diffcbed.replay_buffer import ReplayBuffer\n",
    "from utils.sem_sampling import sample_model, change_obs_data_format_to_mi, change_obs_data_format_to_bo\n",
    "from utils.sem_sampling import change_int_data_format_to_bo, change_int_data_format_to_mi\n",
    "D_O, D_I, exploration_set = setup_observational_interventional(\"Toy\")\n",
    "\n",
    "args = argparse.Namespace(scm_bias = 0.0, noise_bias = 0.0)\n",
    "graph = Graph6Nodes()\n",
    "print(graph.variables)\n",
    "graph_env = GraphStructureEnv(graph, args, noise_sigma=0.1)\n",
    "data_mi = graph_env.sample_linear(num_samples=1000)\n",
    "interventions = {'S': 0}\n",
    "data_bo = sample_model(static_sem=graph.SEM, sample_count=100, interventions=interventions, graph=graph)\n",
    "data_mi = graph_env.intervene(0, 100, np.array([0, 0, 0, 1, 0, 0]), np.array([0, 0, 0, 0, 0, 0]))\n",
    "print(data_mi.samples[: ,-1].mean())\n",
    "print(np.mean(data_bo['Y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X': {'X': array([2.77]),\n",
       "  'Z': array([4.02834284]),\n",
       "  'Y': array([-1.40330757])}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_int_data_format_to_bo(data_mi, graph.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.25459881 -3.4398136   9.37786602 33.13144607 -2.24647676  0.50973089]\n",
      "[ 8.90602100e-01 -1.16754110e-02  1.20882147e+01 -2.61410137e+00\n",
      "  1.03862848e+00 -1.66680569e+00]\n"
     ]
    }
   ],
   "source": [
    "D_I_mi = change_int_data_format_to_mi(D_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = ReplayBuffer(binary=False)\n",
    "buffer.update(data_mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer.update(D_I_mi[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<diffcbed.replay_buffer.ReplayBuffer at 0x327d9ee60>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ceo_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
