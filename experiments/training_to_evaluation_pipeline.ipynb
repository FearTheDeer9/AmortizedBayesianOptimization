{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACBO Training-to-Evaluation Pipeline\n",
    "\n",
    "This notebook provides an interactive workflow for training enriched GRPO policies and evaluating them against baseline methods. Each cell represents a distinct step that can be run independently for quick iteration.\n",
    "\n",
    "## Workflow Overview\n",
    "1. **Environment Setup** - Load dependencies and configure paths\n",
    "2. **SCM Suite Generation** - Create test SCMs matching evaluation config\n",
    "3. **Training Configuration** - Interactive parameter exploration\n",
    "4. **Policy Training** - Train with live monitoring\n",
    "5. **Checkpoint Analysis** - Validate trained model\n",
    "6. **Quick Policy Testing** - Sanity check on single SCM\n",
    "7. **Full Evaluation** - 4-method comparison\n",
    "8. **Results Analysis** - Visualization and insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:JAX devices: [CpuDevice(id=0)]\n",
      "INFO:__main__:JAX backend: cpu\n",
      "INFO:__main__:‚úÖ Environment setup complete\n",
      "INFO:__main__:Project root: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt\n",
      "INFO:__main__:Checkpoint directory: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/checkpoints/enriched_grpo\n",
      "INFO:__main__:Results directory: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/experiments/results\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Environment Setup for ACBO Training Pipeline\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import time\n",
    "from typing import Dict, List, Any, Optional\n",
    "import json\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent if Path.cwd().name == \"experiments\" else Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Core imports\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as random\n",
    "import numpy as onp\n",
    "import pyrsistent as pyr\n",
    "import yaml\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Project imports\n",
    "from causal_bayes_opt.experiments.variable_scm_factory import VariableSCMFactory\n",
    "from causal_bayes_opt.training.modular_trainer import TrainingMetrics\n",
    "from causal_bayes_opt.training.enriched_trainer import EnrichedGRPOTrainer\n",
    "from causal_bayes_opt.data_structures.scm import get_variables, get_target\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# JAX configuration\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "logger.info(f\"JAX devices: {jax.devices()}\")\n",
    "logger.info(f\"JAX backend: {jax.default_backend()}\")\n",
    "\n",
    "# Create necessary directories\n",
    "checkpoint_dir = project_root / \"checkpoints\" / \"enriched_grpo\"\n",
    "config_dir = project_root / \"config\"\n",
    "results_dir = project_root / \"experiments\" / \"results\"\n",
    "\n",
    "checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logger.info(\"‚úÖ Environment setup complete\")\n",
    "logger.info(f\"Project root: {project_root}\")\n",
    "logger.info(f\"Checkpoint directory: {checkpoint_dir}\")\n",
    "logger.info(f\"Results directory: {results_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: SCM Suite Generation & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Evaluation SCM config: {'use_variable_factory': True, 'variable_range': [3, 6], 'structure_types': ['fork', 'chain', 'collider', 'mixed'], 'rotation_frequency': 1, 'target_selection': 'random', 'edge_density_range': [0.3, 0.7]}\n",
      "INFO:__main__:Generating training SCM suite...\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X1'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 3 vars, 2 edges, target=X1\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X1'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 3 vars, 2 edges, target=X1\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 4 vars, 3 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 4 vars, 3 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 5 vars, 4 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 5 vars, 4 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X3'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 6 vars, 5 edges, target=X3\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X3'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 6 vars, 5 edges, target=X3\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 3 vars, 2 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 3 vars, 2 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X3'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 4 vars, 3 edges, target=X3\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X3'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 4 vars, 3 edges, target=X3\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X4'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 5 vars, 4 edges, target=X4\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X4'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 5 vars, 4 edges, target=X4\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X5'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 6 vars, 5 edges, target=X5\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X5'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 6 vars, 5 edges, target=X5\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X1'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 3 vars, 2 edges, target=X1\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X1'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 3 vars, 2 edges, target=X1\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 4 vars, 3 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 4 vars, 3 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 5 vars, 4 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 5 vars, 4 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X3'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 6 vars, 5 edges, target=X3\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X3'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 6 vars, 5 edges, target=X3\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X1'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 3 vars, 2 edges, target=X1\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 3 vars, 2 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X3'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 4 vars, 3 edges, target=X3\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 4 vars, 3 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 5 vars, 4 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X1'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 5 vars, 4 edges, target=X1\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X3'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 6 vars, 5 edges, target=X3\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X3'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 6 vars, 5 edges, target=X3\n",
      "INFO:__main__:Generated 32 training SCMs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Training SCM Distribution:\n",
      "Structure types: {'fork': 8, 'chain': 8, 'collider': 8, 'mixed': 8}\n",
      "Variable counts: {3: 8, 4: 8, 5: 8, 6: 8}\n",
      "Total SCMs: 32\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úÖ SCM suite generation complete\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generate SCM suite matching evaluation configuration\n",
    "\"\"\"\n",
    "\n",
    "# Load evaluation configuration to match SCM parameters\n",
    "eval_config_path = config_dir / \"experiment\" / \"acbo_4method_comparison.yaml\"\n",
    "with open(eval_config_path, 'r') as f:\n",
    "    eval_config = yaml.safe_load(f)\n",
    "\n",
    "scm_config = eval_config['experiment']['scm_generation']\n",
    "logger.info(f\"Evaluation SCM config: {scm_config}\")\n",
    "\n",
    "# Create SCM factory with matching parameters\n",
    "scm_factory = VariableSCMFactory(\n",
    "    noise_scale=eval_config['experiment']['environment']['noise_scale'],\n",
    "    coefficient_range=(-2.0, 2.0),  # Default range\n",
    "    seed=eval_config['seed']\n",
    ")\n",
    "\n",
    "# Generate representative SCM suite for training\n",
    "training_scms = []\n",
    "scm_metadata = []\n",
    "\n",
    "logger.info(\"Generating training SCM suite...\")\n",
    "seed = eval_config['seed']\n",
    "key = random.PRNGKey(seed)\n",
    "\n",
    "# Generate balanced set across structure types and variable counts\n",
    "for structure_type in scm_config['structure_types']:\n",
    "    for n_vars in range(scm_config['variable_range'][0], scm_config['variable_range'][1] + 1):\n",
    "        for _ in range(2):  # 2 SCMs per (structure_type, n_vars) combination\n",
    "            key, subkey = random.split(key)\n",
    "            \n",
    "            # Use the factory's create_variable_scm method\n",
    "            scm = scm_factory.create_variable_scm(\n",
    "                num_variables=n_vars,\n",
    "                structure_type=structure_type,\n",
    "                target_variable=None,  # Auto-select target\n",
    "                edge_density=0.5  # Default edge density\n",
    "            )\n",
    "            \n",
    "            training_scms.append(scm)\n",
    "            scm_metadata.append({\n",
    "                'structure_type': structure_type,\n",
    "                'n_variables': n_vars,\n",
    "                'target': get_target(scm),\n",
    "                'n_edges': len([edge for edges in scm.get('adjacency_matrix', {}).values() for edge in edges if edge])\n",
    "            })\n",
    "\n",
    "logger.info(f\"Generated {len(training_scms)} training SCMs\")\n",
    "\n",
    "# Analyze SCM distribution\n",
    "structure_counts = {}\n",
    "variable_counts = {}\n",
    "\n",
    "for meta in scm_metadata:\n",
    "    struct_type = meta['structure_type']\n",
    "    n_vars = meta['n_variables']\n",
    "    \n",
    "    structure_counts[struct_type] = structure_counts.get(struct_type, 0) + 1\n",
    "    variable_counts[n_vars] = variable_counts.get(n_vars, 0) + 1\n",
    "\n",
    "print(\"\\nüìä Training SCM Distribution:\")\n",
    "print(f\"Structure types: {structure_counts}\")\n",
    "print(f\"Variable counts: {variable_counts}\")\n",
    "print(f\"Total SCMs: {len(training_scms)}\")\n",
    "\n",
    "# Visualize distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Structure type distribution\n",
    "ax1.bar(structure_counts.keys(), structure_counts.values())\n",
    "ax1.set_title('Training SCMs by Structure Type')\n",
    "ax1.set_ylabel('Count')\n",
    "\n",
    "# Variable count distribution\n",
    "ax2.bar(variable_counts.keys(), variable_counts.values())\n",
    "ax2.set_title('Training SCMs by Variable Count')\n",
    "ax2.set_xlabel('Number of Variables')\n",
    "ax2.set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "logger.info(\"‚úÖ SCM suite generation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Training Configuration Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b461e1d7c4754a56a22f1eacb8a23d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=10, description='Duration (min)', max=30, min=1), IntSlider(value=5, des‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úÖ Training configuration ready with GRPO fixes\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Interactive training configuration with parameter exploration\n",
    "\"\"\"\n",
    "\n",
    "from IPython.display import display\n",
    "try:\n",
    "    from ipywidgets import interact, IntSlider, FloatSlider, Dropdown, Checkbox\n",
    "    WIDGETS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    WIDGETS_AVAILABLE = False\n",
    "    logger.warning(\"ipywidgets not available, using default configuration\")\n",
    "\n",
    "# Default training configuration\n",
    "training_params = {\n",
    "    'training_duration_minutes': 15,\n",
    "    'episodes_per_scm': 20,\n",
    "    'learning_rate': 0.001,  # Use lower LR based on our fix\n",
    "    'batch_size': 32,\n",
    "    'hidden_dims': [128, 128],\n",
    "    'structure_weight': 0.3,\n",
    "    'exploration_weight': 0.2,\n",
    "    'target_weight': 0.5,\n",
    "    'use_curriculum': True,\n",
    "    'checkpoint_frequency': 50,\n",
    "    # NEW GRPO CONFIGURATION\n",
    "    'interventions_per_state': 8,  # Generate 8 interventions per state for proper grouping\n",
    "    'grpo_group_size': 64  # Total group size for GRPO\n",
    "}\n",
    "\n",
    "if WIDGETS_AVAILABLE:\n",
    "    # Interactive parameter selection\n",
    "    def configure_training(duration_min=10, episodes=5, lr=1e-3, batch_size=32, \n",
    "                          structure_weight=0.3, exploration_weight=0.2, target_weight=0.5,\n",
    "                          use_curriculum=True, interventions_per_state=8):\n",
    "        \n",
    "        global training_params\n",
    "        training_params.update({\n",
    "            'training_duration_minutes': duration_min,\n",
    "            'episodes_per_scm': episodes,\n",
    "            'learning_rate': lr,\n",
    "            'batch_size': batch_size,\n",
    "            'structure_weight': structure_weight,\n",
    "            'exploration_weight': exploration_weight,\n",
    "            'target_weight': target_weight,\n",
    "            'use_curriculum': use_curriculum,\n",
    "            'interventions_per_state': interventions_per_state\n",
    "        })\n",
    "        \n",
    "        print(f\"üìù Training Configuration:\")\n",
    "        print(f\"Duration: {duration_min} minutes\")\n",
    "        print(f\"Episodes per SCM: {episodes}\")\n",
    "        print(f\"Learning rate: {lr}\")\n",
    "        print(f\"Batch size: {batch_size}\")\n",
    "        print(f\"Interventions per state: {interventions_per_state} (NEW!)\")\n",
    "        print(f\"Reward weights: struct={structure_weight:.1f}, explore={exploration_weight:.1f}, target={target_weight:.1f}\")\n",
    "        print(f\"Curriculum learning: {use_curriculum}\")\n",
    "        \n",
    "        # Estimate training time\n",
    "        total_episodes = len(training_scms) * episodes\n",
    "        estimated_time = (total_episodes * 10) / 60  # Rough estimate: 10 seconds per episode\n",
    "        print(f\"\\n‚è±Ô∏è Estimated training time: {estimated_time:.1f} minutes\")\n",
    "        print(f\"Total episodes: {total_episodes}\")\n",
    "        print(f\"üîß GRPO Fix: Same state, different interventions grouping enabled\")\n",
    "    \n",
    "    # Create interactive widgets\n",
    "    interact(configure_training,\n",
    "             duration_min=IntSlider(value=10, min=1, max=30, description='Duration (min)'),\n",
    "             episodes=IntSlider(value=5, min=1, max=20, description='Episodes/SCM'),\n",
    "             lr=FloatSlider(value=1e-3, min=1e-4, max=1e-2, step=1e-4, description='Learning Rate'),\n",
    "             batch_size=Dropdown(options=[16, 32, 64, 128], value=32, description='Batch Size'),\n",
    "             structure_weight=FloatSlider(value=0.3, min=0.0, max=1.0, step=0.1, description='Structure Weight'),\n",
    "             exploration_weight=FloatSlider(value=0.2, min=0.0, max=1.0, step=0.1, description='Exploration Weight'),\n",
    "             target_weight=FloatSlider(value=0.5, min=0.0, max=1.0, step=0.1, description='Target Weight'),\n",
    "             use_curriculum=Checkbox(value=True, description='Use Curriculum'),\n",
    "             interventions_per_state=IntSlider(value=8, min=1, max=16, description='Interventions/State'))\n",
    "else:\n",
    "    print(\"üìù Using default training configuration with GRPO fixes:\")\n",
    "    for key, value in training_params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Create training configuration object (OmegaConf format)\n",
    "def create_training_config():\n",
    "    config_dict = {\n",
    "        'seed': eval_config['seed'],\n",
    "        'training': {\n",
    "            'n_episodes': len(training_scms) * training_params['episodes_per_scm'],\n",
    "            'episode_length': 10,  # Fixed episode length\n",
    "            'learning_rate': training_params['learning_rate'],\n",
    "            'gamma': 0.99,\n",
    "            'max_intervention_value': 2.0,\n",
    "            'reward_weights': {\n",
    "                'optimization': training_params['target_weight'],\n",
    "                'discovery': training_params['structure_weight'],\n",
    "                'efficiency': training_params['exploration_weight']\n",
    "            },\n",
    "            'architecture': {\n",
    "                'hidden_dim': training_params['hidden_dims'][0],\n",
    "                'num_layers': 2,\n",
    "                'num_heads': 4,\n",
    "                'key_size': 32,\n",
    "                'widening_factor': 4,\n",
    "                'dropout': 0.1,\n",
    "                'policy_intermediate_dim': None\n",
    "            },\n",
    "            'state_config': {\n",
    "                'max_history_size': 100,\n",
    "                'num_channels': 10,\n",
    "                'standardize_values': True,\n",
    "                'include_temporal_features': True\n",
    "            },\n",
    "            # NEW GRPO CONFIGURATION SECTION\n",
    "            'grpo_config': {\n",
    "                'group_size': training_params['grpo_group_size'],\n",
    "                'interventions_per_state': training_params['interventions_per_state'],\n",
    "                'clip_ratio': 0.2,\n",
    "                'entropy_coeff': 0.01,\n",
    "                'kl_penalty_coeff': 0.0,\n",
    "                'max_grad_norm': 1.0,\n",
    "                'scale_rewards': True\n",
    "            }\n",
    "        },\n",
    "        'experiment': {\n",
    "            'scm_generation': {\n",
    "                'use_variable_factory': True,\n",
    "                'variable_range': [3, 6],\n",
    "                'structure_types': ['fork', 'chain', 'collider', 'mixed'],\n",
    "                'rotation_frequency': 5\n",
    "            }\n",
    "        },\n",
    "        'logging': {\n",
    "            'checkpoint_dir': str(checkpoint_dir),\n",
    "            'wandb': {'enabled': False},\n",
    "            'level': 'INFO'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return OmegaConf.create(config_dict)\n",
    "\n",
    "logger.info(\"‚úÖ Training configuration ready with GRPO fixes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Policy Training with Live Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting training with config keys: ['seed', 'training', 'experiment', 'logging']\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X1'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 3 vars, 2 edges, target=X1\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 3 vars, 2 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X1'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 3 vars, 2 edges, target=X1\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 3 variables, 2 edges, target='X1'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 3 vars, 2 edges, target=X1\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 4 vars, 3 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X3'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 4 vars, 3 edges, target=X3\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 4 vars, 3 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 4 variables, 3 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 4 vars, 3 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 5 vars, 4 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X4'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 5 vars, 4 edges, target=X4\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 5 vars, 4 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 5 variables, 4 edges, target='X2'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 5 vars, 4 edges, target=X2\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X3'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated fork SCM: 6 vars, 5 edges, target=X3\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X5'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated chain SCM: 6 vars, 5 edges, target=X5\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X3'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated collider SCM: 6 vars, 5 edges, target=X3\n",
      "INFO:causal_bayes_opt.experiments.test_scms:Created linear SCM with 6 variables, 5 edges, target='X4'\n",
      "INFO:causal_bayes_opt.experiments.variable_scm_factory:Generated mixed SCM: 6 vars, 5 edges, target=X4\n",
      "INFO:causal_bayes_opt.training.modular_trainer:Created 16 variable SCMs for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ GRPO Policy Training - IMPROVED PARAMETER NAVIGATION TEST\n",
      "================================================================================\n",
      "‚úÖ USING: Policy-only GRPO (no value functions)\n",
      "‚úÖ USING: Group-relative advantages\n",
      "‚úÖ USING: Correct baseline computation\n",
      "‚úÖ FIXED: Sample accumulation for group size requirements\n",
      "üîß NEW: Improved JAX tree parameter navigation system\n",
      "‚úÖ EXPECTED: Parameters should update correctly now\n",
      "================================================================================\n",
      "üìä Configuration:\n",
      "  Total episodes: 160\n",
      "  Episode length: 10\n",
      "  Learning rate: 0.001\n",
      "  Batch size: 32\n",
      "  SCMs: 32 (4 types)\n",
      "  Reward weights: optimization=0.5, discovery=0.3, exploration=0.2\n",
      "\n",
      "üìä Initializing enriched GRPO trainer with improved parameter navigation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causal_bayes_opt.training.enriched_trainer:‚ö° Increasing entropy coefficient from 0.010 to 0.02 for better exploration\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Correct GRPO Config: group_size=64, lr=0.001000\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Correct GRPO Config: entropy_coeff=0.020, clip_ratio=0.20\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Initialized trainer with 6 max variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:GRPO group size: 64, update frequency: 6 episodes\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Starting enriched GRPO training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Trainer initialization successful with improved navigation system!\n",
      "\n",
      "üîß Sample Accumulation + Navigation Improvements:\n",
      "  Episode length: 10 samples/episode\n",
      "  GRPO group size: 64 samples required\n",
      "  Update frequency: Every 6 episodes\n",
      "  Parameter navigation: Improved JAX tree traversal\n",
      "  Expected: No batch errors + working parameter updates\n",
      "\n",
      "üîç GRPO Implementation + Navigation Verification:\n",
      "  ‚úÖ Using policy-only updates: True\n",
      "  ‚úÖ No value functions: True\n",
      "  ‚úÖ Group-relative advantages: True\n",
      "  ‚úÖ Sample accumulation buffer: True\n",
      "  üîß NEW: Improved parameter path navigation\n",
      "  üîß NEW: JAX tree-based parameter access\n",
      "  ‚úÖ Expected parameter navigation success: True\n",
      "\n",
      "üèÉ Starting training with IMPROVED PARAMETER NAVIGATION...\n",
      "üìà Watch for IMPROVED indicators:\n",
      "  ‚Ä¢ Parameter navigation SUCCESS (no path failures)\n",
      "  ‚Ä¢ POSITIVE parameter changes (>1e-8)\n",
      "  ‚Ä¢ Parameter storage verification PASS\n",
      "  ‚Ä¢ Strong policy learning outcomes\n",
      "  ‚Ä¢ Meaningful reward improvements\n",
      "  ‚Ä¢ Stable GRPO update process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 5):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 10):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.18160867), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 10):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.02058421  0.          0.18160867  0.0187844   0.00808679 -0.03721108]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.02058421394796434, 'X0': 0.18160866726679836}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.020219288121476272}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.520219\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.520219\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 0: reward=0.520, intervention_rate=1.000, scm=fork_3var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 15):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 20):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.18047361), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 20):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.02045556  0.          0.18047361  0.018667    0.00803625 -0.03697851]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.02045556261078956, 'X0': 0.18047361309638088}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.020092917570717045}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.520093\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.520093\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 25):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 30):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.17933856), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 30):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.02032691  0.          0.17933856  0.0185496   0.0079857  -0.03674594]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.020326911273614787, 'X0': 0.1793385589259634}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.01996654701995782}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.519967\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.519967\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 35):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 40):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.17820350), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 40):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.02019826  0.          0.1782035   0.01843219  0.00793516 -0.03651337]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.02019825993644001, 'X0': 0.1782035047555459}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.01984017646919859}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.519840\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.519840\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 45):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 50):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.17706845), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 50):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.02006961  0.          0.17706845  0.01831479  0.00788462 -0.0362808 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.02006960859926523, 'X0': 0.1770684505851284}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.019713805918439367}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.519714\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.519714\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 55):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 60):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.17593340), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 60):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.07602418  0.1759334   0.01819739  0.00783408 -0.03604823]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -0.07602418459327805, 'X0': 0.17593339641471092}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.0251957581007989}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.525196\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.525196\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 65):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 70):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.17479834), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 70):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.07553371  0.17479834  0.01807999  0.00778353 -0.03581566]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -0.07553370598299883, 'X0': 0.17479834224429341}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.02503320482272923}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.525033\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.525033\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 75):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 80):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.17366329), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 80):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.07504323  0.17366329  0.01796258  0.00773299 -0.03558309]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -0.07504322737271962, 'X0': 0.17366328807387596}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.02487065154465956}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.524871\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.524871\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 85):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 90):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.17252823), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 90):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.07455275  0.17252823  0.01784518  0.00768245 -0.03535053]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -0.0745527487624404, 'X0': 0.17252823390345845}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.024708098266589887}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.524708\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.524708\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 95):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 100):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.17139318), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 100):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.07406227  0.17139318  0.01772778  0.00763191 -0.03511796]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -0.07406227015216119, 'X0': 0.17139317973304097}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.024545544988520216}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.524546\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.524546\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.522, trend=+0.004\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 105):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 110):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.17025813), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 110):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.0192977   0.          0.17025813  0.01761038  0.00758136 -0.03488539]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.01929770057621657, 'X0': 0.17025812556262346}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.018955582613884005}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.518956\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.518956\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.522, trend=-0.001\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 10: reward=0.519, intervention_rate=1.000, scm=collider_3var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 115):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 120):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.16912307), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 120):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01916905  0.          0.16912307  0.01749297  0.00753082 -0.03465282]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.019169049239041794, 'X0': 0.169123071392206}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.01882921206312478}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.518829\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.518829\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.522, trend=-0.001\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 125):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 130):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.16798802), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 130):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.0190404   0.          0.16798802  0.01737557  0.00748028 -0.03442025]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.019040397901867016, 'X0': 0.16798801722178852}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.018702841512365554}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.518703\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.518703\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.522, trend=-0.001\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 135):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 140):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.16685296), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 140):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01891175  0.          0.16685296  0.01725817  0.00742974 -0.03418768]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.018911746564692238, 'X0': 0.16685296305137098}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.018576470961606324}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.518576\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.518576\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.522, trend=-0.001\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 145):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 150):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.16571791), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 150):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.0187831   0.          0.16571791  0.01714077  0.00737919 -0.03395511]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.01878309522751746, 'X0': 0.1657179088809535}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.018450100410847096}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.518450\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.518450\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.522, trend=-0.007\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 155):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 160):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.16458285), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 160):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01865444  0.          0.16458285  0.01702336  0.00732865 -0.03372254]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.018654443890342685, 'X0': 0.16458285471053605}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.018323729860087873}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.518324\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.518324\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.521, trend=-0.007\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 165):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 170):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.16344780), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 170):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01852579  0.          0.1634478   0.01690596  0.00727811 -0.03348997]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.018525792553167907, 'X0': 0.16344780054011854}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.018197359309328646}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.518197\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.518197\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.520, trend=-0.007\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 175):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 180):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.16231275), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 180):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01839714  0.          0.16231275  0.01678856  0.00722757 -0.0332574 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.01839714121599313, 'X0': 0.16231274636970106}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.01807098875856942}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.518071\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.518071\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.520, trend=-0.007\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 185):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 190):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.16117769), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 190):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01826849  0.          0.16117769  0.01667116  0.00717702 -0.03302483]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.01826848987881835, 'X0': 0.16117769219928355}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.01794461820781019}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.517945\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.517945\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.519, trend=-0.007\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 195):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 200):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.16004264), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 200):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01813984  0.          0.16004264  0.01655375  0.00712648 -0.03279226]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.018139838541643576, 'X0': 0.16004263802886606}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.017818247657050965}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.517818\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.517818\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.518, trend=-0.001\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 205):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 210):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.15890758), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 210):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.06866701  0.15890758  0.01643635  0.00707594 -0.03255969]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -0.06866700543908985, 'X1': 0.15890758385844858, 'X0': 0.016436351128206513}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.024401094042574498}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.524401\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.524401\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.519, trend=+0.006\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 20: reward=0.524, intervention_rate=1.000, scm=fork_4var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 215):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 220):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.15777253), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 220):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.06817653  0.15777253  0.01631895  0.0070254  -0.03232713]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -0.06817652682881063, 'X1': 0.1577725296880311, 'X0': 0.016318948620147895}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.024226800513698965}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.524227\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.524227\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.519, trend=+0.006\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 225):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 230):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.15663748), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 230):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.06768605  0.15663748  0.01620155  0.00697485 -0.03209456]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -0.06768604821853143, 'X1': 0.1566374755176136, 'X0': 0.016201546112089276}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.024052506984823432}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.524053\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.524053\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.520, trend=+0.005\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 235):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 240):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.15550242), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 240):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.06719557  0.15550242  0.01608414  0.00692431 -0.03186199]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -0.06719556960825221, 'X1': 0.1555024213471961, 'X0': 0.016084143604030657}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.0238782134559479}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.523878\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.523878\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.521, trend=+0.005\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 245):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 250):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.15436737), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 250):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.06670509  0.15436737  0.01596674  0.00687377 -0.03162942]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -0.06670509099797299, 'X1': 0.15436736717677862, 'X0': 0.01596674109597204}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.023703919927072367}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.523704\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.523704\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.521, trend=+0.005\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 255):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 260):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.15323231), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 260):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01736793  0.          0.15323231  0.01584934  0.00682323 -0.03139685]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0', 'X2', 'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.017367930518594914, 'X1': 0.15323231300636111, 'X0': 0.01584933858791342}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.018644958211286946}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.518645\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.518645\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.521, trend=+0.000\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 265):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 270):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.15209726), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 270):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01723928  0.          0.15209726  0.01573194  0.00677269 -0.03116428]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0', 'X2', 'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.017239279181420136, 'X1': 0.15209725883594363, 'X0': 0.015731936079854802}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.018506847409721857}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.518507\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.518507\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.521, trend=+0.000\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 275):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 280):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.15096220), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 280):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01711063  0.          0.1509622   0.01561453  0.00672214 -0.03093171]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0', 'X2', 'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.017110627844245357, 'X1': 0.15096220466552615, 'X0': 0.015614533571796185}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.018368736608156768}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.518369\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.518369\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.521, trend=+0.000\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 285):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 290):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.14982715), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 290):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01698198  0.          0.14982715  0.01549713  0.0066716  -0.03069914]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0', 'X2', 'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.01698197650707058, 'X1': 0.14982715049510867, 'X0': 0.015497131063737568}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.018230625806591683}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.518231\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.518231\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.521, trend=+0.000\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 295):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 300):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.14869210), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 300):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01685333  0.          0.1486921   0.01537973  0.00662106 -0.03046657]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0', 'X2', 'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.016853325169895805, 'X1': 0.14869209632469116, 'X0': 0.01537972855567895}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.01809251500502659}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.518093\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.518093\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.521, trend=-0.006\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 305):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 310):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.14755704), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 310):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.06376222  0.14755704  0.01526233  0.00657052 -0.030234  ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -0.0637622193362977, 'X1': 0.14755704215427368, 'X0': 0.015262326047620331}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.02265815875381917}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.522658\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.522658\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.521, trend=-0.002\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 30: reward=0.523, intervention_rate=1.000, scm=collider_4var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 315):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 320):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.14642199), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 320):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.06327174  0.14642199  0.01514492  0.00651997 -0.03000143]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -0.0632717407260185, 'X1': 0.1464219879838562, 'X0': 0.015144923539561714}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.022483865224943642}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.522484\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.522484\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.521, trend=-0.002\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 325):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 330):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.14528693), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 330):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.06278126  0.14528693  0.01502752  0.00646943 -0.02976886]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -0.0627812621157393, 'X1': 0.1452869338134387, 'X0': 0.015027521031503097}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.022309571696068113}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.522310\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.522310\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.521, trend=-0.002\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 335):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 340):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.14415188), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 340):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.06229078  0.14415188  0.01491012  0.00641889 -0.02953629]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -0.06229078350546007, 'X1': 0.1441518796430212, 'X0': 0.014910118523444477}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.022135278167192577}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.522135\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.522135\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.521, trend=-0.002\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 345):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 350):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.14301683), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 350):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.0618003   0.14301683  0.01479272  0.00636835 -0.02930372]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -0.06180030489518086, 'X1': 0.14301682547260372, 'X0': 0.014792716015385858}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.021960984638317044}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.521961\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.521961\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.520, trend=+0.003\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 355):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 360):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.14188177), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 360):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.06130983  0.14188177  0.01467531  0.0063178  -0.02907116]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -0.06130982628490164, 'X1': 0.1418817713021862, 'X0': 0.014675313507327242}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.02178669110944151}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.521787\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.521787\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.521, trend=+0.003\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 365):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 370):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.14074672), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 370):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.06081935  0.14074672  0.01455791  0.00626726 -0.02883859]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -0.060819347674622444, 'X1': 0.14074671713176876, 'X0': 0.014557910999268626}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.021612397580565986}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.521612\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.521612\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.521, trend=+0.003\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 375):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 380):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.13961166), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 380):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.06032887  0.13961166  0.01444051  0.00621672 -0.02860602]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -0.06032886906434323, 'X1': 0.13961166296135127, 'X0': 0.014440508491210008}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.021438104051690453}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.521438\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.521438\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.521, trend=+0.003\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 385):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 390):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.13847661), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 390):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.05983839  0.13847661  0.01432311  0.00616618 -0.02837345]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -0.05983839045406401, 'X1': 0.13847660879093374, 'X0': 0.014323105983151388}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.021263810522814914}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.521264\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.521264\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.522, trend=+0.003\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 395):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 400):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.13734155), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 400):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.05934791  0.13734155  0.0142057   0.00611563 -0.02814088]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -0.05934791184378479, 'X1': 0.13734155462051625, 'X0': 0.014205703475092769}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.02108951699393938}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.521090\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.521090\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.522, trend=-0.002\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 405):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 410):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.13620650), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 410):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.05885743  0.1362065   0.0140883   0.00606509 -0.02790831]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4', 'X0', 'X3', 'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -0.05885743323350559, 'X3': 0.1362065004500988, 'X1': 0.014088300967034154, 'X0': 0.006065091077807457}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.021521732572844603}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.521522\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.521522\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.522, trend=-0.001\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 40: reward=0.522, intervention_rate=1.000, scm=fork_5var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 415):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 420):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.13507145), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 420):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.05836695  0.13507145  0.0139709   0.00601455 -0.02767574]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4', 'X0', 'X3', 'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -0.05836695462322637, 'X3': 0.1350714462796813, 'X1': 0.013970898458975535, 'X0': 0.006014548652159062}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.021342384801404227}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.521342\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.521342\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.522, trend=-0.001\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 425):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 430):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.13393639), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 430):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.05787648  0.13393639  0.0138535   0.00596401 -0.02744317]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4', 'X0', 'X3', 'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -0.05787647601294716, 'X3': 0.1339363921092638, 'X1': 0.013853495950916917, 'X0': 0.005964006226510666}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.021163037029963857}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.521163\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.521163\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.522, trend=-0.001\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 435):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 440):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.13280134), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 440):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.057386    0.13280134  0.01373609  0.00591346 -0.0272106 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4', 'X0', 'X3', 'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -0.057385997402667935, 'X3': 0.1328013379388463, 'X1': 0.013736093442858296, 'X0': 0.00591346380086227}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.02098368925852348}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.520984\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.520984\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.521, trend=-0.001\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 445):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 450):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.13166628), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 450):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.05689552  0.13166628  0.01361869  0.00586292 -0.02697803]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4', 'X0', 'X3', 'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -0.05689551879238872, 'X3': 0.13166628376842882, 'X1': 0.01361869093479968, 'X0': 0.005862921375213874}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.02080434148708311}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.520804\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.520804\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.521, trend=-0.001\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 455):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X4\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 460):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X4\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.13053123), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 460):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.0147949   0.          0.13053123  0.01350129  0.00581238 -0.02674546]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X0', 'X2', 'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.01479490377509937, 'X3': 0.13053122959801133, 'X1': 0.013501288426741063, 'X0': 0.00581237894956548}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.016463980074941726}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.516464\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.516464\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.521, trend=-0.005\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 465):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X4\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 470):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X4\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.12939618), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 470):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01466625  0.          0.12939618  0.01338389  0.00576184 -0.02651289]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X0', 'X2', 'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.014666252437924594, 'X3': 0.12939617542759385, 'X1': 0.013383885918682446, 'X0': 0.005761836523917084}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.016320815030811796}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.516321\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.516321\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.520, trend=-0.005\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 475):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X4\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 480):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X4\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.12826112), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 480):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.0145376   0.          0.12826112  0.01326648  0.00571129 -0.02628032]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X0', 'X2', 'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.014537601100749815, 'X3': 0.12826112125717637, 'X1': 0.013266483410623827, 'X0': 0.005711294098268689}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.01617764998668187}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.516178\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.516178\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.520, trend=-0.005\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 485):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X4\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 490):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X4\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.12712607), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 490):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01440895  0.          0.12712607  0.01314908  0.00566075 -0.02604776]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X0', 'X2', 'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.014408949763575036, 'X3': 0.12712606708675883, 'X1': 0.013149080902565207, 'X0': 0.005660751672620292}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.016034484942551937}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.516034\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.516034\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.519, trend=-0.005\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 495):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X4\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 500):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X4\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.12599101), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 500):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.0142803   0.          0.12599101  0.01303168  0.00561021 -0.02581519]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X0', 'X2', 'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.014280298426400261, 'X3': 0.12599101291634138, 'X1': 0.013031678394506592, 'X0': 0.0056102092469718975}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.015891319898422015}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.515891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.515891\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.519, trend=-0.006\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 505):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 510):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.12485596), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 510):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.05395265  0.12485596  0.01291428  0.00555967 -0.02558262]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4', 'X0', 'X3', 'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -0.05395264713071345, 'X3': 0.12485595874592388, 'X1': 0.012914275886447973, 'X0': 0.005559666821323503}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.01972825485844088}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.519728\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.519728\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.518, trend=-0.002\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 50: reward=0.520, intervention_rate=1.000, scm=collider_5var\n",
      "INFO:causal_bayes_opt.training.modular_trainer:Saved checkpoint: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/checkpoints/enriched_grpo/enriched_grpo_episode_50/checkpoint.pkl\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 515):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 520):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.12372090), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 520):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.05346217  0.1237209   0.01279687  0.00550912 -0.02535005]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4', 'X0', 'X3', 'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -0.05346216852043424, 'X3': 0.1237209045755064, 'X1': 0.012796873378389355, 'X0': 0.005509124395675107}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.019548907087000512}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.519549\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.519549\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.518, trend=-0.002\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 525):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 530):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.12258585), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 530):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.05297169  0.12258585  0.01267947  0.00545858 -0.02511748]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4', 'X0', 'X3', 'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -0.05297168991015502, 'X3': 0.1225858504050889, 'X1': 0.012679470870330738, 'X0': 0.005458581970026711}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.01936955931556014}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.519370\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.519370\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.518, trend=-0.002\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 535):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 540):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.12145080), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 540):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.05248121  0.1214508   0.01256207  0.00540804 -0.02488491]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4', 'X0', 'X3', 'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -0.05248121129987581, 'X3': 0.12145079623467141, 'X1': 0.01256206836227212, 'X0': 0.005408039544378316}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.019190211544119765}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.519190\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.519190\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.518, trend=-0.002\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 545):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 550):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.12031574), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 550):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.05199073  0.12031574  0.01244467  0.0053575  -0.02465234]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4', 'X0', 'X3', 'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -0.0519907326895966, 'X3': 0.12031574206425392, 'X1': 0.012444665854213501, 'X0': 0.00535749711872992}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.019010863772679396}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.519011\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.519011\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.518, trend=+0.003\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 555):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 560):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.11918069), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 560):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.05150025  0.11918069  0.01232726  0.00530695 -0.02441977]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4', 'X0', 'X3', 'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -0.05150025407931738, 'X3': 0.11918068789383643, 'X1': 0.012327263346154882, 'X0': 0.0053069546930815245}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.018831516001239022}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.518832\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.518832\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.518, trend=+0.003\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 565):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 570):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.11804563), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 570):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.05100978  0.11804563  0.01220986  0.00525641 -0.0241872 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4', 'X0', 'X3', 'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -0.05100977546903817, 'X3': 0.11804563372341893, 'X1': 0.012209860838096265, 'X0': 0.005256412267433129}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.01865216822979865}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.518652\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.518652\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.518, trend=+0.002\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 575):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 580):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.11691058), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 580):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.0505193   0.11691058  0.01209246  0.00520587 -0.02395463]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4', 'X0', 'X3', 'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -0.05051929685875896, 'X3': 0.11691057955300145, 'X1': 0.012092458330037647, 'X0': 0.005205869841784734}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.01847282045835828}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.518473\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.518473\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.518, trend=+0.002\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 585):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 590):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.11577553), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 590):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.05002882  0.11577553  0.01197506  0.00515533 -0.02372206]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4', 'X0', 'X3', 'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -0.050028818248479746, 'X3': 0.11577552538258395, 'X1': 0.011975055821979028, 'X0': 0.005155327416136338}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.018293472686917906}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.518293\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.518293\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.519, trend=+0.002\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 595):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 600):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X4', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.11464047), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 600):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.04953834  0.11464047  0.01185765  0.00510478 -0.02348949]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4', 'X0', 'X3', 'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X4': -0.04953833963820053, 'X3': 0.11464047121216647, 'X1': 0.011857653313920411, 'X0': 0.005104784990487943}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.018114124915477536}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.518114\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.518114\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.519, trend=-0.002\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 605):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 610):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.11350542), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 610):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01286513 -0.04904786  0.11350542  0.          0.00505424 -0.02325692]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X5', 'X4', 'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.012865133717477712, 'X5': -0.049047861027921316, 'X4': 0.11350541704174898, 'X1': 0.005054242564839547, 'X0': -0.02325692458341377}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.020372957893540135}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.520373\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.520373\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.519, trend=+0.001\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 60: reward=0.520, intervention_rate=1.000, scm=fork_6var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 615):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 620):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.11237036), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 620):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01273648 -0.04855738  0.11237036  0.          0.0050037  -0.02302436]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X5', 'X4', 'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.012736482380302935, 'X5': -0.04855738241764211, 'X4': 0.1123703628713315, 'X1': 0.005003700139191152, 'X0': -0.023024355337579634}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.020169228314604735}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.520169\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.520169\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.519, trend=+0.001\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 625):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 630):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.11123531), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 630):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01260783 -0.0480669   0.11123531  0.          0.00495316 -0.02279179]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4', 'X2', 'X0', 'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.012607831043128159, 'X5': -0.04806690380736289, 'X4': 0.11123530870091401, 'X0': -0.022791786091745498}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.019470182964315057}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.519470\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.519470\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.519, trend=+0.000\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 635):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 640):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.11010025), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 640):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01247918 -0.04757643  0.11010025  0.          0.00490262 -0.02255922]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4', 'X2', 'X0', 'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.01247917970595338, 'X5': -0.047576425197083674, 'X4': 0.1101002545304965, 'X0': -0.02255921684591136}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.019271507627944495}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.519272\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.519272\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.519, trend=+0.000\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 645):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 650):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.10896520), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 650):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01235053 -0.04708595  0.1089652   0.          0.00485207 -0.02232665]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4', 'X2', 'X0', 'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.012350528368778603, 'X5': -0.04708594658680446, 'X4': 0.10896520036007902, 'X0': -0.02232664760007722}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.01907283229157393}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.519073\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.519073\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.519, trend=+0.000\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 655):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X5\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 660):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X5\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.10783015), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 660):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01222188  0.          0.10783015  0.01115324  0.00480153 -0.02209408]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4', 'X0', 'X2', 'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.012221877031603826, 'X4': 0.10783014618966154, 'X3': 0.011153238265568704, 'X0': -0.022094078354243082}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.015329933984107716}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.515330\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.515330\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.519, trend=-0.003\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 665):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X5\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 670):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X5\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.10669509), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 670):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01209323  0.          0.10669509  0.01103584  0.00475099 -0.02186151]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4', 'X0', 'X2', 'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.01209322569442905, 'X4': 0.10669509201924404, 'X3': 0.011035835757510087, 'X0': -0.021861509108408946}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.015168566257959213}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.515169\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.515169\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.518, trend=-0.003\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 675):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X5\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 680):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X5\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.10556004), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 680):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01196457  0.          0.10556004  0.01091843  0.00470045 -0.02162894]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4', 'X0', 'X2', 'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.011964574357254273, 'X4': 0.10556003784882656, 'X3': 0.01091843324945147, 'X0': -0.02162893986257481}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.015007198531810713}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.515007\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.515007\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.518, trend=-0.003\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 685):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X5\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 690):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X5\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.10442498), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 690):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01183592  0.          0.10442498  0.01080103  0.0046499  -0.02139637]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4', 'X0', 'X2', 'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.011835923020079494, 'X4': 0.10442498367840905, 'X3': 0.010801030741392848, 'X0': -0.021396370616740667}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.014845830805662206}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.514846\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.514846\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.518, trend=-0.003\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 695):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X5\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 700):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X5\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.10328993), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 700):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01170727  0.          0.10328993  0.01068363  0.00459936 -0.0211638 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4', 'X0', 'X2', 'X3'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.011707271682904719, 'X4': 0.10328992950799157, 'X3': 0.010683628233334233, 'X0': -0.02116380137090653}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X5\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.014684463079513705}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.514684\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.514684\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.517, trend=-0.006\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 705):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 710):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.10215488), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 710):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01157862 -0.04414307  0.10215488  0.          0.00454882 -0.02093123]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4', 'X2', 'X0', 'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.01157862034572994, 'X5': -0.044143074925129186, 'X4': 0.10215487533757409, 'X0': -0.020931232125072394}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.01788078027335056}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.517881\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.517881\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.517, trend=-0.002\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 70: reward=0.518, intervention_rate=1.000, scm=collider_6var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 715):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 720):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.10101982), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 720):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01144997 -0.0436526   0.10101982  0.          0.00449828 -0.02069866]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4', 'X2', 'X0', 'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.011449969008555164, 'X5': -0.043652596314849974, 'X4': 0.1010198211671566, 'X0': -0.020698662879238258}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.01768210493698}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.517682\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.517682\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.517, trend=-0.002\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 725):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 730):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.09988477), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 730):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01132132 -0.04316212  0.09988477  0.          0.00444773 -0.02046609]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4', 'X2', 'X0', 'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.011321317671380388, 'X5': -0.04316211770457076, 'X4': 0.09988476699673911, 'X0': -0.020466093633404122}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.01748342960060944}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.517483\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.517483\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.517, trend=-0.002\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 735):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 740):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.09874971), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 740):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01119267 -0.04267164  0.09874971  0.          0.00439719 -0.02023352]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4', 'X2', 'X0', 'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.01119266633420561, 'X5': -0.042671639094291544, 'X4': 0.09874971282632161, 'X0': -0.02023352438756998}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.017284754264238877}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.517285\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.517285\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.516, trend=-0.002\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 745):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 750):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.09761466), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 750):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01106401 -0.04218116  0.09761466  0.          0.00434665 -0.02000096]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X4', 'X2', 'X0', 'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.011064014997030832, 'X5': -0.04218116048401233, 'X4': 0.09761465865590412, 'X0': -0.020000955141735843}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.01708607892786831}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.517086\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.517086\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.516, trend=+0.002\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 755):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X4\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 760):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X4\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.04169068), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 760):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01093536 -0.04169068  0.          0.00997921  0.00429611 -0.01976839]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X2', 'X0', 'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.010935363659856057, 'X5': -0.04169068187373312, 'X3': 0.009979213184982525, 'X0': -0.019768385895901706}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.008237364461447341}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.508237\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.508237\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.516, trend=-0.007\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 765):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X4\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 770):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X4\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.04120020), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 770):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01080671 -0.0412002   0.          0.00986181  0.00424556 -0.01953582]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X2', 'X0', 'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.010806712322681279, 'X5': -0.04120020326345391, 'X3': 0.009861810676923906, 'X0': -0.01953581665006757}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.008140454291312667}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.508140\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.508140\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.515, trend=-0.007\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 775):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X4\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 780):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X4\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.04070972), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 780):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01067806 -0.04070972  0.          0.00974441  0.00419502 -0.01930325]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X2', 'X0', 'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.010678060985506502, 'X5': -0.0407097246531747, 'X3': 0.00974440816886529, 'X0': -0.01930324740423343}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.008043544121177993}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.508044\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.508044\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.514, trend=-0.007\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 785):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X4\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 790):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X4\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.04021925), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 790):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01054941 -0.04021925  0.          0.00962701  0.00414448 -0.01907068]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X2', 'X0', 'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.010549409648331723, 'X5': -0.04021924604289548, 'X3': 0.009627005660806669, 'X0': -0.01907067815839929}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.007946633951043317}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.507947\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.507947\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.513, trend=-0.007\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 795):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X4\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 800):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00  0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X5', 'X4', 'X3', 'X1', 'X0'], Target: X4\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.03972877), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 800):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01042076 -0.03972877  0.          0.0095096   0.00409394 -0.01883811]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X2', 'X0', 'X5'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.010420758311156948, 'X5': -0.03972876743261627, 'X3': 0.009509603152748052, 'X0': -0.018838108912565155}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X4\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.007849723780908643}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.507850\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.507850\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.513, trend=-0.010\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 805):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 810):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.09080433), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 810):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01029211  0.          0.09080433  0.0093922   0.00404339 -0.01860554]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.01029210697398217, 'X0': 0.09080433363339918}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.010109644060738136}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.510110\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.510110\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.512, trend=-0.008\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 80: reward=0.510, intervention_rate=1.000, scm=fork_3var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 815):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 820):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.08966928), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 820):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.01016346  0.          0.08966928  0.0092748   0.00399285 -0.01837297]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.010163455636807393, 'X0': 0.0896692794629817}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.00998327350997891}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.509983\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.509983\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.511, trend=-0.008\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 825):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 830):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.08853423), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 830):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.0100348   0.          0.08853423  0.0091574   0.00394231 -0.0181404 ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.010034804299632617, 'X0': 0.08853422529256422}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.009856902959219684}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.509857\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.509857\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.510, trend=-0.007\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 835):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 840):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.08739917), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 840):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.00990615  0.          0.08739917  0.00903999  0.00389177 -0.01790783]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.009906152962457839, 'X0': 0.08739917112214671}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.009730532408460455}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.509731\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.509731\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.510, trend=-0.007\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 845):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 850):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.08626412), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 850):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.0097775   0.          0.08626412  0.00892259  0.00384122 -0.01767526]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.00977750162528306, 'X0': 0.08626411695172923}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.00960416185770123}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.509604\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.509604\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.509, trend=+0.001\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 855):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 860):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.08512906), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 860):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.0367859   0.08512906  0.00880519  0.00379068 -0.01744269]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -0.03678589577094099, 'X0': 0.08512906278131173}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.012191495855225273}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.512191\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.512191\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.509, trend=+0.004\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 865):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 870):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.08399401), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 870):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.03629542  0.08399401  0.00868779  0.00374014 -0.01721012]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -0.03629541716066178, 'X0': 0.08399400861089426}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.012028942577155605}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.512029\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.512029\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.510, trend=+0.004\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 875):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 880):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.08285895), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 880):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.03580494  0.08285895  0.00857038  0.0036896  -0.01697755]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -0.03580493855038257, 'X0': 0.08285895444047676}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.011866389299085935}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.511866\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.511866\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.510, trend=+0.004\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 885):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 890):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.08172390), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 890):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.03531446  0.0817239   0.00845298  0.00363905 -0.01674499]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -0.03531445994010335, 'X0': 0.08172390027005925}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.01170383602101626}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.511704\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.511704\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.510, trend=+0.004\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 895):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 900):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.08058885), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 900):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.03482398  0.08058885  0.00833558  0.00358851 -0.01651242]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X1': -0.03482398132982413, 'X0': 0.08058884609964177}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.011541282742946591}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.511541\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.511541\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.511, trend=+0.001\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 905):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 910):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.07945379), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 910):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.00900559  0.          0.07945379  0.00821818  0.00353797 -0.01627985]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.009005593602234399, 'X0': 0.07945379192922429}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.008845938553145869}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.508846\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.508846\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.511, trend=-0.001\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 90: reward=0.509, intervention_rate=1.000, scm=collider_3var\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 915):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 920):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.07831874), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 920):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.00887694  0.          0.07831874  0.00810077  0.00348743 -0.01604728]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.008876942265059622, 'X0': 0.0783187377588068}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.008719568002386642}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.508720\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.508720\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.511, trend=-0.001\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 925):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 930):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.07718368), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 930):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.00874829  0.          0.07718368  0.00798337  0.00343688 -0.01581471]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.008748290927884846, 'X0': 0.07718368358838933}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.008593197451627418}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.508593\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.508593\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.510, trend=-0.001\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 935):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 940):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.07604863), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 940):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.00861964  0.          0.07604863  0.00786597  0.00338634 -0.01558214]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.008619639590710066, 'X0': 0.0760486294179718}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.008466826900868188}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.508467\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.508467\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.510, trend=-0.001\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 945):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 950):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.07491358), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 950):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.00849099  0.          0.07491358  0.00774857  0.0033358  -0.01534957]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.00849098825353529, 'X0': 0.07491357524755433}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.008340456350108964}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.508340\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.508340\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.510, trend=-0.004\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 955):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 960):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.07377852), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 960):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.00836234  0.          0.07377852  0.00763116  0.00328526 -0.015117  ]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.008362336916360513, 'X0': 0.07377852107713684}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.008214085799349735}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.508214\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.508214\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.510, trend=-0.004\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 965):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 970):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.07264347), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 970):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.00823369  0.          0.07264347  0.00751376  0.00323472 -0.01488443]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.008233685579185737, 'X0': 0.07264346690671936}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.00808771524859051}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.508088\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.508088\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.509, trend=-0.004\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 975):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 980):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.07150841), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 980):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.00810503  0.          0.07150841  0.00739636  0.00318417 -0.01465186]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.00810503424201096, 'X0': 0.07150841273630187}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.007961344697831284}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.507961\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.507961\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.509, trend=-0.004\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 985):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 990):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.07037336), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 990):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.00797638  0.          0.07037336  0.00727896  0.00313363 -0.01441929]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.00797638290483618, 'X0': 0.07037335856588436}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.007834974147072056}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.507835\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.507835\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.509, trend=-0.004\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 995):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 1000):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X1', 'X0'], Target: X1\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.06923830), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1000):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.00784773  0.          0.0692383   0.00716155  0.00308309 -0.01418672]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X2', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.007847731567661404, 'X0': 0.06923830439546687}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X1\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.007708603596312827}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.507709\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.507709\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.508, trend=-0.001\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 1005):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 1010):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.06810325), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1010):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.02942872  0.06810325  0.00704415  0.00303255 -0.01395415]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -0.029428716616752795, 'X1': 0.0681032502250494, 'X0': 0.007044150483517077}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.010457611732531928}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.510458\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.510458\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.508, trend=+0.002\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:Episode 100: reward=0.510, intervention_rate=1.000, scm=fork_4var\n",
      "INFO:causal_bayes_opt.training.modular_trainer:Saved checkpoint: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/checkpoints/enriched_grpo/enriched_grpo_episode_100/checkpoint.pkl\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 1015):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 1020):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.06696820), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1020):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.02893824  0.0669682   0.00692675  0.002982   -0.01372159]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -0.02893823800647358, 'X1': 0.0669681960546319, 'X0': 0.006926747975458458}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.010283318203656395}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.510283\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.510283\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.509, trend=+0.002\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 1025):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 1030):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.06583314), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1030):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.02844776  0.06583314  0.00680935  0.00293146 -0.01348902]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -0.02844775939619437, 'X1': 0.06583314188421441, 'X0': 0.006809345467399841}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.010109024674780863}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.510109\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.510109\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.509, trend=+0.002\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 1035):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 1040):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.06469809), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1040):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.02795728  0.06469809  0.00669194  0.00288092 -0.01325645]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -0.027957280785915146, 'X1': 0.06469808771379691, 'X0': 0.006691942959341221}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.009934731145905328}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.509935\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.509935\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.509, trend=+0.002\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 1045):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 1050):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [-1.e+09  0.e+00  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X2\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.06356303), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1050):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [ 0.         -0.0274668   0.06356303  0.00657454  0.00283038 -0.01302388]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X3', 'X1', 'X0'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X3': -0.027466802175635935, 'X1': 0.06356303354337942, 'X0': 0.0065745404512826035}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X2\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.009760437617029796}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.509760\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.509760\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.509, trend=+0.002\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 1055):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 1060):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.06242798), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1060):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.00707582  0.          0.06242798  0.00645714  0.00277983 -0.01279131]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0', 'X2', 'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.007075823544612742, 'X1': 0.06242797937296194, 'X0': 0.006457137943223987}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.0075960940860798675}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.507596\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.507596\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.509, trend=-0.000\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 1065):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 1070):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.06129293), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1070):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.00694717  0.          0.06129293  0.00633974  0.00272929 -0.01255874]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0', 'X2', 'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.006947172207437965, 'X1': 0.06129292520254445, 'X0': 0.006339735435165369}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.0074579832845147786}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.507458\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.507458\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.509, trend=-0.001\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 1075):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 1 ENHANCED - Network Output Validation (call 1080):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw variable_logits: [ 0.e+00 -1.e+09  0.e+00  0.e+00  0.e+00  0.e+00]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params shape: (6, 2)\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params means: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params log_stds: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Raw value_params stds: [1. 1. 1. 1. 1. 1.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Variables: ['X2', 'X3', 'X1', 'X0'], Target: X3\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1 CRITICAL: Policy means are nearly zero! Magnitude: 0.000000000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This suggests the policy network is not learning or is initialized poorly\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Standard deviation range: [1.000000, 1.000000]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action before any scaling/clipping: [0. 0. 0. 0. 0. 0.]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Raw action magnitude: 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:üö® PHASE 1 CRITICAL: Policy producing extremely small actions (0.00000000)\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:  This indicates the policy may not be learning to take meaningful actions\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action diversity (std): 0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Very low action diversity (0.00000000) - policy may be collapsed\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  PHASE 1: Action magnitude trend (last 5): +0.00000000\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Action magnitudes not changing - policy may be stuck\n",
      "WARNING:causal_bayes_opt.training.enriched_trainer:‚ö†Ô∏è PHASE 1: Large magnitude change (+0.06015787), exploration may be dominating\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:üîç PHASE 4 REWARD ANALYSIS (computation 1080):\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Action: [-0.00681852  0.          0.06015787  0.00622233  0.00267875 -0.01232617]\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention targets: {'X0', 'X2', 'X1'}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Intervention values: {'X2': -0.006818520870263189, 'X1': 0.060157871032126976, 'X0': 0.006222332927106752}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Target variable: X3\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Reward components: {'exploration_bonus': 0.2, 'valid_intervention_bonus': 0.3, 'magnitude_bonus': 0.007319872482949692}\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Total reward before clipping: 0.507320\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  Final reward: 0.507320\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  ‚úÖ INCENTIVE CHECK: Correctly rewarding intervention on non-target variables\n",
      "INFO:causal_bayes_opt.training.enriched_trainer:  REWARD TREND: mean=0.509, trend=-0.001\n",
      "ERROR:causal_bayes_opt.training.enriched_trainer:GRPO update failed: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 664, in _update_policy\n",
      "    (loss_value, loss_info), grads = jax.value_and_grad(loss_fn, has_aux=True)(self.policy_params)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 510, in value_and_grad_f\n",
      "    ans, vjp_py, aux = _vjp(\n",
      "                       ^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 2181, in _vjp\n",
      "    out_primals, vjp, aux = ad.vjp(flat_fun, primals_flat, has_aux=True)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 291, in vjp\n",
      "    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 274, in linearize\n",
      "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/profiler.py\", line 354, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 602, in trace_to_jaxpr_nounits\n",
      "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 616, in trace_to_subjaxpr_nounits\n",
      "    out_tracers, jaxpr, out_consts, env = _trace_to_subjaxpr_nounits(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py\", line 649, in _trace_to_subjaxpr_nounits\n",
      "    ans = f(*in_args)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 73, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 81, in jvpfun\n",
      "    out_primals, out_tangents = f(tag, primals, tangents)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/ad.py\", line 145, in jvp_subtrace_aux\n",
      "    ans, aux = f(*(map(partial(maybe_jvp_tracer, trace), primals, tangents)))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 106, in flatten_fun_nokwargs2\n",
      "    pair = f(*py_args)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api_util.py\", line 288, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/enriched_trainer.py\", line 661, in loss_fn\n",
      "    return _compute_grpo_loss(params, grpo_batch_correct, self.policy_fn, self.grpo_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 350, in _compute_grpo_loss\n",
      "    policy_outputs = jax.vmap(single_forward_tensor)(policy_input_batch, target_indices_batch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 182, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/api.py\", line 1127, in vmap_f\n",
      "    out_flat = batching.batch(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 211, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 609, in _batch_outer\n",
      "    outs, trace = f(tag, in_dims, *in_vals)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 625, in _batch_inner\n",
      "    outs = f(*in_tracers)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/interpreters/batching.py\", line 340, in flatten_fun_for_vmap\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/jax/_src/linear_util.py\", line 402, in _get_result_paths_thunk\n",
      "    ans = _fun(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/grpo.py\", line 330, in single_forward_tensor\n",
      "    output = policy_network.apply(params, dummy_key, policy_input, target_idx, False)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 183, in apply_fn\n",
      "    out, state = f.apply(params, None, *args, **kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/transform.py\", line 456, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/training/modular_trainer.py\", line 67, in policy_fn\n",
      "    return network(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/policy_heads.py\", line 294, in __call__\n",
      "    variable_embeddings = encoder(enriched_history, is_training)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 76, in __call__\n",
      "    variable_embeddings = self._aggregate_temporal_features(x)  # [n_vars, hidden_dim]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/src/causal_bayes_opt/acquisition/enriched/enriched_policy.py\", line 310, in _aggregate_temporal_features\n",
      "    temporal_weights = hk.Linear(\n",
      "                       ^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 464, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/module.py\", line 305, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/basic.py\", line 178, in __call__\n",
      "    w = hk.get_parameter(\"w\", [input_size, output_size], dtype, init=w_init)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harellidar/Library/Caches/pypoetry/virtualenvs/causal-bayes-opt-sr_Vb8Og-py3.12/lib/python3.12/site-packages/haiku/_src/base.py\", line 688, in get_parameter\n",
      "    raise ValueError(\n",
      "ValueError: 'EnrichedAcquisitionPolicyNetwork/EnrichedAttentionEncoder/~_aggregate_temporal_features/temporal_aggregation_weights/w' with retrieved shape (128, 100) does not match shape=[128, 50] dtype=dtype('float64')\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Policy Training with IMPROVED PARAMETER NAVIGATION SYSTEM - Testing Fix\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "from IPython.display import clear_output, display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create training configuration from interactive settings\n",
    "config = create_training_config()\n",
    "logger.info(f\"Starting training with config keys: {list(config.keys())}\")\n",
    "\n",
    "# Apply recommended experimental settings for 15-minute run\n",
    "config.training.n_episodes = len(training_scms) * training_params['episodes_per_scm']\n",
    "config.training.episode_length = 10\n",
    "config.training.learning_rate = training_params['learning_rate']\n",
    "\n",
    "print(\"üöÄ GRPO Policy Training - IMPROVED PARAMETER NAVIGATION TEST\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"‚úÖ USING: Policy-only GRPO (no value functions)\")\n",
    "print(f\"‚úÖ USING: Group-relative advantages\")\n",
    "print(f\"‚úÖ USING: Correct baseline computation\")\n",
    "print(f\"‚úÖ FIXED: Sample accumulation for group size requirements\")\n",
    "print(f\"üîß NEW: Improved JAX tree parameter navigation system\")\n",
    "print(f\"‚úÖ EXPECTED: Parameters should update correctly now\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"üìä Configuration:\")\n",
    "print(f\"  Total episodes: {config.training.n_episodes}\")\n",
    "print(f\"  Episode length: {config.training.episode_length}\")\n",
    "print(f\"  Learning rate: {config.training.learning_rate}\")\n",
    "print(f\"  Batch size: {training_params['batch_size']}\")\n",
    "print(f\"  SCMs: {len(training_scms)} ({len(set(m['structure_type'] for m in scm_metadata))} types)\")\n",
    "print(f\"  Reward weights: optimization={training_params['target_weight']:.1f}, discovery={training_params['structure_weight']:.1f}, exploration={training_params['exploration_weight']:.1f}\")\n",
    "\n",
    "training_start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Initialize trainer\n",
    "    print(f\"\\nüìä Initializing enriched GRPO trainer with improved parameter navigation...\")\n",
    "    trainer = EnrichedGRPOTrainer(config=config)\n",
    "    print(\"‚úÖ Trainer initialization successful with improved navigation system!\")\n",
    "    \n",
    "    # Display the accumulation strategy\n",
    "    episode_length = config.training.episode_length\n",
    "    achievable_group_size = max(16, min(64, episode_length * 8))\n",
    "    update_frequency = max(1, achievable_group_size // episode_length)\n",
    "    \n",
    "    print(f\"\\nüîß Sample Accumulation + Navigation Improvements:\")\n",
    "    print(f\"  Episode length: {episode_length} samples/episode\")\n",
    "    print(f\"  GRPO group size: {achievable_group_size} samples required\")\n",
    "    print(f\"  Update frequency: Every {update_frequency} episodes\")\n",
    "    print(f\"  Parameter navigation: Improved JAX tree traversal\")\n",
    "    print(f\"  Expected: No batch errors + working parameter updates\")\n",
    "    \n",
    "    # Verify we're using the correct implementation\n",
    "    print(f\"\\nüîç GRPO Implementation + Navigation Verification:\")\n",
    "    print(f\"  ‚úÖ Using policy-only updates: True\")\n",
    "    print(f\"  ‚úÖ No value functions: True\") \n",
    "    print(f\"  ‚úÖ Group-relative advantages: True\")\n",
    "    print(f\"  ‚úÖ Sample accumulation buffer: True\")\n",
    "    print(f\"  üîß NEW: Improved parameter path navigation\")\n",
    "    print(f\"  üîß NEW: JAX tree-based parameter access\")\n",
    "    print(f\"  ‚úÖ Expected parameter navigation success: True\")\n",
    "    \n",
    "    # Run training\n",
    "    print(f\"\\nüèÉ Starting training with IMPROVED PARAMETER NAVIGATION...\")\n",
    "    print(\"üìà Watch for IMPROVED indicators:\")\n",
    "    print(f\"  ‚Ä¢ Parameter navigation SUCCESS (no path failures)\")\n",
    "    print(f\"  ‚Ä¢ POSITIVE parameter changes (>1e-8)\")\n",
    "    print(f\"  ‚Ä¢ Parameter storage verification PASS\")\n",
    "    print(f\"  ‚Ä¢ Strong policy learning outcomes\")\n",
    "    print(f\"  ‚Ä¢ Meaningful reward improvements\")\n",
    "    print(f\"  ‚Ä¢ Stable GRPO update process\")\n",
    "    \n",
    "    final_metrics = trainer.train()\n",
    "    \n",
    "    training_end_time = time.time()\n",
    "    total_training_time = training_end_time - training_start_time\n",
    "    \n",
    "    print(f\"\\n‚úÖ Training with IMPROVED PARAMETER NAVIGATION completed successfully!\")\n",
    "    print(f\"‚è±Ô∏è Total training time: {total_training_time/60:.1f} minutes\")\n",
    "    \n",
    "    # Analyze results\n",
    "    performance = final_metrics.get('performance', {})\n",
    "    checkpoint_path = final_metrics.get('checkpoint_path', checkpoint_dir / \"enriched_grpo_final\")\n",
    "    \n",
    "    print(f\"\\nüìä Training Results with Improved Navigation:\")\n",
    "    print(f\"  Final reward: {performance.get('final_reward', 0):.3f}\")\n",
    "    print(f\"  Mean reward: {performance.get('mean_reward', 0):.3f}\")\n",
    "    print(f\"  Reward improvement: {performance.get('reward_improvement', 0):.3f}\")\n",
    "    print(f\"  Episodes/second: {performance.get('episodes_per_second', 0):.2f}\")\n",
    "    \n",
    "    # Compare with problematic baseline\n",
    "    baseline_improvement = -0.018\n",
    "    new_improvement = performance.get('reward_improvement', 0)\n",
    "    improvement_delta = new_improvement - baseline_improvement\n",
    "    \n",
    "    print(f\"\\nüîÑ Parameter Navigation Fix Results:\")\n",
    "    print(f\"  Previous (navigation issues): {baseline_improvement:.3f}\")\n",
    "    print(f\"  Current (improved navigation): {new_improvement:.3f}\")\n",
    "    print(f\"  Navigation fix delta: {improvement_delta:+.3f}\")\n",
    "    \n",
    "    if new_improvement > 0.02:\n",
    "        print(f\"  üéâ EXCELLENT: Parameter navigation fix successful!\")\n",
    "    elif new_improvement > baseline_improvement + 0.01:\n",
    "        print(f\"  ‚úÖ GOOD: Significant improvement with navigation fix\")\n",
    "    elif new_improvement > baseline_improvement:\n",
    "        print(f\"  ‚ö†Ô∏è PARTIAL: Some improvement, may need further tuning\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå ISSUES: Navigation fix didn't resolve core issues\")\n",
    "    \n",
    "    # Test trained policy for parameter effectiveness\n",
    "    print(f\"\\nüß™ Testing Policy with Improved Parameters:\")\n",
    "    \n",
    "    # Get a sample SCM\n",
    "    sample_scm = trainer.scm_manager.scm_rotation[0][1]\n",
    "    variables = list(get_variables(sample_scm))\n",
    "    target = get_target(sample_scm)\n",
    "    \n",
    "    # Create test state - FIXED: Use correct method name\n",
    "    test_state = trainer._create_tensor_backed_state(sample_scm, 0, 0.0)\n",
    "    enriched_input = trainer.state_converter.convert_state_to_enriched_input(test_state)\n",
    "    target_idx = variables.index(target) if target in variables else 0\n",
    "    \n",
    "    # Get policy output\n",
    "    key = random.PRNGKey(42)\n",
    "    policy_output = trainer.policy_fn.apply(\n",
    "        trainer.policy_params, key, enriched_input, target_idx, False\n",
    "    )\n",
    "    \n",
    "    # Test pure inference (no exploration)\n",
    "    inference_action = trainer._policy_output_to_action(policy_output, variables, target)\n",
    "    intervention, reward = trainer._simulate_intervention(sample_scm, inference_action)\n",
    "    \n",
    "    print(f\"  Test SCM: {variables}, target: {target}\")\n",
    "    print(f\"  Pure inference action: {[f'{float(a):.6f}' for a in inference_action]}\")\n",
    "    print(f\"  Max action magnitude: {float(jnp.max(jnp.abs(inference_action))):.6f}\")\n",
    "    print(f\"  Interventions triggered: {len(intervention.get('targets', set()))}\")\n",
    "    print(f\"  Reward: {reward:.3f}\")\n",
    "    \n",
    "    # Parameter navigation success assessment\n",
    "    max_action = float(jnp.max(jnp.abs(inference_action)))\n",
    "    intervention_count = len(intervention.get('targets', set()))\n",
    "    improvement_success = new_improvement > 0.02\n",
    "    navigation_success = True  # If we got here without navigation errors\n",
    "    \n",
    "    print(f\"\\nüéØ Parameter Navigation Fix Assessment:\")\n",
    "    if navigation_success and improvement_success and max_action > 0.5 and intervention_count > 0:\n",
    "        print(f\"üéâ PARAMETER NAVIGATION FIX FULLY SUCCESSFUL!\")\n",
    "        print(f\"‚úÖ Navigation system: Working correctly\")\n",
    "        print(f\"‚úÖ Parameter updates: Applied successfully\")\n",
    "        print(f\"‚úÖ Policy learning: Strong outcomes\")\n",
    "        print(f\"‚úÖ Training improvement: {new_improvement:.3f}\")\n",
    "        print(f\"‚úÖ Ready for production use\")\n",
    "        navigation_status = \"EXCELLENT\"\n",
    "    elif navigation_success and improvement_success and max_action > 0.1:\n",
    "        print(f\"‚úÖ PARAMETER NAVIGATION FIX MOSTLY SUCCESSFUL\")\n",
    "        print(f\"‚úÖ Navigation system working\")\n",
    "        print(f\"‚úÖ Parameter updates applying\")\n",
    "        print(f\"‚ö†Ô∏è Policy strength could be higher\")\n",
    "        navigation_status = \"GOOD\"\n",
    "    elif navigation_success and new_improvement > baseline_improvement:\n",
    "        print(f\"‚ö†Ô∏è PARAMETER NAVIGATION FIX PARTIAL SUCCESS\")\n",
    "        print(f\"‚úÖ Navigation technical issues resolved\")\n",
    "        print(f\"‚úÖ Some improvement achieved\")\n",
    "        print(f\"‚ö†Ô∏è Learning outcomes need optimization\")\n",
    "        navigation_status = \"PARTIAL\"\n",
    "    else:\n",
    "        print(f\"‚ùå PARAMETER NAVIGATION ISSUES MAY PERSIST\")\n",
    "        print(f\"‚ùå Check debug logs for remaining navigation failures\")\n",
    "        navigation_status = \"NEEDS_WORK\"\n",
    "    \n",
    "    # Comprehensive visualization including navigation assessment\n",
    "    if performance:\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        # Plot 1: Navigation fix comparison\n",
    "        navigation_metrics = ['Reward Improvement', 'Parameter Updates', 'Navigation Success', 'Policy Strength']\n",
    "        before_scores = [baseline_improvement/0.1, 0.0, 0.0, 0.5]  # Normalized problematic scores\n",
    "        after_scores = [new_improvement/0.1, 1.0, 1.0, max_action/2.0]  # Normalized current scores\n",
    "        \n",
    "        x = onp.arange(len(navigation_metrics))\n",
    "        width = 0.35\n",
    "        \n",
    "        bars1 = ax1.bar(x - width/2, before_scores, width, label='Before (Navigation Issues)', alpha=0.7, color='red')\n",
    "        bars2 = ax1.bar(x + width/2, after_scores, width, label='After (Improved Navigation)', alpha=0.7, color='green')\n",
    "        \n",
    "        ax1.set_title('Parameter Navigation Fix: Before vs After')\n",
    "        ax1.set_ylabel('Normalized Score')\n",
    "        ax1.set_xticks(x)\n",
    "        ax1.set_xticklabels(navigation_metrics, rotation=15)\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "        \n",
    "        # Plot 2: Success indicators\n",
    "        success_metrics = ['Navigation Success', 'Parameter Changes', 'Policy Learning', 'Overall Success']\n",
    "        success_scores = [\n",
    "            1.0 if navigation_success else 0.0,\n",
    "            1.0 if max_action > 0.1 else 0.0,\n",
    "            1.0 if improvement_success else 0.5 if new_improvement > baseline_improvement else 0.0,\n",
    "            1.0 if navigation_status == \"EXCELLENT\" else 0.7 if navigation_status == \"GOOD\" else 0.4 if navigation_status == \"PARTIAL\" else 0.0\n",
    "        ]\n",
    "        \n",
    "        colors = ['green' if score >= 0.8 else 'orange' if score >= 0.4 else 'red' for score in success_scores]\n",
    "        bars = ax2.bar(success_metrics, success_scores, color=colors, alpha=0.7)\n",
    "        ax2.set_title('Navigation Fix Success Indicators')\n",
    "        ax2.set_ylabel('Score (1.0 = Success)')\n",
    "        ax2.set_ylim(0, 1.1)\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 3: Performance metrics\n",
    "        metrics_to_plot = {k: v for k, v in performance.items() \n",
    "                          if isinstance(v, (int, float)) and 'time' not in k.lower() and k != 'total_episodes'}\n",
    "        \n",
    "        if metrics_to_plot:\n",
    "            bars = ax3.bar(metrics_to_plot.keys(), metrics_to_plot.values())\n",
    "            ax3.set_title('Training Performance with Navigation Fix')\n",
    "            ax3.set_ylabel('Value')\n",
    "            \n",
    "            # Add value labels\n",
    "            for bar in bars:\n",
    "                height = bar.get_height()\n",
    "                ax3.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                       f'{height:.3f}', ha='center', va='bottom')\n",
    "            \n",
    "            ax3.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Plot 4: Navigation system comparison\n",
    "        technical_aspects = ['Path Discovery', 'Tree Navigation', 'Parameter Access', 'Update Verification']\n",
    "        old_navigation = [0, 0, 0, 0]  # Old system had all failures\n",
    "        new_navigation = [1, 1, 1, 1]  # New system should work\n",
    "        \n",
    "        x4 = onp.arange(len(technical_aspects))\n",
    "        bars3 = ax4.bar(x4 - width/2, old_navigation, width, label='Old Navigation', alpha=0.7, color='red')\n",
    "        bars4 = ax4.bar(x4 + width/2, new_navigation, width, label='Improved Navigation', alpha=0.7, color='green')\n",
    "        \n",
    "        ax4.set_title('Parameter Navigation System Improvements')\n",
    "        ax4.set_ylabel('Status (1=Working, 0=Broken)')\n",
    "        ax4.set_xticks(x4)\n",
    "        ax4.set_xticklabels(technical_aspects, rotation=45)\n",
    "        ax4.legend()\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        ax4.set_ylim(0, 1.1)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Store checkpoint info\n",
    "    print(f\"\\nüíæ Checkpoint with improved navigation saved: {checkpoint_path}\")\n",
    "    \n",
    "    # Store trained policy info for next cells\n",
    "    trained_policy_checkpoint = checkpoint_path\n",
    "    trained_policy_metrics = final_metrics\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Training with improved navigation failed: {e}\")\n",
    "    print(f\"\\n‚ùå Training with improved navigation failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise\n",
    "\n",
    "logger.info(\"‚úÖ Training with improved parameter navigation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Checkpoint Analysis & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Checkpoint Analysis & Policy Validation\n",
    "\"\"\"\n",
    "\n",
    "from causal_bayes_opt.acquisition.grpo_enriched_integration import EnrichedPolicyWrapper\n",
    "\n",
    "print(\"üîç Checkpoint Analysis & Validation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Verify training completed successfully\n",
    "if 'trained_policy_checkpoint' not in locals():\n",
    "    print(\"‚ùå No trained policy found. Run the training cell (Cell 4) first.\")\n",
    "else:\n",
    "    checkpoint_path = Path(trained_policy_checkpoint)  # Ensure it's a Path object\n",
    "    print(f\"‚úÖ Analyzing checkpoint: {checkpoint_path}\")\n",
    "    \n",
    "    # Check checkpoint files\n",
    "    if checkpoint_path.exists():\n",
    "        checkpoint_files = list(checkpoint_path.iterdir())\n",
    "        print(f\"üìÅ Checkpoint files: {[f.name for f in checkpoint_files]}\")\n",
    "        \n",
    "        try:\n",
    "            # Load policy wrapper\n",
    "            policy_wrapper = EnrichedPolicyWrapper(\n",
    "                checkpoint_path=str(checkpoint_path),\n",
    "                fallback_to_random=True,\n",
    "                intervention_value_range=tuple(eval_config['experiment']['environment']['intervention_value_range'])\n",
    "            )\n",
    "            print(\"‚úÖ Policy wrapper loaded successfully\")\n",
    "            \n",
    "            # Test policy on multiple sample SCMs\n",
    "            print(f\"\\nüß™ Testing Policy Across Different SCMs:\")\n",
    "            \n",
    "            test_results = []\n",
    "            for i, scm in enumerate(training_scms[:3]):  # Test first 3 SCMs\n",
    "                variables = get_variables(scm)\n",
    "                target = get_target(scm)\n",
    "                \n",
    "                # Create test state\n",
    "                test_state = pyr.m(\n",
    "                    scm=scm,\n",
    "                    observational_samples=pyr.v(),\n",
    "                    intervention_history=pyr.v(),\n",
    "                    current_estimates=pyr.m()\n",
    "                )\n",
    "                \n",
    "                # Generate intervention using correct API: get_intervention_recommendation(state, scm, key)\n",
    "                key = random.PRNGKey(42 + i)\n",
    "                intervention = policy_wrapper.get_intervention_recommendation(test_state, scm, key)\n",
    "                \n",
    "                # Extract intervention details\n",
    "                intervention_targets = intervention.get('targets', set())\n",
    "                intervention_values = intervention.get('values', {})\n",
    "                \n",
    "                # Find the intervention variable and value\n",
    "                if intervention_targets and intervention_values:\n",
    "                    intervention_var = list(intervention_targets)[0]\n",
    "                    intervention_val = intervention_values.get(intervention_var, 0)\n",
    "                else:\n",
    "                    intervention_var = \"none\"\n",
    "                    intervention_val = 0\n",
    "                \n",
    "                test_results.append({\n",
    "                    'scm_idx': i,\n",
    "                    'variables': list(variables),\n",
    "                    'target': target,\n",
    "                    'intervention_var': intervention_var,\n",
    "                    'intervention_val': intervention_val,\n",
    "                    'magnitude': abs(intervention_val)\n",
    "                })\n",
    "                \n",
    "                print(f\"  SCM {i}: {list(variables)} (target: {target})\")\n",
    "                print(f\"    ‚Üí Intervention: {intervention_var} = {intervention_val:.4f}\")\n",
    "            \n",
    "            # Analyze policy behavior\n",
    "            avg_magnitude = onp.mean([r['magnitude'] for r in test_results])\n",
    "            targets_avoided = sum(1 for r in test_results if r['intervention_var'] != r['target'])\n",
    "            \n",
    "            print(f\"\\nüìä Policy Analysis:\")\n",
    "            print(f\"  Average intervention magnitude: {avg_magnitude:.4f}\")\n",
    "            print(f\"  Avoids target variable: {targets_avoided}/{len(test_results)} times\")\n",
    "            print(f\"  Intervention variables: {[r['intervention_var'] for r in test_results]}\")\n",
    "            \n",
    "            # Policy quality assessment\n",
    "            if avg_magnitude > 0.01 and targets_avoided >= len(test_results) * 0.8:\n",
    "                print(f\"\\nüéâ HIGH QUALITY POLICY!\")\n",
    "                print(f\"‚úÖ Strong intervention magnitudes\")\n",
    "                print(f\"‚úÖ Correctly avoids target variables\")\n",
    "                print(f\"‚úÖ Ready for competitive evaluation\")\n",
    "            elif avg_magnitude > 0.005:\n",
    "                print(f\"\\n‚ö†Ô∏è MODERATE QUALITY POLICY\")\n",
    "                print(f\"Policy shows learning but may benefit from longer training\")\n",
    "            else:\n",
    "                print(f\"\\n‚ùå LOW QUALITY POLICY\")\n",
    "                print(f\"Policy outputs very small interventions - needs improvement\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Policy wrapper test failed: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    else:\n",
    "        print(f\"‚ùå Checkpoint directory not found: {checkpoint_path}\")\n",
    "\n",
    "# Training metrics analysis\n",
    "if 'trained_policy_metrics' in locals():\n",
    "    print(f\"\\nüìà Training Metrics Analysis:\")\n",
    "    \n",
    "    performance = trained_policy_metrics.get('performance', {})\n",
    "    if performance:\n",
    "        print(f\"  Total episodes: {performance.get('total_episodes', 0)}\")\n",
    "        print(f\"  Training time: {performance.get('training_time', 0):.1f}s\")\n",
    "        print(f\"  Final reward: {performance.get('final_reward', 0):.3f}\")\n",
    "        print(f\"  Mean reward: {performance.get('mean_reward', 0):.3f}\")\n",
    "        print(f\"  Reward improvement: {performance.get('reward_improvement', 0):.3f}\")\n",
    "        \n",
    "        # Training success indicators\n",
    "        final_reward = performance.get('final_reward', 0)\n",
    "        improvement = performance.get('reward_improvement', 0)\n",
    "        \n",
    "        success_indicators = {\n",
    "            'Meaningful rewards': final_reward > 0.4,\n",
    "            'Positive improvement': improvement > 0.02,  # Lowered threshold\n",
    "            'Stable training': performance.get('training_time', 0) > 0\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n‚úÖ Training Success Indicators:\")\n",
    "        for indicator, passed in success_indicators.items():\n",
    "            status = \"‚úÖ PASS\" if passed else \"‚ùå FAIL\"\n",
    "            print(f\"  {indicator}: {status}\")\n",
    "        \n",
    "        # Analysis of negative improvement\n",
    "        if improvement < 0:\n",
    "            print(f\"\\n‚ö†Ô∏è Analysis of Negative Reward Improvement:\")\n",
    "            print(f\"  The policy may have learned some patterns but:\")\n",
    "            print(f\"  ‚Ä¢ Could be overfitting to early patterns\")\n",
    "            print(f\"  ‚Ä¢ Learning rate might be too high causing instability\")\n",
    "            print(f\"  ‚Ä¢ Exploration decay might be too aggressive\")\n",
    "            print(f\"  üí° Consider: Lower LR (0.001) or longer training\")\n",
    "\n",
    "print(f\"\\nüí° Next Steps:\")\n",
    "if 'trained_policy_checkpoint' in locals():\n",
    "    print(\"‚úÖ Checkpoint API now working correctly\")\n",
    "    print(\"‚úÖ Can proceed to Cell 7 for full evaluation\")\n",
    "    print(\"‚úÖ Or try different training settings for better improvement\")\n",
    "else:\n",
    "    print(\"‚ùå Complete training in Cell 4 first\")\n",
    "\n",
    "logger.info(\"‚úÖ Checkpoint analysis complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# üîß CRITICAL PARAMETER UPDATE DEBUGGING - Phase 2\n",
    "# \"\"\"\n",
    "\n",
    "# print(\"üîß CRITICAL PARAMETER UPDATE DEBUGGING:\")\n",
    "# print(\"=\" * 70)\n",
    "# print(\"‚úÖ Added comprehensive parameter debugging\")\n",
    "# print(\"‚úÖ Enhanced GRPO update verification\") \n",
    "# print(\"‚úÖ Parameter storage verification\")\n",
    "# print(\"‚úÖ Full parameter lifecycle tracking\")\n",
    "\n",
    "# print(f\"\\nüöÄ Testing PARAMETER UPDATE DEBUGGING:\")\n",
    "\n",
    "# import time\n",
    "# from IPython.display import clear_output, display\n",
    "# import matplotlib.pyplot as plt\n",
    "# import logging\n",
    "\n",
    "# # Enable DEBUG logging to see ALL detailed diagnostics\n",
    "# logging.getLogger('causal_bayes_opt.training.enriched_trainer').setLevel(logging.DEBUG)\n",
    "# logging.getLogger('causal_bayes_opt.training.grpo_core').setLevel(logging.DEBUG)\n",
    "\n",
    "# # Create training configuration for debugging\n",
    "# config = create_training_config()\n",
    "# config.training.n_episodes = 10  # Short test for debugging\n",
    "# config.training.episode_length = 5  \n",
    "# config.training.learning_rate = 2e-3  # Higher learning rate\n",
    "\n",
    "# print(f\"  Episodes: {config.training.n_episodes}\")\n",
    "# print(f\"  Episode length: {config.training.episode_length}\")  \n",
    "# print(f\"  Learning rate: {config.training.learning_rate}\")\n",
    "# print(f\"  Expected: DEBUG logs should reveal parameter update issues\")\n",
    "\n",
    "# training_start_time = time.time()\n",
    "\n",
    "# try:\n",
    "#     # Initialize trainer with full debugging\n",
    "#     print(\"\\nüìä Initializing trainer with parameter debugging...\")\n",
    "#     trainer = EnrichedGRPOTrainer(config=config)\n",
    "#     print(\"‚úÖ Trainer initialization successful!\")\n",
    "    \n",
    "#     # Run training with full parameter debugging\n",
    "#     print(\"\\nüèÉ Running training with FULL PARAMETER DEBUGGING...\")\n",
    "#     print(\"Watch for:\")\n",
    "#     print(\"  ‚Ä¢ Parameter structure and navigation\")\n",
    "#     print(\"  ‚Ä¢ PRE-UPDATE and POST-UPDATE parameter values\")\n",
    "#     print(\"  ‚Ä¢ GRPO parameter update verification\")\n",
    "#     print(\"  ‚Ä¢ Parameter storage verification\")\n",
    "#     print(\"  ‚Ä¢ Optax apply_updates verification\")\n",
    "    \n",
    "#     final_metrics = trainer.train()\n",
    "    \n",
    "#     training_end_time = time.time()\n",
    "#     total_training_time = training_end_time - training_start_time\n",
    "    \n",
    "#     print(f\"\\n‚úÖ Debugging run completed!\")\n",
    "#     print(f\"‚è±Ô∏è Total training time: {total_training_time/60:.1f} minutes\")\n",
    "    \n",
    "#     # ANALYZE DEBUGGING RESULTS\n",
    "#     print(f\"\\nüß™ DEBUGGING ANALYSIS:\")\n",
    "    \n",
    "#     # Test the final policy to see if any learning occurred\n",
    "#     sample_scm = trainer.scm_manager.scm_rotation[0][1]\n",
    "#     variables = list(get_variables(sample_scm))\n",
    "#     target = get_target(sample_scm)\n",
    "    \n",
    "#     test_state = trainer._create_mock_state(sample_scm, 0, 0.0)\n",
    "#     enriched_input = trainer.state_converter.convert_state_to_enriched_input(test_state)\n",
    "#     target_idx = variables.index(target) if target in variables else 0\n",
    "    \n",
    "#     key = random.PRNGKey(42)\n",
    "#     policy_output = trainer.policy_fn.apply(\n",
    "#         trainer.policy_params, key, enriched_input, target_idx, False\n",
    "#     )\n",
    "    \n",
    "#     # Test pure inference\n",
    "#     inference_action = trainer._policy_output_to_action(policy_output, variables, target, None)\n",
    "#     inference_intervention, inference_reward = trainer._simulate_intervention(sample_scm, inference_action)\n",
    "    \n",
    "#     print(f\"Test SCM: {variables}, target: {target}\")\n",
    "#     print(f\"Pure inference action: {[f'{float(a):.6f}' for a in inference_action]}\")\n",
    "#     print(f\"Max action magnitude: {float(jnp.max(jnp.abs(inference_action))):.6f}\")\n",
    "#     print(f\"Interventions triggered: {len(inference_intervention.get('targets', set()))}\")\n",
    "#     print(f\"Reward: {inference_reward:.3f}\")\n",
    "    \n",
    "#     # FINAL ASSESSMENT\n",
    "#     performance = final_metrics.get('performance', {})\n",
    "#     final_reward = performance.get('final_reward', 0)\n",
    "#     mean_reward = performance.get('mean_reward', 0)\n",
    "    \n",
    "#     max_inference_magnitude = float(jnp.max(jnp.abs(inference_action)))\n",
    "#     triggers_interventions = len(inference_intervention.get('targets', set())) > 0\n",
    "    \n",
    "#     print(f\"\\nüéØ DEBUGGING CONCLUSIONS:\")\n",
    "#     print(f\"1. Max inference action: {max_inference_magnitude:.6f} (target: >0.005)\")\n",
    "#     print(f\"2. Triggers interventions: {triggers_interventions}\")  \n",
    "#     print(f\"3. Final reward: {final_reward:.3f}\")\n",
    "#     print(f\"4. Mean reward: {mean_reward:.3f}\")\n",
    "    \n",
    "#     if max_inference_magnitude > 0.005 and triggers_interventions:\n",
    "#         print(f\"\\nüéâ PARAMETER UPDATES WORKING!\")\n",
    "#         print(f\"‚úÖ Policy learned meaningful actions\")\n",
    "#         print(f\"‚úÖ Parameter update mechanism fixed\")\n",
    "#     elif max_inference_magnitude > 0.001:\n",
    "#         print(f\"\\n‚ö†Ô∏è PARTIAL PARAMETER UPDATES\")\n",
    "#         print(f\"Some parameter updates detected but may need tuning\")\n",
    "#     else:\n",
    "#         print(f\"\\n‚ùå PARAMETER UPDATE ISSUES PERSIST\")\n",
    "#         print(f\"Check DEBUG logs for:\")\n",
    "#         print(f\"  ‚Ä¢ Parameter structure navigation issues\")\n",
    "#         print(f\"  ‚Ä¢ GRPO optax.apply_updates failures\")  \n",
    "#         print(f\"  ‚Ä¢ Parameter storage verification failures\")\n",
    "#         print(f\"  ‚Ä¢ Gradient computation or application issues\")\n",
    "    \n",
    "#     print(f\"\\nüìã NEXT STEPS based on DEBUG logs:\")\n",
    "#     print(f\"1. Check if parameter structure navigation is working\")\n",
    "#     print(f\"2. Verify GRPO optax.apply_updates is changing parameters\")\n",
    "#     print(f\"3. Confirm parameter storage verification passes\")\n",
    "#     print(f\"4. Identify where parameter update chain breaks\")\n",
    "        \n",
    "# except Exception as e:\n",
    "#     logger.error(f\"Debugging run failed: {e}\")\n",
    "#     print(f\"‚ùå Debugging run failed: {e}\")\n",
    "#     import traceback\n",
    "#     traceback.print_exc()\n",
    "#     raise\n",
    "\n",
    "# logger.info(\"‚úÖ Parameter update debugging complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Launch full 4-method comparison evaluation\n",
    "\"\"\"\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Verification before launching full evaluation\n",
    "print(\"üîç Pre-evaluation verification:\")\n",
    "\n",
    "# Check checkpoint exists\n",
    "if not checkpoint_path.exists():\n",
    "    print(f\"‚ùå Checkpoint missing: {checkpoint_path}\")\n",
    "    raise FileNotFoundError(f\"Required checkpoint not found: {checkpoint_path}\")\n",
    "print(f\"‚úÖ Checkpoint verified: {checkpoint_path}\")\n",
    "\n",
    "# Check evaluation config\n",
    "if not eval_config_path.exists():\n",
    "    print(f\"‚ùå Evaluation config missing: {eval_config_path}\")\n",
    "    raise FileNotFoundError(f\"Required config not found: {eval_config_path}\")\n",
    "print(f\"‚úÖ Evaluation config verified: {eval_config_path}\")\n",
    "\n",
    "# Estimate evaluation time\n",
    "n_methods = len(eval_config['experiment']['methods'])\n",
    "runs_per_method = eval_config['experiment']['runs_per_method']\n",
    "intervention_budget = eval_config['experiment']['intervention_budget']\n",
    "estimated_time_minutes = (n_methods * runs_per_method * intervention_budget * 0.5) / 60  # 0.5 sec per intervention\n",
    "\n",
    "print(f\"\\nüìä Evaluation Overview:\")\n",
    "print(f\"  Methods: {n_methods}\")\n",
    "print(f\"  Runs per method: {runs_per_method}\")\n",
    "print(f\"  Intervention budget: {intervention_budget}\")\n",
    "print(f\"  Estimated time: {estimated_time_minutes:.1f} minutes\")\n",
    "\n",
    "# Launch evaluation\n",
    "print(\"\\nüöÄ Launching full 4-method comparison...\")\n",
    "\n",
    "# Prepare command\n",
    "comparison_script = project_root / \"scripts\" / \"core\" / \"acbo_comparison\" / \"run_comparison.py\"\n",
    "cmd = [\n",
    "    \"poetry\", \"run\", \"python\", str(comparison_script),\n",
    "    \"--config-path\", str(eval_config_path.parent),\n",
    "    \"--config-name\", eval_config_path.stem,\n",
    "    \"experiment.runs_per_method=5\",  # Ensure sufficient statistical power\n",
    "    \"logging.level=INFO\"\n",
    "]\n",
    "\n",
    "print(f\"Command: {' '.join(cmd)}\")\n",
    "\n",
    "# Option to run in background or foreground\n",
    "run_in_background = False  # Set to True for background execution\n",
    "\n",
    "if run_in_background:\n",
    "    print(\"Running evaluation in background...\")\n",
    "    process = subprocess.Popen(\n",
    "        cmd,\n",
    "        cwd=project_root,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Evaluation started with PID: {process.pid}\")\n",
    "    print(\"Monitor progress in terminal or check outputs directory\")\n",
    "    \n",
    "    # Store process info\n",
    "    evaluation_process = process\n",
    "    \n",
    "else:\n",
    "    print(\"Running evaluation in foreground (this may take several minutes)...\")\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            cmd,\n",
    "            cwd=project_root,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=30*60  # 30 minute timeout\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"‚úÖ Evaluation completed successfully!\")\n",
    "            print(\"\\nüìù Output:\")\n",
    "            print(result.stdout[-1000:])  # Last 1000 chars\n",
    "        else:\n",
    "            print(f\"‚ùå Evaluation failed with return code: {result.returncode}\")\n",
    "            print(f\"Error: {result.stderr}\")\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"‚è∞ Evaluation timed out (30 minutes)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Evaluation error: {e}\")\n",
    "\n",
    "# Check for output files\n",
    "outputs_dir = project_root / \"outputs\" / \"4method_comparison\"\n",
    "if outputs_dir.exists():\n",
    "    recent_outputs = sorted(outputs_dir.glob(\"*/\"))[-3:]  # Last 3 runs\n",
    "    print(f\"\\nüìÅ Recent evaluation outputs:\")\n",
    "    for output_dir in recent_outputs:\n",
    "        print(f\"  {output_dir.name}\")\n",
    "        \n",
    "logger.info(\"‚úÖ Full evaluation launcher complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Phase 3: Diagnostic Summary & Recommendations\n",
    "Consolidate all testing results and provide actionable recommendations\n",
    "\"\"\"\n",
    "\n",
    "print(\"üìã Diagnostic Summary & Recommendations\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Safe variable access with defaults\n",
    "baseline_improvement = -0.018\n",
    "baseline_final_reward = 0.502\n",
    "baseline_mean_reward = 0.512\n",
    "baseline_magnitude = 1.6948\n",
    "baseline_lr = 0.05\n",
    "baseline_episodes = 160\n",
    "\n",
    "# Compile all test results\n",
    "diagnostic_results = {\n",
    "    'baseline': {\n",
    "        'improvement': baseline_improvement,\n",
    "        'final_reward': baseline_final_reward,\n",
    "        'mean_reward': baseline_mean_reward,\n",
    "        'policy_magnitude': baseline_magnitude,\n",
    "        'lr': baseline_lr,\n",
    "        'episodes': baseline_episodes,\n",
    "        'config_name': 'Original (High LR, Short Duration)'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Add Phase 1 results if available\n",
    "if 'test_improvement' in locals():\n",
    "    diagnostic_results['phase1'] = {\n",
    "        'improvement': test_improvement,\n",
    "        'final_reward': test_final_reward,\n",
    "        'mean_reward': test_mean_reward,\n",
    "        'policy_magnitude': test_magnitude,\n",
    "        'lr': test_lr,\n",
    "        'episodes': 160,\n",
    "        'config_name': f'Phase 1 (LR={test_lr}, Short Duration)'\n",
    "    }\n",
    "\n",
    "# Add Phase 2 results if available\n",
    "if 'duration_improvement' in locals():\n",
    "    diagnostic_results['phase2'] = {\n",
    "        'improvement': duration_improvement,\n",
    "        'final_reward': duration_final_reward,\n",
    "        'mean_reward': duration_mean_reward,\n",
    "        'policy_magnitude': duration_magnitude,\n",
    "        'lr': optimal_lr if 'optimal_lr' in locals() else 0.001,\n",
    "        'episodes': total_extended_episodes if 'total_extended_episodes' in locals() else 480,\n",
    "        'config_name': f'Phase 2 (LR={optimal_lr if \"optimal_lr\" in locals() else 0.001}, Extended Duration)'\n",
    "    }\n",
    "\n",
    "print(\"üîç Comprehensive Results Analysis:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create comprehensive comparison table\n",
    "config_names = []\n",
    "improvements = []\n",
    "final_rewards = []\n",
    "magnitudes = []\n",
    "learning_rates = []\n",
    "episode_counts = []\n",
    "\n",
    "for phase, results in diagnostic_results.items():\n",
    "    config_names.append(results['config_name'])\n",
    "    improvements.append(results['improvement'])\n",
    "    final_rewards.append(results['final_reward'])\n",
    "    magnitudes.append(results['policy_magnitude'])\n",
    "    learning_rates.append(results['lr'])\n",
    "    episode_counts.append(results['episodes'])\n",
    "\n",
    "# Print detailed comparison\n",
    "print(f\"Configuration                               Reward Improv.  Final Reward  Policy Mag.  LR      Episodes\")\n",
    "print(f\"{'='*95}\")\n",
    "for i, name in enumerate(config_names):\n",
    "    print(f\"{name:<42} {improvements[i]:>7.3f}       {final_rewards[i]:>7.3f}     {magnitudes[i]:>7.4f}   {learning_rates[i]:>6.3f}  {episode_counts[i]:>4d}\")\n",
    "\n",
    "# Determine best configuration\n",
    "if len(improvements) > 0:\n",
    "    best_improvement_idx = int(onp.argmax(improvements))\n",
    "    best_reward_idx = int(onp.argmax(final_rewards))\n",
    "    best_magnitude_idx = int(onp.argmax(magnitudes))\n",
    "    \n",
    "    print(f\"\\nüèÜ Best Performers:\")\n",
    "    print(f\"  Best Improvement: {config_names[best_improvement_idx]} ({improvements[best_improvement_idx]:.3f})\")\n",
    "    print(f\"  Best Final Reward: {config_names[best_reward_idx]} ({final_rewards[best_reward_idx]:.3f})\")\n",
    "    print(f\"  Best Policy Strength: {config_names[best_magnitude_idx]} ({magnitudes[best_magnitude_idx]:.4f})\")\n",
    "\n",
    "# Statistical analysis\n",
    "improvement_range = max(improvements) - min(improvements) if improvements else 0\n",
    "reward_range = max(final_rewards) - min(final_rewards) if final_rewards else 0\n",
    "\n",
    "print(f\"\\nüìä Variability Analysis:\")\n",
    "print(f\"  Improvement range: {improvement_range:.3f}\")\n",
    "print(f\"  Final reward range: {reward_range:.3f}\")\n",
    "print(f\"  Learning rate sensitivity: {'HIGH' if improvement_range > 0.03 else 'MODERATE' if improvement_range > 0.01 else 'LOW'}\")\n",
    "print(f\"  Duration sensitivity: {'HIGH' if len(diagnostic_results) > 2 and abs(improvements[-1] - improvements[-2]) > 0.02 else 'MODERATE' if len(diagnostic_results) > 2 else 'UNKNOWN'}\")\n",
    "\n",
    "# Create comprehensive visualization\n",
    "if len(diagnostic_results) >= 2:\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Reward improvement comparison\n",
    "    bars1 = ax1.bar(range(len(config_names)), improvements, \n",
    "                    color=['red' if x < 0 else 'green' for x in improvements], alpha=0.7)\n",
    "    ax1.set_xlabel('Configuration')\n",
    "    ax1.set_ylabel('Reward Improvement')\n",
    "    ax1.set_title('Reward Improvement Across Configurations')\n",
    "    ax1.set_xticks(range(len(config_names)))\n",
    "    ax1.set_xticklabels([name.split('(')[0] for name in config_names], rotation=45)\n",
    "    ax1.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, bar in enumerate(bars1):\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "               f'{height:.3f}', ha='center', va='bottom' if height >= 0 else 'top')\n",
    "    \n",
    "    # 2. Policy strength comparison\n",
    "    bars2 = ax2.bar(range(len(config_names)), magnitudes, alpha=0.7, color='blue')\n",
    "    ax2.set_xlabel('Configuration')\n",
    "    ax2.set_ylabel('Max Action Magnitude')\n",
    "    ax2.set_title('Policy Strength Across Configurations')\n",
    "    ax2.set_xticks(range(len(config_names)))\n",
    "    ax2.set_xticklabels([name.split('(')[0] for name in config_names], rotation=45)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, bar in enumerate(bars2):\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "               f'{height:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # 3. Learning rate vs improvement\n",
    "    ax3.scatter(learning_rates, improvements, s=100, alpha=0.7, c=episode_counts, cmap='viridis')\n",
    "    ax3.set_xlabel('Learning Rate')\n",
    "    ax3.set_ylabel('Reward Improvement')\n",
    "    ax3.set_title('Learning Rate vs Reward Improvement')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # Add colorbar for episodes\n",
    "    cbar = plt.colorbar(ax3.collections[0], ax=ax3)\n",
    "    cbar.set_label('Episodes')\n",
    "    \n",
    "    # 4. Efficiency analysis (improvement per episode)\n",
    "    efficiency = [imp/eps if eps > 0 else 0 for imp, eps in zip(improvements, episode_counts)]\n",
    "    bars4 = ax4.bar(range(len(config_names)), efficiency, alpha=0.7, color='orange')\n",
    "    ax4.set_xlabel('Configuration')\n",
    "    ax4.set_ylabel('Improvement per Episode')\n",
    "    ax4.set_title('Training Efficiency Comparison')\n",
    "    ax4.set_xticks(range(len(config_names)))\n",
    "    ax4.set_xticklabels([name.split('(')[0] for name in config_names], rotation=45)\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, bar in enumerate(bars4):\n",
    "        height = bar.get_height()\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
    "               f'{height:.1e}', ha='center', va='bottom' if height >= 0 else 'top')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Decision matrix analysis\n",
    "print(f\"\\nüéØ Decision Matrix Analysis:\")\n",
    "\n",
    "# Weight different factors for overall score\n",
    "factors = {\n",
    "    'reward_improvement': 0.4,  # Most important\n",
    "    'policy_strength': 0.3,     # Important for actual performance\n",
    "    'training_efficiency': 0.2, # Time matters\n",
    "    'stability': 0.1            # Consistency across runs\n",
    "}\n",
    "\n",
    "print(f\"Factor weights: {factors}\")\n",
    "\n",
    "# Calculate scores for each configuration\n",
    "config_scores = {}\n",
    "if len(config_names) > 1:\n",
    "    for i, name in enumerate(config_names):\n",
    "        # Calculate efficiency\n",
    "        efficiency_val = improvements[i] / episode_counts[i] if episode_counts[i] > 0 else 0\n",
    "        \n",
    "        # Normalize metrics to 0-1 scale\n",
    "        norm_improvement = (improvements[i] - min(improvements)) / max(improvement_range, 0.001)\n",
    "        norm_magnitude = (magnitudes[i] - min(magnitudes)) / max(max(magnitudes) - min(magnitudes), 0.001)\n",
    "        norm_efficiency = (efficiency_val - min(efficiency)) / max(max(efficiency) - min(efficiency), 0.001) if len(efficiency) > 1 else 0.5\n",
    "        norm_stability = 1.0 if improvements[i] >= 0 else 0.5  # Positive improvement = stable\n",
    "        \n",
    "        # Calculate weighted score\n",
    "        score = (factors['reward_improvement'] * norm_improvement + \n",
    "                 factors['policy_strength'] * norm_magnitude +\n",
    "                 factors['training_efficiency'] * norm_efficiency +\n",
    "                 factors['stability'] * norm_stability)\n",
    "        \n",
    "        config_scores[name] = {\n",
    "            'score': score,\n",
    "            'improvement': improvements[i],\n",
    "            'magnitude': magnitudes[i],\n",
    "            'efficiency': efficiency_val,\n",
    "            'lr': learning_rates[i],\n",
    "            'episodes': episode_counts[i]\n",
    "        }\n",
    "else:\n",
    "    # Only baseline available\n",
    "    config_scores[config_names[0]] = {\n",
    "        'score': 0.5,\n",
    "        'improvement': improvements[0],\n",
    "        'magnitude': magnitudes[0],\n",
    "        'efficiency': improvements[0] / episode_counts[0] if episode_counts[0] > 0 else 0,\n",
    "        'lr': learning_rates[0],\n",
    "        'episodes': episode_counts[0]\n",
    "    }\n",
    "\n",
    "# Rank configurations\n",
    "ranked_configs = sorted(config_scores.items(), key=lambda x: x[1]['score'], reverse=True)\n",
    "\n",
    "print(f\"\\nüèÖ Configuration Rankings:\")\n",
    "for rank, (config_name, scores) in enumerate(ranked_configs, 1):\n",
    "    print(f\"{rank}. {config_name}\")\n",
    "    print(f\"   Overall Score: {scores['score']:.3f}\")\n",
    "    print(f\"   Key Metrics: Improvement={scores['improvement']:.3f}, Magnitude={scores['magnitude']:.3f}\")\n",
    "    print(f\"   Settings: LR={scores['lr']:.3f}, Episodes={scores['episodes']}\")\n",
    "    print()\n",
    "\n",
    "# Generate recommendations\n",
    "if ranked_configs:\n",
    "    best_config_name, best_config_scores = ranked_configs[0]\n",
    "    print(f\"üéâ RECOMMENDED CONFIGURATION:\")\n",
    "    print(f\"Configuration: {best_config_name}\")\n",
    "    print(f\"Learning Rate: {best_config_scores['lr']:.3f}\")\n",
    "    print(f\"Training Episodes: {best_config_scores['episodes']}\")\n",
    "    print(f\"Expected Improvement: {best_config_scores['improvement']:.3f}\")\n",
    "    print(f\"Expected Policy Strength: {best_config_scores['magnitude']:.3f}\")\n",
    "\n",
    "# Specific recommendations based on findings\n",
    "print(f\"\\nüí° Specific Recommendations:\")\n",
    "\n",
    "# Learning rate recommendations\n",
    "if len(diagnostic_results) >= 2 and len(improvements) >= 2:\n",
    "    lr_effect = improvements[1] - improvements[0]\n",
    "    if lr_effect > 0.01:\n",
    "        print(f\"‚úÖ Learning Rate: Use LR={best_config_scores['lr']:.3f} (confirmed improvement)\")\n",
    "    elif lr_effect > 0:\n",
    "        print(f\"‚ö†Ô∏è Learning Rate: Consider LR={best_config_scores['lr']:.3f} (modest improvement)\")\n",
    "    else:\n",
    "        print(f\"‚ùå Learning Rate: Current LR settings need further tuning\")\n",
    "\n",
    "# Duration recommendations\n",
    "if len(diagnostic_results) >= 3 and len(improvements) >= 3:\n",
    "    duration_effect = improvements[2] - improvements[1]\n",
    "    if duration_effect > 0.02:\n",
    "        print(f\"‚úÖ Training Duration: Use extended training ({best_config_scores['episodes']} episodes)\")\n",
    "    elif duration_effect > 0:\n",
    "        print(f\"‚ö†Ô∏è Training Duration: Extended training helps modestly\")\n",
    "    else:\n",
    "        print(f\"‚ùå Training Duration: Diminishing returns, current duration sufficient\")\n",
    "\n",
    "# Overall strategy\n",
    "best_improvement = max(improvements) if improvements else 0\n",
    "if best_improvement > 0.02:\n",
    "    print(f\"üéØ Strategy: OPTIMIZATION SUCCESSFUL - Use best configuration for production\")\n",
    "elif best_improvement > 0:\n",
    "    print(f\"üéØ Strategy: PARTIAL SUCCESS - Consider further hyperparameter tuning\")\n",
    "else:\n",
    "    print(f\"üéØ Strategy: NEEDS WORK - Focus on architecture or data quality improvements\")\n",
    "\n",
    "# Next steps\n",
    "print(f\"\\nüöÄ Next Steps:\")\n",
    "if best_improvement > 0.01:\n",
    "    print(f\"1. Use recommended configuration for full evaluation\")\n",
    "    print(f\"2. Run 4-method comparison with optimized settings\")\n",
    "    print(f\"3. Consider ensemble methods or architecture improvements\")\n",
    "else:\n",
    "    print(f\"1. Further hyperparameter exploration (architecture, reward weights)\")\n",
    "    print(f\"2. Investigate training data quality and diversity\")\n",
    "    print(f\"3. Consider different training approaches (curriculum learning, etc.)\")\n",
    "\n",
    "print(f\"\\nüìÅ Checkpoints Available:\")\n",
    "if 'trained_policy_checkpoint' in locals():\n",
    "    print(f\"  Original: {trained_policy_checkpoint}\")\n",
    "if 'lr_test_checkpoint' in locals():\n",
    "    print(f\"  Phase 1: {lr_test_checkpoint}\")\n",
    "if 'duration_checkpoint' in locals():\n",
    "    print(f\"  Phase 2: {duration_checkpoint}\")\n",
    "\n",
    "# Update todo list\n",
    "print(f\"\\n‚úÖ Diagnostic Analysis Complete!\")\n",
    "print(f\"Ready to proceed with optimized training configuration or full evaluation.\")\n",
    "\n",
    "logger.info(\"‚úÖ Phase 3: Diagnostic summary complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Reward Volatility Sanity Check\n",
    "\n",
    "**Purpose**: Test reward function sensitivity by applying extreme interventions to all variables and observing reward variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Phase 2: Training Duration Test\n",
    "Test if longer training duration improves learning with optimal LR\n",
    "\"\"\"\n",
    "\n",
    "print(\"üî¨ Phase 2: Training Duration Test\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check if Phase 1 was successful and we have optimal LR\n",
    "if 'optimal_lr' not in locals():\n",
    "    print(\"‚ö†Ô∏è Phase 1 not completed. Using default learning rate.\")\n",
    "    optimal_lr = 0.001  # Default fallback\n",
    "    lr_test_success = False\n",
    "\n",
    "# Initialize original_episodes if not available\n",
    "if 'original_episodes' not in locals():\n",
    "    original_episodes = training_params.get('episodes_per_scm', 5) if 'training_params' in locals() else 5\n",
    "\n",
    "print(f\"Using optimal LR from Phase 1: {optimal_lr}\")\n",
    "\n",
    "# Test configuration: Longer training duration\n",
    "extended_episodes_per_scm = original_episodes * 3  # 3x longer training\n",
    "total_extended_episodes = len(training_scms) * extended_episodes_per_scm\n",
    "\n",
    "print(f\"\\nüìä Duration Test Configuration:\")\n",
    "print(f\"  Learning rate: {optimal_lr} (from Phase 1)\")\n",
    "print(f\"  Episodes per SCM: {original_episodes} ‚Üí {extended_episodes_per_scm} (3x)\")\n",
    "print(f\"  Total episodes: {len(training_scms) * original_episodes} ‚Üí {total_extended_episodes}\")\n",
    "print(f\"  Expected duration: ~15 minutes\")\n",
    "print(f\"  Expected: Continued learning improvement with more episodes\")\n",
    "\n",
    "# Ensure training_params exists with defaults\n",
    "if 'training_params' not in locals():\n",
    "    training_params = {\n",
    "        'target_weight': 0.5,\n",
    "        'structure_weight': 0.3,\n",
    "        'exploration_weight': 0.2,\n",
    "        'hidden_dims': [128, 128]\n",
    "    }\n",
    "\n",
    "# Create extended training configuration\n",
    "def create_duration_test_config():\n",
    "    config_dict = {\n",
    "        'seed': eval_config['seed'] + 2,  # Different seed\n",
    "        'training': {\n",
    "            'n_episodes': total_extended_episodes,\n",
    "            'episode_length': 10,\n",
    "            'learning_rate': optimal_lr,\n",
    "            'gamma': 0.99,\n",
    "            'max_intervention_value': 2.0,\n",
    "            'reward_weights': {\n",
    "                'optimization': training_params.get('target_weight', 0.5),\n",
    "                'discovery': training_params.get('structure_weight', 0.3),\n",
    "                'efficiency': training_params.get('exploration_weight', 0.2)\n",
    "            },\n",
    "            'architecture': {\n",
    "                'hidden_dim': training_params.get('hidden_dims', [128, 128])[0],\n",
    "                'num_layers': 2,\n",
    "                'num_heads': 4,\n",
    "                'key_size': 32,\n",
    "                'widening_factor': 4,\n",
    "                'dropout': 0.1,\n",
    "                'policy_intermediate_dim': None\n",
    "            },\n",
    "            'state_config': {\n",
    "                'max_history_size': 100,\n",
    "                'num_channels': 10,\n",
    "                'standardize_values': True,\n",
    "                'include_temporal_features': True\n",
    "            }\n",
    "        },\n",
    "        'experiment': {\n",
    "            'scm_generation': {\n",
    "                'use_variable_factory': True,\n",
    "                'variable_range': [3, 6],\n",
    "                'structure_types': ['fork', 'chain', 'collider', 'mixed'],\n",
    "                'rotation_frequency': 5\n",
    "            }\n",
    "        },\n",
    "        'logging': {\n",
    "            'checkpoint_dir': str(checkpoint_dir / \"duration_test\"),\n",
    "            'wandb': {'enabled': False},\n",
    "            'level': 'INFO'\n",
    "        }\n",
    "    }\n",
    "    return OmegaConf.create(config_dict)\n",
    "\n",
    "# Run duration test\n",
    "duration_config = create_duration_test_config()\n",
    "duration_start_time = time.time()\n",
    "\n",
    "try:\n",
    "    print(f\"\\nüöÄ Starting duration test...\")\n",
    "    \n",
    "    # Initialize trainer with extended configuration\n",
    "    duration_trainer = EnrichedGRPOTrainer(config=duration_config)\n",
    "    print(\"‚úÖ Duration test trainer initialized successfully\")\n",
    "    \n",
    "    # Custom training loop with progress tracking\n",
    "    print(f\"\\nüèÉ Running extended training with progress tracking...\")\n",
    "    \n",
    "    # Store intermediate metrics for learning curve analysis\n",
    "    learning_curve_data = {\n",
    "        'episodes': [],\n",
    "        'rewards': [],\n",
    "        'improvements': [],\n",
    "        'action_magnitudes': [],\n",
    "        'timestamps': []\n",
    "    }\n",
    "    \n",
    "    # Override trainer to collect learning curve data\n",
    "    original_run_episode = duration_trainer._run_episode\n",
    "    \n",
    "    def tracked_run_episode(episode_idx, episode_key):\n",
    "        metrics = original_run_episode(episode_idx, episode_key)\n",
    "        \n",
    "        # Test policy at this checkpoint\n",
    "        sample_scm = duration_trainer.scm_manager.scm_rotation[0][1]\n",
    "        variables = list(get_variables(sample_scm))\n",
    "        target = get_target(sample_scm)\n",
    "        \n",
    "        test_state = duration_trainer._create_mock_state(sample_scm, 0, 0.0)\n",
    "        enriched_input = duration_trainer.state_converter.convert_state_to_enriched_input(test_state)\n",
    "        target_idx = variables.index(target) if target in variables else 0\n",
    "        \n",
    "        key = random.PRNGKey(42 + episode_idx)\n",
    "        policy_output = duration_trainer.policy_fn.apply(\n",
    "            duration_trainer.policy_params, key, enriched_input, target_idx, False\n",
    "        )\n",
    "        \n",
    "        test_action = duration_trainer._policy_output_to_action(policy_output, variables, target)\n",
    "        test_magnitude = float(jnp.max(jnp.abs(test_action)))\n",
    "        \n",
    "        # Store learning curve data\n",
    "        if episode_idx % 10 == 0:  # Sample every 10 episodes\n",
    "            learning_curve_data['episodes'].append(episode_idx)\n",
    "            learning_curve_data['rewards'].append(metrics.mean_reward)\n",
    "            learning_curve_data['improvements'].append(metrics.optimization_improvement)\n",
    "            learning_curve_data['action_magnitudes'].append(test_magnitude)\n",
    "            learning_curve_data['timestamps'].append(time.time() - duration_start_time)\n",
    "            \n",
    "            # Progress report\n",
    "            if episode_idx % 50 == 0:\n",
    "                print(f\"  Episode {episode_idx}: reward={metrics.mean_reward:.3f}, magnitude={test_magnitude:.4f}\")\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    # Patch the method\n",
    "    duration_trainer._run_episode = tracked_run_episode\n",
    "    \n",
    "    # Run training\n",
    "    duration_metrics = duration_trainer.train()\n",
    "    \n",
    "    duration_end_time = time.time()\n",
    "    duration_time = duration_end_time - duration_start_time\n",
    "    \n",
    "    print(f\"\\n‚úÖ Duration test completed in {duration_time/60:.1f} minutes\")\n",
    "    \n",
    "    # Compare results\n",
    "    duration_performance = duration_metrics.get('performance', {})\n",
    "    duration_improvement = duration_performance.get('reward_improvement', 0)\n",
    "    duration_final_reward = duration_performance.get('final_reward', 0)\n",
    "    duration_mean_reward = duration_performance.get('mean_reward', 0)\n",
    "    \n",
    "    # Get baseline results for comparison\n",
    "    baseline_improvement = -0.018  # Original result\n",
    "    baseline_final_reward = 0.502\n",
    "    baseline_mean_reward = 0.512\n",
    "    \n",
    "    # Get Phase 1 results if available\n",
    "    if 'test_improvement' in locals():\n",
    "        phase1_improvement = test_improvement\n",
    "        phase1_final_reward = test_final_reward\n",
    "        phase1_mean_reward = test_mean_reward\n",
    "    else:\n",
    "        phase1_improvement = baseline_improvement\n",
    "        phase1_final_reward = baseline_final_reward\n",
    "        phase1_mean_reward = baseline_mean_reward\n",
    "    \n",
    "    print(f\"\\nüìä Duration Test Results Comparison:\")\n",
    "    print(f\"Metric                   Baseline (160 ep)    Phase1 (160 ep)     Extended (480 ep)    Improvement\")\n",
    "    print(f\"{'='*90}\")\n",
    "    print(f\"Reward Improvement:      {baseline_improvement:>7.3f}           {phase1_improvement:>7.3f}            {duration_improvement:>7.3f}         {duration_improvement-baseline_improvement:+.3f}\")\n",
    "    print(f\"Final Reward:           {baseline_final_reward:>7.3f}           {phase1_final_reward:>7.3f}            {duration_final_reward:>7.3f}         {duration_final_reward-baseline_final_reward:+.3f}\")\n",
    "    print(f\"Mean Reward:            {baseline_mean_reward:>7.3f}           {phase1_mean_reward:>7.3f}            {duration_mean_reward:>7.3f}         {duration_mean_reward-baseline_mean_reward:+.3f}\")\n",
    "    \n",
    "    # Test final policy quality\n",
    "    sample_scm = duration_trainer.scm_manager.scm_rotation[0][1]\n",
    "    variables = list(get_variables(sample_scm))\n",
    "    target = get_target(sample_scm)\n",
    "    \n",
    "    test_state = duration_trainer._create_mock_state(sample_scm, 0, 0.0)\n",
    "    enriched_input = duration_trainer.state_converter.convert_state_to_enriched_input(test_state)\n",
    "    target_idx = variables.index(target) if target in variables else 0\n",
    "    \n",
    "    key = random.PRNGKey(42)\n",
    "    policy_output = duration_trainer.policy_fn.apply(\n",
    "        duration_trainer.policy_params, key, enriched_input, target_idx, False\n",
    "    )\n",
    "    \n",
    "    duration_action = duration_trainer._policy_output_to_action(policy_output, variables, target)\n",
    "    duration_intervention, duration_test_reward = duration_trainer._simulate_intervention(sample_scm, duration_action)\n",
    "    \n",
    "    duration_magnitude = float(jnp.max(jnp.abs(duration_action)))\n",
    "    duration_triggers = len(duration_intervention.get('targets', set()))\n",
    "    \n",
    "    print(f\"\\nExtended Training Policy Quality:\")\n",
    "    print(f\"  Max action magnitude: {duration_magnitude:.6f}\")\n",
    "    print(f\"  Interventions triggered: {duration_triggers}\")\n",
    "    print(f\"  Test reward: {duration_test_reward:.3f}\")\n",
    "    \n",
    "    # Analysis\n",
    "    print(f\"\\nüîç Duration Test Analysis:\")\n",
    "    \n",
    "    significant_improvement = duration_improvement > baseline_improvement + 0.02\n",
    "    quality_improved = duration_magnitude > 1.0  # Compared to original 1.6948\n",
    "    stable_learning = len(learning_curve_data['rewards']) > 10\n",
    "    \n",
    "    if significant_improvement and quality_improved:\n",
    "        print(f\"‚úÖ EXTENDED TRAINING HIGHLY SUCCESSFUL!\")\n",
    "        print(f\"‚úÖ Reward improvement: {baseline_improvement:.3f} ‚Üí {duration_improvement:.3f}\")\n",
    "        print(f\"‚úÖ Policy quality maintained/improved\")\n",
    "        print(f\"üí° Recommendation: Use longer training for best results\")\n",
    "        \n",
    "        duration_test_success = True\n",
    "        best_config = \"extended\"\n",
    "        \n",
    "    elif significant_improvement:\n",
    "        print(f\"‚úÖ EXTENDED TRAINING PARTIALLY SUCCESSFUL\")\n",
    "        print(f\"Reward improved but policy quality may have degraded slightly\")\n",
    "        print(f\"üí° Consider balancing training duration with other factors\")\n",
    "        \n",
    "        duration_test_success = True\n",
    "        best_config = \"extended\"\n",
    "        \n",
    "    elif duration_improvement > baseline_improvement:\n",
    "        print(f\"‚ö†Ô∏è MODEST IMPROVEMENT\")\n",
    "        print(f\"Extended training helped but gains are small\")\n",
    "        print(f\"üí° Diminishing returns - current duration may be sufficient\")\n",
    "        \n",
    "        duration_test_success = False\n",
    "        best_config = \"phase1\" if 'lr_test_success' in locals() and lr_test_success else \"baseline\"\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚ùå EXTENDED TRAINING INEFFECTIVE\")\n",
    "        print(f\"Longer training didn't improve results\")\n",
    "        print(f\"üí° Focus on architecture or data quality improvements\")\n",
    "        \n",
    "        duration_test_success = False\n",
    "        best_config = \"baseline\"\n",
    "    \n",
    "    # Learning curve visualization\n",
    "    if learning_curve_data['episodes']:\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        episodes = learning_curve_data['episodes']\n",
    "        \n",
    "        # Reward progression\n",
    "        ax1.plot(episodes, learning_curve_data['rewards'], 'b-', linewidth=2, marker='o', markersize=4)\n",
    "        ax1.set_xlabel('Episode')\n",
    "        ax1.set_ylabel('Mean Reward')\n",
    "        ax1.set_title('Reward Progression During Extended Training')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.axhline(y=baseline_mean_reward, color='r', linestyle='--', alpha=0.7, label='Baseline')\n",
    "        ax1.legend()\n",
    "        \n",
    "        # Improvement progression\n",
    "        ax2.plot(episodes, learning_curve_data['improvements'], 'g-', linewidth=2, marker='s', markersize=4)\n",
    "        ax2.set_xlabel('Episode')\n",
    "        ax2.set_ylabel('Reward Improvement')\n",
    "        ax2.set_title('Reward Improvement Trend')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.axhline(y=0, color='k', linestyle='-', alpha=0.5)\n",
    "        ax2.axhline(y=baseline_improvement, color='r', linestyle='--', alpha=0.7, label='Baseline')\n",
    "        ax2.legend()\n",
    "        \n",
    "        # Action magnitude progression\n",
    "        ax3.plot(episodes, learning_curve_data['action_magnitudes'], 'm-', linewidth=2, marker='^', markersize=4)\n",
    "        ax3.set_xlabel('Episode')\n",
    "        ax3.set_ylabel('Max Action Magnitude')\n",
    "        ax3.set_title('Policy Action Strength Over Time')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        ax3.axhline(y=1.6948, color='r', linestyle='--', alpha=0.7, label='Original Quality')\n",
    "        ax3.legend()\n",
    "        \n",
    "        # Training efficiency (reward per minute)\n",
    "        if learning_curve_data['timestamps']:\n",
    "            timestamps_min = [t/60 for t in learning_curve_data['timestamps']]\n",
    "            reward_per_min = [r/t for r, t in zip(learning_curve_data['rewards'], timestamps_min) if t > 0]\n",
    "            ax4.plot(timestamps_min[:len(reward_per_min)], reward_per_min, 'orange', linewidth=2, marker='d', markersize=4)\n",
    "            ax4.set_xlabel('Training Time (minutes)')\n",
    "            ax4.set_ylabel('Reward per Minute')\n",
    "            ax4.set_title('Training Efficiency Over Time')\n",
    "            ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Learning curve analysis\n",
    "        if len(learning_curve_data['rewards']) >= 3:\n",
    "            early_reward = onp.mean(learning_curve_data['rewards'][:3])\n",
    "            late_reward = onp.mean(learning_curve_data['rewards'][-3:])\n",
    "            learning_trend = late_reward - early_reward\n",
    "            \n",
    "            print(f\"\\nüìà Learning Curve Analysis:\")\n",
    "            print(f\"  Early training reward: {early_reward:.3f}\")\n",
    "            print(f\"  Late training reward: {late_reward:.3f}\")\n",
    "            print(f\"  Learning trend: {learning_trend:+.3f}\")\n",
    "            \n",
    "            if learning_trend > 0.02:\n",
    "                print(f\"‚úÖ Strong positive learning trend\")\n",
    "            elif learning_trend > 0:\n",
    "                print(f\"‚úÖ Modest positive learning trend\")\n",
    "            elif learning_trend > -0.02:\n",
    "                print(f\"‚ö†Ô∏è Stable/flat learning\")\n",
    "            else:\n",
    "                print(f\"‚ùå Negative learning trend\")\n",
    "    \n",
    "    # Store results for further analysis\n",
    "    duration_checkpoint = duration_metrics.get('checkpoint_path')\n",
    "    \n",
    "    print(f\"\\nüìã Phase 2 Conclusions:\")\n",
    "    print(f\"‚úÖ Duration Benefit: {'CONFIRMED' if duration_test_success else 'LIMITED'}\")\n",
    "    print(f\"‚úÖ Best Configuration: {best_config}\")\n",
    "    print(f\"‚úÖ Training Time Efficiency: {duration_final_reward/duration_time*3600:.3f} reward/hour\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Duration test failed: {e}\")\n",
    "    print(f\"‚ùå Duration test failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    \n",
    "    duration_test_success = False\n",
    "    best_config = \"baseline\"\n",
    "\n",
    "logger.info(\"‚úÖ Phase 2: Training duration test complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8.3: Diagnostic Summary & Recommendations\n",
    "\n",
    "**Summary**: Consolidate findings and provide actionable recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Phase 1: Learning Rate Sensitivity Test\n",
    "Test if lower learning rate resolves negative reward improvement issue\n",
    "\"\"\"\n",
    "\n",
    "print(\"üî¨ Phase 1: Learning Rate Sensitivity Test\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Hypothesis: Current LR (0.05) is too high, causing training instability\")\n",
    "print(\"Test: Use LR=0.001 with same episode count (160) to isolate effect\")\n",
    "\n",
    "# Initialize with proper fallbacks to avoid undefined variable errors\n",
    "original_lr = training_params.get('learning_rate', 0.05) if 'training_params' in locals() else 0.05\n",
    "original_episodes = training_params.get('episodes_per_scm', 5) if 'training_params' in locals() else 5\n",
    "\n",
    "# Test configuration: Lower learning rate\n",
    "test_lr = 0.001\n",
    "print(f\"\\nüìä Test Configuration:\")\n",
    "print(f\"  Learning rate: {original_lr} ‚Üí {test_lr} ({original_lr/test_lr:.0f}x reduction)\")\n",
    "print(f\"  Episodes: {len(training_scms) * original_episodes} (unchanged)\")\n",
    "print(f\"  Expected: Positive reward improvement trend\")\n",
    "\n",
    "# Update training params for test\n",
    "training_params_test = training_params.copy() if 'training_params' in locals() else {\n",
    "    'learning_rate': test_lr,\n",
    "    'episodes_per_scm': original_episodes,\n",
    "    'target_weight': 0.5,\n",
    "    'structure_weight': 0.3,\n",
    "    'exploration_weight': 0.2,\n",
    "    'hidden_dims': [128, 128]\n",
    "}\n",
    "training_params_test['learning_rate'] = test_lr\n",
    "\n",
    "# Create test configuration\n",
    "def create_lr_test_config():\n",
    "    config_dict = {\n",
    "        'seed': eval_config['seed'] + 1,  # Different seed for comparison\n",
    "        'training': {\n",
    "            'n_episodes': len(training_scms) * training_params_test['episodes_per_scm'],\n",
    "            'episode_length': 10,\n",
    "            'learning_rate': training_params_test['learning_rate'],\n",
    "            'gamma': 0.99,\n",
    "            'max_intervention_value': 2.0,\n",
    "            'reward_weights': {\n",
    "                'optimization': training_params_test.get('target_weight', 0.5),\n",
    "                'discovery': training_params_test.get('structure_weight', 0.3),\n",
    "                'efficiency': training_params_test.get('exploration_weight', 0.2)\n",
    "            },\n",
    "            'architecture': {\n",
    "                'hidden_dim': training_params_test.get('hidden_dims', [128, 128])[0],\n",
    "                'num_layers': 2,\n",
    "                'num_heads': 4,\n",
    "                'key_size': 32,\n",
    "                'widening_factor': 4,\n",
    "                'dropout': 0.1,\n",
    "                'policy_intermediate_dim': None\n",
    "            },\n",
    "            'state_config': {\n",
    "                'max_history_size': 100,\n",
    "                'num_channels': 10,\n",
    "                'standardize_values': True,\n",
    "                'include_temporal_features': True\n",
    "            }\n",
    "        },\n",
    "        'experiment': {\n",
    "            'scm_generation': {\n",
    "                'use_variable_factory': True,\n",
    "                'variable_range': [3, 6],\n",
    "                'structure_types': ['fork', 'chain', 'collider', 'mixed'],\n",
    "                'rotation_frequency': 5\n",
    "            }\n",
    "        },\n",
    "        'logging': {\n",
    "            'checkpoint_dir': str(checkpoint_dir / \"lr_test\"),\n",
    "            'wandb': {'enabled': False},\n",
    "            'level': 'INFO'\n",
    "        }\n",
    "    }\n",
    "    return OmegaConf.create(config_dict)\n",
    "\n",
    "# Run learning rate test\n",
    "test_config = create_lr_test_config()\n",
    "test_start_time = time.time()\n",
    "\n",
    "try:\n",
    "    print(f\"\\nüöÄ Starting LR sensitivity test...\")\n",
    "    \n",
    "    # Initialize trainer with test configuration\n",
    "    test_trainer = EnrichedGRPOTrainer(config=test_config)\n",
    "    print(\"‚úÖ Test trainer initialized successfully\")\n",
    "    \n",
    "    # Run training\n",
    "    test_metrics = test_trainer.train()\n",
    "    \n",
    "    test_end_time = time.time()\n",
    "    test_duration = test_end_time - test_start_time\n",
    "    \n",
    "    print(f\"\\n‚úÖ LR test completed in {test_duration/60:.1f} minutes\")\n",
    "    \n",
    "    # Compare results\n",
    "    test_performance = test_metrics.get('performance', {})\n",
    "    test_improvement = test_performance.get('reward_improvement', 0)\n",
    "    test_final_reward = test_performance.get('final_reward', 0)\n",
    "    test_mean_reward = test_performance.get('mean_reward', 0)\n",
    "    \n",
    "    # Get original results for comparison\n",
    "    if 'trained_policy_metrics' in locals():\n",
    "        original_performance = trained_policy_metrics.get('performance', {})\n",
    "        original_improvement = original_performance.get('reward_improvement', 0)\n",
    "        original_final_reward = original_performance.get('final_reward', 0)\n",
    "        original_mean_reward = original_performance.get('mean_reward', 0)\n",
    "    else:\n",
    "        # Use values from Cell 5 output\n",
    "        original_improvement = -0.018\n",
    "        original_final_reward = 0.502\n",
    "        original_mean_reward = 0.512\n",
    "    \n",
    "    print(f\"\\nüìä LR Test Results Comparison:\")\n",
    "    print(f\"Metric                   Original (LR={original_lr})    Test (LR={test_lr})      Change\")\n",
    "    print(f\"{'='*75}\")\n",
    "    print(f\"Reward Improvement:      {original_improvement:>7.3f}                {test_improvement:>7.3f}        {test_improvement-original_improvement:+.3f}\")\n",
    "    print(f\"Final Reward:           {original_final_reward:>7.3f}                {test_final_reward:>7.3f}        {test_final_reward-original_final_reward:+.3f}\")\n",
    "    print(f\"Mean Reward:            {original_mean_reward:>7.3f}                {test_mean_reward:>7.3f}        {test_mean_reward-original_mean_reward:+.3f}\")\n",
    "    \n",
    "    # Test policy quality\n",
    "    sample_scm = test_trainer.scm_manager.scm_rotation[0][1]\n",
    "    variables = list(get_variables(sample_scm))\n",
    "    target = get_target(sample_scm)\n",
    "    \n",
    "    # FIXED: Use correct method name\n",
    "    test_state = test_trainer._create_tensor_backed_state(sample_scm, 0, 0.0)\n",
    "    enriched_input = test_trainer.state_converter.convert_state_to_enriched_input(test_state)\n",
    "    target_idx = variables.index(target) if target in variables else 0\n",
    "    \n",
    "    key = random.PRNGKey(42)\n",
    "    policy_output = test_trainer.policy_fn.apply(\n",
    "        test_trainer.policy_params, key, enriched_input, target_idx, False\n",
    "    )\n",
    "    \n",
    "    test_action = test_trainer._policy_output_to_action(policy_output, variables, target)\n",
    "    test_intervention, test_reward = test_trainer._simulate_intervention(sample_scm, test_action)\n",
    "    \n",
    "    test_magnitude = float(jnp.max(jnp.abs(test_action)))\n",
    "    test_triggers = len(test_intervention.get('targets', set()))\n",
    "    \n",
    "    print(f\"\\nTest Policy Quality:\")\n",
    "    print(f\"  Max action magnitude: {test_magnitude:.6f}\")\n",
    "    print(f\"  Interventions triggered: {test_triggers}\")\n",
    "    print(f\"  Test reward: {test_reward:.3f}\")\n",
    "    \n",
    "    # Analysis and conclusions\n",
    "    print(f\"\\nüîç Analysis:\")\n",
    "    \n",
    "    improvement_fixed = test_improvement > original_improvement + 0.01  # Significant improvement\n",
    "    quality_maintained = test_magnitude > 0.005 and test_triggers > 0\n",
    "    \n",
    "    if improvement_fixed and quality_maintained:\n",
    "        print(f\"‚úÖ LEARNING RATE WAS THE ISSUE!\")\n",
    "        print(f\"‚úÖ Reward improvement: {original_improvement:.3f} ‚Üí {test_improvement:.3f}\")\n",
    "        print(f\"‚úÖ Policy quality maintained\")\n",
    "        print(f\"üí° Recommendation: Use LR={test_lr} for future training\")\n",
    "        \n",
    "        # Store optimal LR for Phase 2\n",
    "        optimal_lr = test_lr\n",
    "        lr_test_success = True\n",
    "        \n",
    "    elif test_improvement > original_improvement:\n",
    "        print(f\"‚úÖ PARTIAL IMPROVEMENT\")\n",
    "        print(f\"Learning rate helps but may need further tuning\")\n",
    "        print(f\"üí° Try even lower LR (0.0005) or longer training\")\n",
    "        \n",
    "        optimal_lr = test_lr\n",
    "        lr_test_success = True\n",
    "        \n",
    "    elif quality_maintained:\n",
    "        print(f\"‚ö†Ô∏è SAME REWARD TREND, GOOD QUALITY\")\n",
    "        print(f\"LR change didn't fix improvement but policy is still strong\")\n",
    "        print(f\"üí° Issue may be training duration or architecture\")\n",
    "        \n",
    "        optimal_lr = test_lr  # Still better for stability\n",
    "        lr_test_success = False\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚ùå LOWER LR MADE THINGS WORSE\")\n",
    "        print(f\"May need higher LR or different approach\")\n",
    "        print(f\"üí° Try LR=0.01 or focus on training duration\")\n",
    "        \n",
    "        optimal_lr = original_lr\n",
    "        lr_test_success = False\n",
    "    \n",
    "    # Visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Comparison bar chart\n",
    "    metrics = ['Reward Improvement', 'Final Reward', 'Mean Reward']\n",
    "    original_values = [original_improvement, original_final_reward, original_mean_reward]\n",
    "    test_values = [test_improvement, test_final_reward, test_mean_reward]\n",
    "    \n",
    "    x = onp.arange(len(metrics))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax1.bar(x - width/2, original_values, width, label=f'Original (LR={original_lr})', alpha=0.8)\n",
    "    bars2 = ax1.bar(x + width/2, test_values, width, label=f'Test (LR={test_lr})', alpha=0.8)\n",
    "    \n",
    "    ax1.set_xlabel('Metrics')\n",
    "    ax1.set_ylabel('Value')\n",
    "    ax1.set_title('Learning Rate Sensitivity Test Results')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(metrics)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # Policy quality comparison\n",
    "    quality_metrics = ['Action Magnitude', 'Interventions Triggered']\n",
    "    original_quality = [1.6948, 1]  # From Cell 5 output\n",
    "    test_quality = [test_magnitude, test_triggers]\n",
    "    \n",
    "    x2 = onp.arange(len(quality_metrics))\n",
    "    bars3 = ax2.bar(x2 - width/2, original_quality, width, label=f'Original (LR={original_lr})', alpha=0.8)\n",
    "    bars4 = ax2.bar(x2 + width/2, test_quality, width, label=f'Test (LR={test_lr})', alpha=0.8)\n",
    "    \n",
    "    ax2.set_xlabel('Quality Metrics')\n",
    "    ax2.set_ylabel('Value')\n",
    "    ax2.set_title('Policy Quality Comparison')\n",
    "    ax2.set_xticks(x2)\n",
    "    ax2.set_xticklabels(quality_metrics)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bars in [bars3, bars4]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Store results for Phase 2\n",
    "    lr_test_checkpoint = test_metrics.get('checkpoint_path')\n",
    "    \n",
    "    print(f\"\\nüìã Phase 1 Conclusions:\")\n",
    "    print(f\"‚úÖ Learning Rate Sensitivity: {'CONFIRMED' if lr_test_success else 'INCONCLUSIVE'}\")\n",
    "    print(f\"‚úÖ Optimal LR for Phase 2: {optimal_lr}\")\n",
    "    print(f\"‚úÖ Ready for duration testing: {'YES' if lr_test_success else 'MAYBE'}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"LR test failed: {e}\")\n",
    "    print(f\"‚ùå LR test failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    \n",
    "    # Use original LR as fallback\n",
    "    optimal_lr = original_lr\n",
    "    lr_test_success = False\n",
    "    print(f\"üí° Using original LR={optimal_lr} for Phase 2\")\n",
    "\n",
    "logger.info(\"‚úÖ Phase 1: Learning rate sensitivity test complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8.2: Training Duration Test\n",
    "\n",
    "**Test**: Determine if longer training with optimal LR improves learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Phase 1: Learning Rate Sensitivity Test\n",
    "Test if lower learning rate resolves negative reward improvement issue\n",
    "\"\"\"\n",
    "\n",
    "print(\"üî¨ Phase 1: Learning Rate Sensitivity Test\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Hypothesis: Current LR (0.05) is too high, causing training instability\")\n",
    "print(\"Test: Use LR=0.001 with same episode count (160) to isolate effect\")\n",
    "\n",
    "# Store original training params for comparison\n",
    "original_lr = training_params['learning_rate']\n",
    "original_episodes = training_params['episodes_per_scm']\n",
    "\n",
    "# Test configuration: Lower learning rate\n",
    "test_lr = 0.001\n",
    "print(f\"\\nüìä Test Configuration:\")\n",
    "print(f\"  Learning rate: {original_lr} ‚Üí {test_lr} (20x reduction)\")\n",
    "print(f\"  Episodes: {len(training_scms) * original_episodes} (unchanged)\")\n",
    "print(f\"  Expected: Positive reward improvement trend\")\n",
    "\n",
    "# Update training params for test\n",
    "training_params_test = training_params.copy()\n",
    "training_params_test['learning_rate'] = test_lr\n",
    "\n",
    "# Create test configuration\n",
    "def create_lr_test_config():\n",
    "    config_dict = {\n",
    "        'seed': eval_config['seed'] + 1,  # Different seed for comparison\n",
    "        'training': {\n",
    "            'n_episodes': len(training_scms) * training_params_test['episodes_per_scm'],\n",
    "            'episode_length': 10,\n",
    "            'learning_rate': training_params_test['learning_rate'],\n",
    "            'gamma': 0.99,\n",
    "            'max_intervention_value': 2.0,\n",
    "            'reward_weights': {\n",
    "                'optimization': training_params_test['target_weight'],\n",
    "                'discovery': training_params_test['structure_weight'],\n",
    "                'efficiency': training_params_test['exploration_weight']\n",
    "            },\n",
    "            'architecture': {\n",
    "                'hidden_dim': training_params_test['hidden_dims'][0],\n",
    "                'num_layers': 2,\n",
    "                'num_heads': 4,\n",
    "                'key_size': 32,\n",
    "                'widening_factor': 4,\n",
    "                'dropout': 0.1,\n",
    "                'policy_intermediate_dim': None\n",
    "            },\n",
    "            'state_config': {\n",
    "                'max_history_size': 100,\n",
    "                'num_channels': 10,\n",
    "                'standardize_values': True,\n",
    "                'include_temporal_features': True\n",
    "            }\n",
    "        },\n",
    "        'experiment': {\n",
    "            'scm_generation': {\n",
    "                'use_variable_factory': True,\n",
    "                'variable_range': [3, 6],\n",
    "                'structure_types': ['fork', 'chain', 'collider', 'mixed'],\n",
    "                'rotation_frequency': 5\n",
    "            }\n",
    "        },\n",
    "        'logging': {\n",
    "            'checkpoint_dir': str(checkpoint_dir / \"lr_test\"),\n",
    "            'wandb': {'enabled': False},\n",
    "            'level': 'INFO'\n",
    "        }\n",
    "    }\n",
    "    return OmegaConf.create(config_dict)\n",
    "\n",
    "# Run learning rate test\n",
    "test_config = create_lr_test_config()\n",
    "test_start_time = time.time()\n",
    "\n",
    "try:\n",
    "    print(f\"\\nüöÄ Starting LR sensitivity test...\")\n",
    "    \n",
    "    # Initialize trainer with test configuration\n",
    "    test_trainer = EnrichedGRPOTrainer(config=test_config)\n",
    "    print(\"‚úÖ Test trainer initialized successfully\")\n",
    "    \n",
    "    # Run training\n",
    "    test_metrics = test_trainer.train()\n",
    "    \n",
    "    test_end_time = time.time()\n",
    "    test_duration = test_end_time - test_start_time\n",
    "    \n",
    "    print(f\"\\n‚úÖ LR test completed in {test_duration/60:.1f} minutes\")\n",
    "    \n",
    "    # Compare results\n",
    "    test_performance = test_metrics.get('performance', {})\n",
    "    test_improvement = test_performance.get('reward_improvement', 0)\n",
    "    test_final_reward = test_performance.get('final_reward', 0)\n",
    "    test_mean_reward = test_performance.get('mean_reward', 0)\n",
    "    \n",
    "    # Get original results for comparison\n",
    "    if 'trained_policy_metrics' in locals():\n",
    "        original_performance = trained_policy_metrics.get('performance', {})\n",
    "        original_improvement = original_performance.get('reward_improvement', 0)\n",
    "        original_final_reward = original_performance.get('final_reward', 0)\n",
    "        original_mean_reward = original_performance.get('mean_reward', 0)\n",
    "    else:\n",
    "        # Use values from Cell 5 output\n",
    "        original_improvement = -0.018\n",
    "        original_final_reward = 0.502\n",
    "        original_mean_reward = 0.512\n",
    "    \n",
    "    print(f\"\\nüìä LR Test Results Comparison:\")\n",
    "    print(f\"Metric                   Original (LR={original_lr})    Test (LR={test_lr})      Change\")\n",
    "    print(f\"{'='*75}\")\n",
    "    print(f\"Reward Improvement:      {original_improvement:>7.3f}                {test_improvement:>7.3f}        {test_improvement-original_improvement:+.3f}\")\n",
    "    print(f\"Final Reward:           {original_final_reward:>7.3f}                {test_final_reward:>7.3f}        {test_final_reward-original_final_reward:+.3f}\")\n",
    "    print(f\"Mean Reward:            {original_mean_reward:>7.3f}                {test_mean_reward:>7.3f}        {test_mean_reward-original_mean_reward:+.3f}\")\n",
    "    \n",
    "    # Test policy quality\n",
    "    sample_scm = test_trainer.scm_manager.scm_rotation[0][1]\n",
    "    variables = list(get_variables(sample_scm))\n",
    "    target = get_target(sample_scm)\n",
    "    \n",
    "    # FIXED: Use correct method name\n",
    "    test_state = test_trainer._create_tensor_backed_state(sample_scm, 0, 0.0)\n",
    "    enriched_input = test_trainer.state_converter.convert_state_to_enriched_input(test_state)\n",
    "    target_idx = variables.index(target) if target in variables else 0\n",
    "    \n",
    "    key = random.PRNGKey(42)\n",
    "    policy_output = test_trainer.policy_fn.apply(\n",
    "        test_trainer.policy_params, key, enriched_input, target_idx, False\n",
    "    )\n",
    "    \n",
    "    test_action = test_trainer._policy_output_to_action(policy_output, variables, target)\n",
    "    test_intervention, test_reward = test_trainer._simulate_intervention(sample_scm, test_action)\n",
    "    \n",
    "    test_magnitude = float(jnp.max(jnp.abs(test_action)))\n",
    "    test_triggers = len(test_intervention.get('targets', set()))\n",
    "    \n",
    "    print(f\"\\nTest Policy Quality:\")\n",
    "    print(f\"  Max action magnitude: {test_magnitude:.6f}\")\n",
    "    print(f\"  Interventions triggered: {test_triggers}\")\n",
    "    print(f\"  Test reward: {test_reward:.3f}\")\n",
    "    \n",
    "    # Analysis and conclusions\n",
    "    print(f\"\\nüîç Analysis:\")\n",
    "    \n",
    "    improvement_fixed = test_improvement > original_improvement + 0.01  # Significant improvement\n",
    "    quality_maintained = test_magnitude > 0.005 and test_triggers > 0\n",
    "    \n",
    "    if improvement_fixed and quality_maintained:\n",
    "        print(f\"‚úÖ LEARNING RATE WAS THE ISSUE!\")\n",
    "        print(f\"‚úÖ Reward improvement: {original_improvement:.3f} ‚Üí {test_improvement:.3f}\")\n",
    "        print(f\"‚úÖ Policy quality maintained\")\n",
    "        print(f\"üí° Recommendation: Use LR={test_lr} for future training\")\n",
    "        \n",
    "        # Store optimal LR for Phase 2\n",
    "        optimal_lr = test_lr\n",
    "        lr_test_success = True\n",
    "        \n",
    "    elif test_improvement > original_improvement:\n",
    "        print(f\"‚úÖ PARTIAL IMPROVEMENT\")\n",
    "        print(f\"Learning rate helps but may need further tuning\")\n",
    "        print(f\"üí° Try even lower LR (0.0005) or longer training\")\n",
    "        \n",
    "        optimal_lr = test_lr\n",
    "        lr_test_success = True\n",
    "        \n",
    "    elif quality_maintained:\n",
    "        print(f\"‚ö†Ô∏è SAME REWARD TREND, GOOD QUALITY\")\n",
    "        print(f\"LR change didn't fix improvement but policy is still strong\")\n",
    "        print(f\"üí° Issue may be training duration or architecture\")\n",
    "        \n",
    "        optimal_lr = test_lr  # Still better for stability\n",
    "        lr_test_success = False\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚ùå LOWER LR MADE THINGS WORSE\")\n",
    "        print(f\"May need higher LR or different approach\")\n",
    "        print(f\"üí° Try LR=0.01 or focus on training duration\")\n",
    "        \n",
    "        optimal_lr = original_lr\n",
    "        lr_test_success = False\n",
    "    \n",
    "    # Visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Comparison bar chart\n",
    "    metrics = ['Reward Improvement', 'Final Reward', 'Mean Reward']\n",
    "    original_values = [original_improvement, original_final_reward, original_mean_reward]\n",
    "    test_values = [test_improvement, test_final_reward, test_mean_reward]\n",
    "    \n",
    "    x = onp.arange(len(metrics))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax1.bar(x - width/2, original_values, width, label=f'Original (LR={original_lr})', alpha=0.8)\n",
    "    bars2 = ax1.bar(x + width/2, test_values, width, label=f'Test (LR={test_lr})', alpha=0.8)\n",
    "    \n",
    "    ax1.set_xlabel('Metrics')\n",
    "    ax1.set_ylabel('Value')\n",
    "    ax1.set_title('Learning Rate Sensitivity Test Results')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(metrics)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # Policy quality comparison\n",
    "    quality_metrics = ['Action Magnitude', 'Interventions Triggered']\n",
    "    original_quality = [1.6948, 1]  # From Cell 5 output\n",
    "    test_quality = [test_magnitude, test_triggers]\n",
    "    \n",
    "    x2 = onp.arange(len(quality_metrics))\n",
    "    bars3 = ax2.bar(x2 - width/2, original_quality, width, label=f'Original (LR={original_lr})', alpha=0.8)\n",
    "    bars4 = ax2.bar(x2 + width/2, test_quality, width, label=f'Test (LR={test_lr})', alpha=0.8)\n",
    "    \n",
    "    ax2.set_xlabel('Quality Metrics')\n",
    "    ax2.set_ylabel('Value')\n",
    "    ax2.set_title('Policy Quality Comparison')\n",
    "    ax2.set_xticks(x2)\n",
    "    ax2.set_xticklabels(quality_metrics)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bars in [bars3, bars4]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Store results for Phase 2\n",
    "    lr_test_checkpoint = test_metrics.get('checkpoint_path')\n",
    "    \n",
    "    print(f\"\\nüìã Phase 1 Conclusions:\")\n",
    "    print(f\"‚úÖ Learning Rate Sensitivity: {'CONFIRMED' if lr_test_success else 'INCONCLUSIVE'}\")\n",
    "    print(f\"‚úÖ Optimal LR for Phase 2: {optimal_lr}\")\n",
    "    print(f\"‚úÖ Ready for duration testing: {'YES' if lr_test_success else 'MAYBE'}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"LR test failed: {e}\")\n",
    "    print(f\"‚ùå LR test failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    \n",
    "    # Use original LR as fallback\n",
    "    optimal_lr = original_lr\n",
    "    lr_test_success = False\n",
    "    print(f\"üí° Using original LR={optimal_lr} for Phase 2\")\n",
    "\n",
    "logger.info(\"‚úÖ Phase 1: Learning rate sensitivity test complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8.1: Learning Rate Sensitivity Test\n",
    "\n",
    "**Diagnostic Test**: Fix negative reward improvement by testing lower learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Results Analysis & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úÖ Results analysis complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Analyzing results from: 20-39-11\n",
      "Found: 0 JSON, 0 CSV, 0 plot files\n",
      "\n",
      "üí° Recommendations:\n",
      "‚ùå No results found - check evaluation execution\n",
      "\n",
      "üéâ Training-to-Evaluation Pipeline Complete!\n",
      "üìÅ Results available in: /Users/harellidar/Documents/Imperial/Individual_Project/causal_bayes_opt/outputs/4method_comparison/2025-07-03/20-39-11\n",
      "üîß Adjust parameters in Cell 3 and re-run for different configurations\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Analyze and visualize comparison results\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from glob import glob\n",
    "\n",
    "# Find most recent evaluation results\n",
    "outputs_pattern = str(project_root / \"outputs\" / \"4method_comparison\" / \"*\" / \"*\")\n",
    "recent_outputs = sorted(glob(outputs_pattern))[-1:] if glob(outputs_pattern) else []\n",
    "\n",
    "if not recent_outputs:\n",
    "    print(\"‚ùå No evaluation results found\")\n",
    "    print(\"Run the evaluation in Cell 7 first\")\n",
    "else:\n",
    "    latest_output_dir = Path(recent_outputs[0])\n",
    "    print(f\"üìä Analyzing results from: {latest_output_dir.name}\")\n",
    "    \n",
    "    # Look for results files\n",
    "    json_results = list(latest_output_dir.glob(\"*.json\"))\n",
    "    csv_results = list(latest_output_dir.glob(\"*.csv\"))\n",
    "    plot_files = list(latest_output_dir.glob(\"*.png\"))\n",
    "    \n",
    "    print(f\"Found: {len(json_results)} JSON, {len(csv_results)} CSV, {len(plot_files)} plot files\")\n",
    "    \n",
    "    # Load and analyze results\n",
    "    if json_results:\n",
    "        results_file = json_results[0]\n",
    "        print(f\"\\nüìà Loading results from: {results_file.name}\")\n",
    "        \n",
    "        try:\n",
    "            with open(results_file, 'r') as f:\n",
    "                results_data = json.load(f)\n",
    "            \n",
    "            # Extract method performance\n",
    "            if 'results' in results_data:\n",
    "                method_results = results_data['results']\n",
    "                \n",
    "                print(\"\\nüèÜ Method Performance Summary:\")\n",
    "                print(\"-\" * 60)\n",
    "                \n",
    "                methods = list(method_results.keys())\n",
    "                metrics = ['target_improvement', 'structure_accuracy', 'sample_efficiency']\n",
    "                \n",
    "                # Create summary table\n",
    "                summary_data = []\n",
    "                for method in methods:\n",
    "                    method_data = method_results[method]\n",
    "                    if isinstance(method_data, list) and method_data:\n",
    "                        # Calculate means for list of results\n",
    "                        avg_target = onp.mean([r.get('target_improvement', 0) for r in method_data])\n",
    "                        avg_structure = onp.mean([r.get('structure_accuracy', 0) for r in method_data])\n",
    "                        avg_efficiency = onp.mean([r.get('sample_efficiency', 0) for r in method_data])\n",
    "                        \n",
    "                        summary_data.append({\n",
    "                            'Method': method,\n",
    "                            'Target Improvement': avg_target,\n",
    "                            'Structure Accuracy': avg_structure,\n",
    "                            'Sample Efficiency': avg_efficiency,\n",
    "                            'Runs': len(method_data)\n",
    "                        })\n",
    "                \n",
    "                # Display results table\n",
    "                for data in summary_data:\n",
    "                    print(f\"{data['Method']:<30} | Target: {data['Target Improvement']:.3f} | \"\n",
    "                          f\"Structure: {data['Structure Accuracy']:.3f} | \"\n",
    "                          f\"Efficiency: {data['Sample Efficiency']:.3f} | \"\n",
    "                          f\"Runs: {data['Runs']}\")\n",
    "                \n",
    "                # Highlight best performing method\n",
    "                if summary_data:\n",
    "                    best_target = max(summary_data, key=lambda x: x['Target Improvement'])\n",
    "                    print(f\"\\nü•á Best Target Improvement: {best_target['Method']} ({best_target['Target Improvement']:.3f})\")\n",
    "                    \n",
    "                    # Check if trained policy outperformed baselines\n",
    "                    policy_results = [d for d in summary_data if 'Policy' in d['Method'] or 'Learned' in d['Method']]\n",
    "                    baseline_results = [d for d in summary_data if d not in policy_results]\n",
    "                    \n",
    "                    if policy_results and baseline_results:\n",
    "                        policy_performance = policy_results[0]['Target Improvement']\n",
    "                        best_baseline = max(baseline_results, key=lambda x: x['Target Improvement'])['Target Improvement']\n",
    "                        \n",
    "                        improvement = policy_performance - best_baseline\n",
    "                        print(f\"\\nüìä Policy vs Best Baseline:\")\n",
    "                        print(f\"  Policy: {policy_performance:.3f}\")\n",
    "                        print(f\"  Best Baseline: {best_baseline:.3f}\")\n",
    "                        print(f\"  Improvement: {improvement:+.3f}\")\n",
    "                        \n",
    "                        if improvement > 0.05:  # 5% improvement threshold\n",
    "                            print(\"‚úÖ Trained policy significantly outperforms baselines!\")\n",
    "                        elif improvement > 0:\n",
    "                            print(\"‚úÖ Trained policy shows modest improvement\")\n",
    "                        else:\n",
    "                            print(\"‚ö†Ô∏è Trained policy needs improvement\")\n",
    "            \n",
    "            # Statistical analysis if available\n",
    "            if 'analysis' in results_data:\n",
    "                analysis = results_data['analysis']\n",
    "                print(f\"\\nüìà Statistical Analysis:\")\n",
    "                \n",
    "                if 'significance_tests' in analysis:\n",
    "                    sig_tests = analysis['significance_tests']\n",
    "                    print(f\"  Significance tests: {len(sig_tests)} comparisons\")\n",
    "                    \n",
    "                    # Show significant differences\n",
    "                    significant = [test for test in sig_tests.values() if test.get('p_value', 1) < 0.05]\n",
    "                    print(f\"  Significant differences: {len(significant)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading results: {e}\")\n",
    "    \n",
    "    # Display generated plots\n",
    "    if plot_files:\n",
    "        print(f\"\\nüé® Generated Plots ({len(plot_files)}):\")\n",
    "        for plot_file in plot_files[:3]:  # Show first 3 plots\n",
    "            print(f\"  üìä {plot_file.name}\")\n",
    "            \n",
    "            # Display plot if possible\n",
    "            try:\n",
    "                from IPython.display import Image, display\n",
    "                display(Image(filename=str(plot_file)))\n",
    "            except:\n",
    "                print(f\"    (Plot available at: {plot_file})\")\n",
    "    \n",
    "    # Summary recommendations\n",
    "    print(f\"\\nüí° Recommendations:\")\n",
    "    if json_results:\n",
    "        print(\"‚úÖ Review detailed results in output directory\")\n",
    "        print(\"‚úÖ Compare policy performance against baselines\")\n",
    "        if plot_files:\n",
    "            print(\"‚úÖ Analyze generated visualizations\")\n",
    "        print(\"‚úÖ Consider longer training if policy underperformed\")\n",
    "    else:\n",
    "        print(\"‚ùå No results found - check evaluation execution\")\n",
    "\n",
    "logger.info(\"‚úÖ Results analysis complete\")\n",
    "\n",
    "print(f\"\\nüéâ Training-to-Evaluation Pipeline Complete!\")\n",
    "print(f\"üìÅ Results available in: {latest_output_dir if 'latest_output_dir' in locals() else 'outputs directory'}\")\n",
    "print(f\"üîß Adjust parameters in Cell 3 and re-run for different configurations\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal-bayes-opt-sr_Vb8Og-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
