# Component Registry

This document provides a comprehensive overview of the components available in the `causal_meta` package, their functionality, interfaces, and recommended usage patterns. The goal is to reduce code duplication and improve collaboration by ensuring that all team members understand the existing tools before implementing new ones.

## IMPORTANT: READ BEFORE WRITING NEW CODE

**This registry is the authoritative source for understanding the components available in the codebase.** Before implementing new functionality:

1. **ALWAYS check this registry first** to see if a component already exists that meets your needs or can be extended
2. **Follow the interfaces and patterns** documented here for consistent implementation
3. **Update this registry** when adding new components or making significant changes to existing ones
4. **Reference this document** when designing integration between components

Following these guidelines will significantly reduce code duplication, improve integration, and make the codebase more maintainable.

## Core Structure

The `causal_meta` package is organized into the following main modules:

1. **graph**: Core graph representations and generation utilities
2. **environments**: Structural Causal Models (SCMs) and intervention mechanisms
3. **meta_learning**: Amortized causal discovery and meta-learning components
4. **discovery**: Causal discovery algorithms
5. **optimization**: Optimization algorithms for causal systems
6. **inference**: Inference algorithms for causal models
7. **utils**: Utility functions and visualization tools

## Graph Module (`causal_meta.graph`)

### CausalGraph (`causal_meta.graph.causal_graph.CausalGraph`)

**Purpose**: Represents a causal graph structure (Directed Acyclic Graph - DAG) with nodes representing variables and edges representing causal relationships.

**Key Methods**:
- `add_node(node_id, **attrs)`: Add a node to the graph
- `add_edge(source, target, **attrs)`: Add a directed edge from source to target
- `remove_node(node_id)`: Remove a node and all its connected edges
- `remove_edge(source, target)`: Remove an edge from the graph
- `get_nodes()`: Get all nodes in the graph
- `get_edges()`: Get all edges in the graph
- `get_parents(node)`: Get parents of a node
- `get_children(node)`: Get children of a node
- `get_adjacency_matrix()`: Get the adjacency matrix representation of the graph
- `is_acyclic()`: Check if the graph is acyclic
- `to_networkx()`: Convert to a NetworkX graph
- `from_networkx(nx_graph)`: Create a CausalGraph from a NetworkX graph
- `copy()`: Create a deep copy of the graph

**Usage Example**:
```python
from causal_meta.graph.causal_graph import CausalGraph

# Create a new causal graph
graph = CausalGraph()
graph.add_node("X")
graph.add_node("Y")
graph.add_node("Z")
graph.add_edge("X", "Y")
graph.add_edge("Y", "Z")

# Check properties
parents_of_y = graph.get_parents("Y")  # ["X"]
is_dag = graph.is_acyclic()  # True

# Get adjacency matrix
adj_matrix = graph.get_adjacency_matrix()
```

### DirectedGraph (`causal_meta.graph.directed_graph.DirectedGraph`)

**Purpose**: Base class for directed graphs, providing common functionality for graph manipulation. The `CausalGraph` class extends this with causality-specific methods.

**Usage Note**: In most cases, use `CausalGraph` directly rather than `DirectedGraph`.

### TaskFamily (`causal_meta.graph.task_family.TaskFamily`)

**Purpose**: Represents a family of related causal tasks, typically generated by varying a base graph.

**Key Methods**:
- `__init__(base_graph, variations, metadata)`: Constructor
- `get_base_graph()`: Get the base graph of the family
- `get_variations()`: Get the list of variation graphs
- `save(filepath)`: Save the task family to a file
- `load(filepath)`: Load a task family from a file

**Usage Example**:
```python
from causal_meta.graph.task_family import TaskFamily
from causal_meta.graph.generators.factory import GraphFactory
from causal_meta.graph.generators.task_families import generate_task_family

# Create a base graph
base_graph = GraphFactory.create_random_dag(num_nodes=5, edge_probability=0.3)

# Generate a task family
variations = generate_task_family(
    base_graph, 
    num_tasks=10, 
    variation_type="edge_weight",
    variation_strength=0.2
)

# Create a TaskFamily object
task_family = TaskFamily(
    base_graph=base_graph,
    variations=variations,
    metadata={"family_type": "edge_weight_variation", "num_tasks": 10}
)

# Save the task family
task_family.save("path/to/task_family.pkl")
```

### Graph Generators (`causal_meta.graph.generators`)

#### GraphFactory (`causal_meta.graph.generators.factory.GraphFactory`)

**Purpose**: Creates different types of causal graph structures.

**Key Methods**:
- `create_random_dag(num_nodes, edge_probability)`: Create a random DAG
- `create_chain_graph(num_nodes)`: Create a chain graph
- `create_tree_graph(num_nodes, branching_factor)`: Create a tree graph
- `create_scale_free_graph(num_nodes, alpha, beta, gamma)`: Create a scale-free graph
- `create_erdos_renyi_graph(num_nodes, edge_probability)`: Create an Erdős–Rényi random graph

**Usage Example**:
```python
from causal_meta.graph.generators.factory import GraphFactory

# Create a random DAG
random_dag = GraphFactory.create_random_dag(num_nodes=10, edge_probability=0.2)

# Create a chain graph
chain_graph = GraphFactory.create_chain_graph(num_nodes=5)
```

#### Task Family Generation (`causal_meta.graph.generators.task_families`)

**Purpose**: Creates families of related causal graphs by introducing variations to a base graph.

**Key Functions**:
- `generate_task_family(base_graph, num_tasks, variation_type, variation_strength)`: Generate a family of related graphs
- `generate_edge_weight_variations(base_graph, num_variations, variation_strength)`: Generate variations by modifying edge weights
- `generate_structure_variations(base_graph, num_variations, variation_strength)`: Generate variations by modifying graph structure

**Usage Example**:
```python
from causal_meta.graph.generators.factory import GraphFactory
from causal_meta.graph.generators.task_families import generate_task_family

# Create a base graph
base_graph = GraphFactory.create_random_dag(num_nodes=5, edge_probability=0.3)

# Generate a task family with edge weight variations
edge_weight_variations = generate_task_family(
    base_graph, 
    num_tasks=10, 
    variation_type="edge_weight",
    variation_strength=0.2
)

# Generate a task family with structure variations
structure_variations = generate_task_family(
    base_graph, 
    num_tasks=10, 
    variation_type="structure",
    variation_strength=0.3
)
```

### Visualization (`causal_meta.graph.visualization`)

**Purpose**: Provides visualization utilities for causal graphs and task families.

**Key Functions**:
- `plot_graph(graph, **kwargs)`: Plot a causal graph
- `plot_graphs_comparison(graphs, titles, **kwargs)`: Plot multiple graphs for comparison
- `plot_adjacency_matrix(adj_matrix, **kwargs)`: Plot an adjacency matrix
- `plot_adjacency_matrices_comparison(adj_matrices, titles, **kwargs)`: Plot multiple adjacency matrices
- `plot_intervention_effect(pre_intervention_data, post_intervention_data, intervention_node, **kwargs)`: Visualize intervention effects

**Usage Example**:
```python
from causal_meta.graph.visualization import plot_graph, plot_graphs_comparison
from causal_meta.graph.generators.factory import GraphFactory

# Create a graph
graph = GraphFactory.create_random_dag(num_nodes=5, edge_probability=0.3)

# Plot a single graph
plot_graph(graph, title="Random DAG")

# Plot multiple graphs
graphs = [
    GraphFactory.create_random_dag(num_nodes=5, edge_probability=0.3),
    GraphFactory.create_random_dag(num_nodes=5, edge_probability=0.3)
]
plot_graphs_comparison(graphs, titles=["Graph 1", "Graph 2"])
```

## Environments Module (`causal_meta.environments`)

### StructuralCausalModel (`causal_meta.environments.scm.StructuralCausalModel`)

**Purpose**: Implements a Structural Causal Model (SCM) based on a causal graph, defining structural equations for each node and allowing data generation under observational and interventional scenarios.

**Key Methods**:
- `__init__(graph, structural_equations, noise_distributions)`: Constructor
- `sample_data(n_samples)`: Generate observational data
- `do_intervention(target_node, value)`: Perform a perfect intervention
- `soft_intervention(target_node, func, strength)`: Perform a soft intervention
- `sample_interventional_data(interventions, n_samples)`: Generate interventional data
- `get_causal_graph()`: Get the underlying causal graph
- `get_adjacency_matrix()`: Get the adjacency matrix of the causal graph

**Usage Example**:
```python
from causal_meta.environments.scm import StructuralCausalModel
from causal_meta.graph.generators.factory import GraphFactory

# Create a graph
graph = GraphFactory.create_random_dag(num_nodes=3, edge_probability=0.4)

# Define structural equations
def f_x(noise):
    return noise

def f_y(x, noise):
    return 2 * x + noise

def f_z(y, noise):
    return 0.5 * y + noise

# Create noise distributions
import numpy as np
noise_dists = {
    "X": lambda n: np.random.normal(0, 1, n),
    "Y": lambda n: np.random.normal(0, 0.5, n),
    "Z": lambda n: np.random.normal(0, 0.1, n)
}

# Create the SCM
structural_equations = {
    "X": f_x,
    "Y": f_y,
    "Z": f_z
}

scm = StructuralCausalModel(graph, structural_equations, noise_dists)

# Sample observational data
obs_data = scm.sample_data(n_samples=1000)

# Perform an intervention and sample interventional data
int_scm = scm.do_intervention("X", 2.0)
int_data = int_scm.sample_data(n_samples=1000)
```

### Interventions (`causal_meta.environments.interventions`)

**Purpose**: Defines different types of interventions on SCMs.

**Key Classes**:
- `Intervention`: Abstract base class for interventions
- `PerfectIntervention`: Implements the do-operator (sets node to fixed value, removes parents)
- `SoftIntervention`: Modifies the structural equation
- `ImperfectIntervention`: Modifies node value based on original value, intervention value, and strength

**Usage Example**:
```python
from causal_meta.environments.interventions import PerfectIntervention, SoftIntervention
from causal_meta.environments.scm import StructuralCausalModel

# Create an SCM (see previous example)
# ...

# Perfect intervention
perfect_int = PerfectIntervention(target_node="X", value=2.0)
int_scm = perfect_int.apply(scm)
int_data = int_scm.sample_data(n_samples=1000)

# Soft intervention
def new_mechanism(x, noise):
    return 0.5 * x + noise

soft_int = SoftIntervention(target_node="Y", new_mechanism=new_mechanism)
soft_int_scm = soft_int.apply(scm)
soft_int_data = soft_int_scm.sample_data(n_samples=1000)
```

### Mechanisms (`causal_meta.environments.mechanisms`)

**Purpose**: Provides utilities for creating and managing structural equations for SCMs.

**Key Functions**:
- `create_linear_mechanism(parents, weights)`: Create a linear mechanism
- `create_nonlinear_mechanism(parents, function)`: Create a nonlinear mechanism
- `create_additive_noise_mechanism(parents, function)`: Create a mechanism with additive noise

**Usage Example**:
```python
from causal_meta.environments.mechanisms import create_linear_mechanism

# Create a linear mechanism for a node with two parents
mechanism = create_linear_mechanism(parents=["X", "Y"], weights=[1.5, -0.7])
```

## Meta Learning Module (`causal_meta.meta_learning`)

### Amortized Causal Discovery (`causal_meta.meta_learning.amortized_causal_discovery`)

**Purpose**: Implements neural network-based amortized causal discovery, combining graph structure inference and dynamics modeling.

**Key Classes**:
- `AmortizedCausalDiscovery`: Main class that integrates GraphEncoder and DynamicsDecoder

**Key Methods**:
- `__init__(graph_encoder_params, dynamics_decoder_params)`: Constructor
- `forward(data)`: Forward pass through both components
- `train(train_loader, val_loader, **kwargs)`: Train the model
- `infer_causal_graph(data)`: Infer a causal graph from data
- `predict_intervention_outcomes(data, interventions)`: Predict outcomes of interventions
- `save(path)`: Save the model
- `load(path)`: Load a model from a file

**Usage Example**:
```python
from causal_meta.meta_learning import AmortizedCausalDiscovery
from causal_meta.meta_learning.data_generation import SyntheticDataGenerator

# Create data generator
data_gen = SyntheticDataGenerator(...)

# Create datasets
train_loader, val_loader = data_gen.create_dataloaders(...)

# Initialize model
model = AmortizedCausalDiscovery(
    graph_encoder_params={
        "input_dim": 10,
        "hidden_dim": 64,
        "num_layers": 3
    },
    dynamics_decoder_params={
        "hidden_dim": 64,
        "num_layers": 2
    }
)

# Train the model
model.train(train_loader, val_loader, epochs=100)

# Infer a causal graph
graph = model.infer_causal_graph(test_data)

# Predict intervention outcomes
outcomes = model.predict_intervention_outcomes(test_data, interventions={"X": 2.0})
```

### GraphEncoder (`causal_meta.meta_learning.acd_models.GraphEncoder`)

**Purpose**: Neural network component for inferring causal structure from observational and interventional data.

**Key Methods**:
- `__init__(input_dim, hidden_dim, num_layers, **kwargs)`: Constructor
- `forward(data)`: Compute edge probabilities for a batch of data
- `compute_sparsity_loss(adj_matrices)`: Compute sparsity regularization
- `compute_acyclicity_loss(adj_matrices)`: Compute acyclicity regularization

**Usage Example**:
```python
from causal_meta.meta_learning.acd_models import GraphEncoder
import torch

# Initialize encoder
encoder = GraphEncoder(
    input_dim=10,
    hidden_dim=64,
    num_layers=3
)

# Create dummy data
data = torch.randn(32, 100, 10)  # (batch_size, seq_len, features)

# Forward pass
edge_probs = encoder(data)
```

### DynamicsDecoder (`causal_meta.meta_learning.dynamics_decoder.DynamicsDecoder`)

**Purpose**: Neural network component for predicting intervention outcomes based on inferred graph structure.

**Key Methods**:
- `__init__(hidden_dim, num_layers, **kwargs)`: Constructor
- `forward(data, graph, interventions)`: Predict outcomes under interventions
- `predict_with_uncertainty(data, graph, interventions)`: Predict with uncertainty estimates

**Usage Example**:
```python
from causal_meta.meta_learning.dynamics_decoder import DynamicsDecoder
import torch

# Initialize decoder
decoder = DynamicsDecoder(
    hidden_dim=64,
    num_layers=2
)

# Create dummy data
data = torch.randn(32, 100, 10)  # (batch_size, seq_len, features)
graph = torch.randn(32, 10, 10)  # (batch_size, nodes, nodes)
interventions = {3: 2.0}  # Intervene on node 3, set to 2.0

# Forward pass
predictions = decoder(data, graph, interventions)
```

### Meta-Learning Components (`causal_meta.meta_learning.meta_learning`)

**Purpose**: Implements meta-learning techniques for amortized causal discovery, enabling few-shot adaptation to new tasks.

**Key Classes**:
- `TaskEmbedding`: Converts causal graphs to numerical embeddings
- `MAMLForCausalDiscovery`: Implements MAML for causal discovery

**Key Methods**:
- `TaskEmbedding.embed(graph)`: Convert a graph to a numerical embedding
- `MAMLForCausalDiscovery.meta_train(task_batch)`: Meta-train across a batch of tasks
- `MAMLForCausalDiscovery.adapt(task, n_gradient_steps)`: Adapt to a new task

**Usage Example**:
```python
from causal_meta.meta_learning.meta_learning import TaskEmbedding, MAMLForCausalDiscovery
from causal_meta.graph.generators.factory import GraphFactory

# Create a graph
graph = GraphFactory.create_random_dag(num_nodes=5, edge_probability=0.3)

# Create embedding
embedder = TaskEmbedding(input_dim=5, output_dim=32)
embedding = embedder.embed(graph)

# MAML with a causal discovery model
from causal_meta.meta_learning.amortized_causal_discovery import AmortizedCausalDiscovery

# Create a model
model = AmortizedCausalDiscovery(...)

# Create MAML wrapper
maml = MAMLForCausalDiscovery(model, inner_lr=0.01)

# Meta-train (simplified example)
maml.meta_train(tasks=task_batch)

# Adapt to a new task
adapted_model = maml.adapt(new_task, n_gradient_steps=5)
```

### AmortizedCBO (`causal_meta.meta_learning.amortized_cbo.AmortizedCBO`)

**Purpose**: Implements Causal Bayesian Optimization using amortized neural components.

**Key Methods**:
- `__init__(model, acquisition_function, **kwargs)`: Constructor
- `optimize(initial_data, budget, **kwargs)`: Run the optimization loop
- `select_intervention(data, graph)`: Select the next intervention
- `update_model(data)`: Update the model with new observations

**Usage Example**:
```python
from causal_meta.meta_learning.amortized_cbo import AmortizedCBO, ExpectedImprovement
from causal_meta.meta_learning.amortized_causal_discovery import AmortizedCausalDiscovery

# Create a model
model = AmortizedCausalDiscovery(...)

# Create acquisition function
acq_func = ExpectedImprovement()

# Create CBO optimizer
cbo = AmortizedCBO(model=model, acquisition_function=acq_func)

# Run optimization
results = cbo.optimize(
    initial_data=initial_data,
    budget=10,
    target_node="Y",
    maximize=True
)
```

### Visualization (`causal_meta.meta_learning.visualization`)

**Purpose**: Provides specialized visualization utilities for neural causal discovery and optimization results, complementing the basic graph visualization utilities in `causal_meta.graph.visualization`.

**Key Functions**:
- `plot_graph_inference_results(true_graph, inferred_graph, **kwargs)`: Visualize comparison between ground truth and inferred causal graphs
- `plot_intervention_outcomes(observational_data, intervention_data, predictions, intervention_targets, **kwargs)`: Visualize intervention effects and model predictions
- `plot_optimization_progress(objective_values, best_values, iterations, **kwargs)`: Track optimization progress over iterations
- `plot_performance_comparison(metrics_dict, comparison_key, **kwargs)`: Compare performance metrics across different methods
- `plot_uncertainty(predictions, uncertainty, **kwargs)`: Visualize predictions with uncertainty estimates

**Usage Example**:
```python
from causal_meta.meta_learning.visualization import (
    plot_graph_inference_results,
    plot_intervention_outcomes,
    plot_optimization_progress,
    plot_performance_comparison,
    plot_uncertainty
)

# Visualize graph inference results
plot_graph_inference_results(
    true_graph=ground_truth_graph,
    inferred_graph=model_inferred_graph,
    title="Causal Discovery Performance"
)

# Visualize intervention outcomes
plot_intervention_outcomes(
    observational_data=obs_data,
    intervention_data=int_data,
    predictions=model_predictions,
    intervention_targets={"X1": 0.5},
    title="Intervention Effects and Predictions"
)

# Track optimization progress
plot_optimization_progress(
    objective_values=obj_history,
    best_values=best_obj_history,
    iterations=range(len(obj_history)),
    title="Optimization Convergence"
)

# Compare methods
metrics = {
    "Method1": {"SHD": 2.3, "F1": 0.85, "Runtime": 10.2},
    "Method2": {"SHD": 1.8, "F1": 0.92, "Runtime": 15.7},
    "Method3": {"SHD": 3.1, "F1": 0.78, "Runtime": 8.5}
}
plot_performance_comparison(
    metrics_dict=metrics,
    comparison_key="F1",
    title="Model Performance Comparison"
)

# Visualize uncertainty
plot_uncertainty(
    predictions=model_preds,
    uncertainty=model_uncertainties,
    title="Predictions with Uncertainty"
)
```

The visualization module integrates with the neural models in the meta_learning package, handling tensor outputs and providing specialized visualizations for neural causal discovery and optimization results. It follows consistent styling and interfaces with the existing visualization utilities in `causal_meta.graph.visualization`.

## Data Generation (`causal_meta.meta_learning.data_generation`)

**Purpose**: Generates synthetic data for training and testing neural causal discovery models.

**Key Classes**:
- `SyntheticDataGenerator`: Generates synthetic data from SCMs

**Key Methods**:
- `generate_observational_data(scm, n_samples)`: Generate observational data
- `generate_interventional_data(scm, interventions, n_samples)`: Generate interventional data
- `create_dataloaders(n_tasks, n_samples_per_task)`: Create PyTorch dataloaders

**Usage Example**:
```python
from causal_meta.meta_learning.data_generation import SyntheticDataGenerator
from causal_meta.graph.generators.factory import GraphFactory

# Create data generator
data_gen = SyntheticDataGenerator(
    num_nodes=5,
    graph_type="random",
    edge_probability=0.3
)

# Generate observational data
obs_data = data_gen.generate_observational_data(n_samples=1000)

# Generate interventional data
int_data = data_gen.generate_interventional_data(
    interventions={"X": 2.0},
    n_samples=1000
)

# Create dataloaders
train_loader, val_loader = data_gen.create_dataloaders(
    n_tasks=100,
    n_samples_per_task=1000,
    batch_size=32
)
```

## Best Practices for Leveraging Components

1. **Understand Existing Components**: Before implementing new code, check this registry to see if a component already exists that meets your needs. This is a **mandatory first step** for all new development.

2. **Consistent Interfaces**: When extending or implementing new components, maintain consistent interfaces with existing ones. Follow the method names, parameter orders, and return types defined in similar existing components.

3. **Use the Higher-Level Abstractions**: Prefer using higher-level abstractions (e.g., `AmortizedCausalDiscovery`) rather than lower-level components (e.g., `GraphEncoder` and `DynamicsDecoder`) when possible. Only implement at a lower level when you need specific customization not available in higher-level components.

4. **Documentation and Examples**: Add clear documentation and examples when implementing new components. Use the format in this registry as a template.

5. **Testing**: Write comprehensive tests for all components to ensure they work as expected. Include tests for normal operation, edge cases, and integration with dependent components.

6. **Integration**: When adding new components, ensure they integrate well with existing ones by preserving interface contracts and data formats expected by dependent components.

7. **Register Your Components**: After implementing a new component, you **must** update this registry to document it. This step is not optional and should be treated as part of the implementation process.

## Common Patterns and Anti-Patterns

### Patterns to Follow

1. **Consistent Data Formats**: Use consistent data formats across components (e.g., PyTorch tensors for neural models, pandas DataFrames for data manipulation).

2. **Clear Component Boundaries**: Define clear interfaces between components to facilitate integration.

3. **Error Handling**: Implement robust error handling with informative error messages.

4. **Configuration Management**: Use configuration objects for complex components to make them more flexible.

5. **Serialization**: Implement save/load methods for all stateful components.

### Anti-Patterns to Avoid

1. **Duplicating Functionality**: Do not reimplement functionality that already exists in the registry.

2. **Inconsistent Naming**: Follow naming conventions consistently (e.g., `get_nodes()` vs. `nodes()`).

3. **Hardcoding Parameters**: Avoid hardcoding parameters that should be configurable.

4. **Mixing Abstraction Levels**: Don't mix high-level and low-level operations in the same component.

5. **Ignoring Tensor Shapes**: Always be explicit about tensor shapes and dimensions, especially in neural network components.

## Component Dependency Graph

Here's a simplified dependency graph showing how the key components relate to each other:

```
CausalGraph
    ↑
    |
StructuralCausalModel
    ↑
    |
  TaskFamily ← TaskFamilyGenerator
    ↑
    |
SyntheticDataGenerator
    ↑
    |
  GraphEncoder       DynamicsDecoder
     ↑  \             /  ↑
     |   \           /   |
     |    \         /    |
     |     AmortizedCausalDiscovery
     |               ↑
  TaskEmbedding      |
     |               |
     |   MAMLForCausalDiscovery
     \       /
      \     /
       \   /
    AmortizedCBO
```

This diagram illustrates the hierarchical relationship between components, helping to understand which components depend on others.

## Contribution Guidelines and Ongoing Maintenance

### When Adding New Components

1. **Check Existing Components First**: Always review this registry before implementing new functionality to avoid duplication.

2. **Follow Existing Patterns**: When creating new components, adhere to the interfaces and patterns of similar existing components. For example, if extending or creating a variant of an existing class, maintain the same method signatures and parameter names where possible.

3. **Update This Registry**: After adding a new component to the codebase, update this registry with:
   - A clear description of the component's purpose
   - The key methods and their parameters
   - Usage examples
   - How it integrates with existing components
   - Where it fits in the component dependency graph

4. **Adhere to Architecture**: Structure your code to align with the existing architecture and dependency relationships shown in the component dependency graph.

5. **Implement Required Interfaces**: Ensure new components implement all interfaces expected by dependent components. Check the higher-level components that will use your new component to understand what interfaces they expect.

### When Modifying Existing Components

1. **Interface Stability**: Maintain backward compatibility where possible. If breaking changes are necessary, document them clearly.

2. **Update Documentation**: Update this registry to reflect any changes to interfaces, parameters, or behavior.

3. **Update Usages**: Ensure all code that depends on the modified component is updated as needed.

### Integration Checklist

Before submitting new or modified code, verify that:

- [ ] You've checked this registry for existing components that might fulfill or partially fulfill your needs
- [ ] Your component follows the naming conventions and interface patterns of similar existing components
- [ ] You've added comprehensive tests for the new/modified component
- [ ] You've updated this registry with appropriate documentation
- [ ] You've verified that dependent components still work with your changes
- [ ] You've added proper error handling and input validation
- [ ] Your code handles tensor shapes and data formats consistently with the rest of the codebase

The repository maintainer should review and approve all updates to this registry to ensure accuracy and consistency. This registry serves as both documentation and a design guide for the entire project.

*Last updated: [Current Date]*

## Table of Contents

- [Benchmark Framework](#benchmark-framework)
- [Causal Discovery](#causal-discovery)
- [Causal Models](#causal-models)
- [Intervention Optimization](#intervention-optimization)
- [Graph Neural Networks](#graph-neural-networks)
- [Meta-Learning Components](#meta-learning-components)
- [Utilities](#utilities)

## Benchmark Framework

### Overview

The benchmarking framework provides comprehensive tools for evaluating and comparing causal discovery and causal Bayesian optimization methods. The framework features:

1. Standard benchmarks for causal discovery and intervention optimization
2. Scalability testing to evaluate performance across different graph sizes
3. Memory and runtime profiling capabilities
4. Result visualization and reporting tools
5. Integration with neural network-based approaches

### Base Benchmark (`causal_meta.meta_learning.benchmark.Benchmark`)

**Purpose**: Abstract base class that defines the common interface for all benchmark implementations.

**Key Methods**:
- `setup()`: Set up the benchmark environment, generating datasets and problems
- `run()`: Run the benchmark on all registered models and baselines
- `add_model(name, model)`: Add a model to be evaluated
- `add_baseline(name, baseline)`: Add a baseline method for comparison
- `evaluate_structure_recovery(true_graph, pred_graph)`: Evaluate graph structure recovery performance
- `evaluate_intervention_prediction(scm, model, interventions)`: Evaluate intervention prediction performance
- `time_performance(callable_fn, *args, **kwargs)`: Measure execution time of a function
- `plot_results(metrics, title, save_path)`: Plot benchmark results
- `save_results(results, filename)`: Save benchmark results to a file
- `load_results(filename)`: Load benchmark results from a file

**Usage Example**:
```python
from causal_meta.meta_learning.benchmark import CausalDiscoveryBenchmark
from my_package import MyCausalDiscoveryModel

# Create a benchmark
benchmark = CausalDiscoveryBenchmark(
    name="my_benchmark",
    output_dir="benchmark_results",
    seed=42,
    num_nodes=10,
    num_graphs=20,
    num_samples=1000
)

# Add models to evaluate
my_model = MyCausalDiscoveryModel()
benchmark.add_model("my_model", my_model)

# Set up and run the benchmark
benchmark.setup()
results = benchmark.run()

# Plot and save results
benchmark.plot_results(
    title="My Benchmark Results",
    save_path="benchmark_results/my_plot.png"
)
```

### CausalDiscoveryBenchmark (`causal_meta.meta_learning.benchmark.CausalDiscoveryBenchmark`)

**Purpose**: Benchmarks causal discovery methods on synthetic graph recovery tasks.

**Key Features**:
- Evaluates how well methods recover graph structures from observational data
- Supports both observational and interventional data
- Measures structural accuracy using SHD, precision, recall, and F1 score
- Tracks runtime and memory usage
- Generates comprehensive reports with aggregated statistics

**Additional Methods**:
- `_evaluate_method(method_name, method)`: Evaluate a single causal discovery method
- `_run_structure_learning(method, obs_data, int_data)`: Run structure learning with proper interface handling
- `_aggregate_results()`: Aggregate results across all datasets and methods

**Usage Example**:
```python
from causal_meta.meta_learning.benchmark import CausalDiscoveryBenchmark
from my_package import MyCausalDiscoveryModel

# Create a benchmark for causal discovery evaluation
benchmark = CausalDiscoveryBenchmark(
    name="causal_discovery_er_10",
    output_dir="benchmark_results",
    seed=42,
    num_nodes=10,  # Evaluate on graphs with 10 nodes
    num_graphs=20,  # Generate 20 different test graphs
    num_samples=1000,  # 1000 samples per dataset
    graph_type="random",  # Use random Erdos-Renyi graphs
    edge_prob=0.3  # Control graph sparsity
)

# Add your causal discovery model
model = MyCausalDiscoveryModel()
benchmark.add_model("my_model", model)

# Set up and run the benchmark
benchmark.setup()
results = benchmark.run()
```

### CBOBenchmark (`causal_meta.meta_learning.benchmark.CBOBenchmark`)

**Purpose**: Benchmarks causal Bayesian optimization methods on synthetic intervention optimization tasks.

**Key Features**:
- Evaluates how well methods optimize interventions in causal systems
- Creates synthetic optimization problems with varying graph structures
- Measures optimization performance, sample efficiency, and computational requirements
- Compares against random baseline for relative improvement
- Tracks runtime and memory usage

**Additional Methods**:
- `_evaluate_method(method_name, method)`: Evaluate a single CBO method
- `_run_optimization(method, graph, scm, obs_data, ...)`: Run optimization with proper interface handling
- `_aggregate_results()`: Aggregate results across all optimization problems

**Usage Example**:
```python
from causal_meta.meta_learning.benchmark import CBOBenchmark
from my_package import MyCBOModel

# Create a benchmark for causal Bayesian optimization
benchmark = CBOBenchmark(
    name="cbo_er_10",
    output_dir="benchmark_results",
    seed=42,
    num_nodes=10,  # Evaluate on graphs with 10 nodes
    num_graphs=10,  # Generate 10 different test problems
    num_samples=1000,  # 1000 samples per dataset
    graph_type="random",  # Use random Erdos-Renyi graphs
    intervention_budget=10  # Allow 10 interventions per optimization
)

# Add your CBO model
model = MyCBOModel()
benchmark.add_model("my_model", model)

# Set up and run the benchmark
benchmark.setup()
results = benchmark.run()
```

### ScalabilityBenchmark (`causal_meta.meta_learning.benchmark.ScalabilityBenchmark`)

**Purpose**: Evaluates how methods scale with increasing graph size, measuring both performance and computational requirements.

**Key Features**:
- Automatically tests on graphs of increasing size
- Measures runtime, memory usage, and accuracy as problem size increases
- Implements curve fitting to identify polynomial or exponential scaling
- Determines computational complexity class of algorithms
- Generates scaling reports with recommendations

**Key Methods**:
- `memory_usage()`: Get current memory usage statistics
- `measure_memory_usage(func, **kwargs)`: Measure the memory usage of a function
- `evaluate_method_scalability(method_name, method)`: Evaluate method scalability
- `analyze_scaling()`: Analyze scaling behavior across all methods
- `plot_scaling_curves(metric, log_scale, save_path)`: Plot scaling curves
- `generate_scaling_report(output_path)`: Generate a comprehensive scaling report

**Usage Example**:
```python
from causal_meta.meta_learning.benchmark import ScalabilityBenchmark
from my_package import MyCausalDiscoveryModel

# Create a scalability benchmark
benchmark = ScalabilityBenchmark(
    name="scalability_benchmark",
    output_dir="benchmark_results",
    seed=42,
    min_nodes=5,  # Start with graphs of size 5
    max_nodes=50,  # Go up to graphs of size 50
    step_size=5,  # Test sizes 5, 10, 15, ..., 50
    num_graphs_per_size=3,  # Generate 3 test problems per size
    measure_mode="both"  # Evaluate both discovery and CBO
)

# Add models to evaluate
model = MyCausalDiscoveryModel()
benchmark.add_model("my_model", model)

# Set up and run the benchmark
benchmark.setup()
results = benchmark.run()

# Generate scaling curves and report
benchmark.plot_scaling_curves(
    metric="runtime",
    log_scale=True,
    save_path="benchmark_results/runtime_scaling.png"
)
report = benchmark.generate_scaling_report(
    output_path="benchmark_results/scaling_report.json"
)
```

### BenchmarkRunner (`causal_meta.meta_learning.benchmark_runner.BenchmarkRunner`)

**Purpose**: Utility class for running multiple benchmarks and aggregating results, making it easy to compare different methods across various tasks.

**Key Methods**:
- `add_benchmark(benchmark)`: Add a benchmark to be run
- `add_model(name, model)`: Add a model to be evaluated in all benchmarks
- `register_model(name, model)`: Alias for add_model (backward compatibility)
- `add_baseline(name, baseline)`: Add a baseline method for comparison
- `run_all()`: Run all registered benchmarks with all registered methods
- `generate_summary_report(output_path)`: Generate a summary report of benchmark results
- `generate_comparison_plots(output_dir)`: Generate comparison plots of results
- `create_standard_suite(...)`: Class method to create a standard benchmark suite
- `create_scalability_suite(...)`: Create a scalability benchmark suite
- `run_scalability_analysis(...)`: Run scalability analysis on a benchmark

**Usage Example**:
```python
from causal_meta.meta_learning.benchmark_runner import BenchmarkRunner
from my_package import MyCausalDiscoveryModel, MyCBOModel

# Create a benchmark runner
runner = BenchmarkRunner(
    name="my_benchmark_run",
    output_dir="benchmark_results",
    seed=42
)

# Add models to evaluate
discovery_model = MyCausalDiscoveryModel()
cbo_model = MyCBOModel()
runner.add_model("my_discovery_model", discovery_model)
runner.add_model("my_cbo_model", cbo_model)

# Create a standard benchmark suite
benchmark_ids = runner.create_standard_suite(
    graph_sizes=[5, 10, 20],
    num_graphs=5,
    num_samples=500
)

# Run all benchmarks
results = runner.run_all()

# Generate summary report
report_path = runner.generate_summary_report()

# Create a scalability suite
scalability_id = runner.create_scalability_suite(
    min_nodes=5,
    max_nodes=30,
    step_size=5
)[0]

# Run scalability analysis
scaling_results = runner.run_scalability_analysis(scalability_id)
```

## Common Benchmark Integration Patterns

### Integration with Neural Methods

Neural-based causal discovery and optimization methods can be evaluated using the same benchmarking framework. The benchmark classes automatically detect and handle different method interfaces.

For AmortizedCausalDiscovery:
```python
from causal_meta.meta_learning.benchmark import CausalDiscoveryBenchmark
from causal_meta.meta_learning.amortized_causal_discovery import AmortizedCausalDiscovery

# Create a neural causal discovery model
model = AmortizedCausalDiscovery(
    graph_encoder_params={...},
    dynamics_decoder_params={...}
)

# Add the model to a benchmark
benchmark = CausalDiscoveryBenchmark(
    name="neural_cd_benchmark",
    num_nodes=10,
    num_graphs=20
)
benchmark.add_model("neural_model", model)

# Run the benchmark
benchmark.setup()
results = benchmark.run()
```

For AmortizedCBO:
```python
from causal_meta.meta_learning.benchmark import CBOBenchmark
from causal_meta.meta_learning.amortized_cbo import AmortizedCBO

# Create a neural CBO model
model = AmortizedCBO(
    acd_model=acd_model,
    acquisition_function="expected_improvement"
)

# Add the model to a benchmark
benchmark = CBOBenchmark(
    name="neural_cbo_benchmark",
    num_nodes=10,
    num_graphs=10
)
benchmark.add_model("neural_cbo", model)

# Run the benchmark
benchmark.setup()
results = benchmark.run()
```

### Custom Model Interfaces

The benchmarking framework supports various model interfaces:

1. Standard interface:
   ```python
   # For discovery: model.learn_graph(obs_data, int_data)
   # For CBO: model.optimize(scm, graph, obs_data, target_node, ...)
   ```

2. Fit-predict interface:
   ```python
   # For discovery: model.fit(obs_data) followed by model.predict_graph()
   ```

3. Callable interface:
   ```python
   # For discovery: model(obs_data) returns a graph or adjacency matrix
   # For CBO: model(scm, graph, obs_data, ...) returns intervention
   ```

4. Neural interfaces:
   ```python
   # AmortizedCausalDiscovery.infer_graph and predict_intervention_outcomes
   # AmortizedCBO.suggest_intervention and get_best_intervention
   ```

## Benchmarking Framework Components

### `Benchmark` (Abstract Base Class)

**Purpose**: Serves as the foundation for all benchmark types, providing common functionality and interfaces.

**Key Features**:
- Abstract interface for benchmark configuration and execution
- Model registration and management
- Result tracking and serialization
- Common visualization and reporting utilities

**Key Methods**:
```python
def add_model(self, name, model, **kwargs)
```
- Registers a model for evaluation
- `name`: String identifier for the model
- `model`: Model instance or callable
- `kwargs`: Additional model-specific parameters

```python
def setup(self)
```
- Prepares the benchmark environment
- Generates test problems, graphs, and datasets
- Must be called before `run()`

```python
def run(self, models=None)
```
- Evaluates all registered models (or specified subset)
- `models`: Optional list of model names to evaluate
- Returns: Dictionary of results by model name

```python
def plot_results(self, metrics=None, **kwargs)
```
- Generates visualization of benchmark results
- `metrics`: List of metrics to include in visualization
- `kwargs`: Additional plotting parameters

```python
def save_results(self, file_path)
```
- Serializes results to disk
- `file_path`: Target path for saved results

**Usage Example**:
```python
benchmark = ConcreteBenchmark(name="example", seed=42)
benchmark.add_model("method1", Method1())
benchmark.add_model("method2", Method2())
benchmark.setup()
results = benchmark.run()
benchmark.plot_results(metrics=["metric1", "metric2"])
benchmark.save_results("results.json")
```

### `CausalDiscoveryBenchmark`

**Purpose**: Evaluates causal discovery/structure learning methods on their ability to recover true graph structure.

**Inheritance**: Extends `Benchmark`

**Parameters**:
- `name`: String identifier for the benchmark
- `seed`: Random seed for reproducibility
- `num_nodes`: Number of nodes in test graphs
- `num_graphs`: Number of test graphs to generate
- `num_samples`: Number of samples per dataset
- `graph_type`: Type of graphs to generate (e.g., "random", "scale-free")
- `edge_prob`: Probability of edge creation (for random graphs)
- `measure_memory`: Whether to track memory usage
- `timeout`: Maximum runtime allowed per method (seconds)

**Key Methods** (in addition to inherited methods):
```python
def add_baseline(self, name, method=None)
```
- Adds a baseline method (e.g., random, true graph)
- `name`: String identifier for the baseline
- `method`: Optional method implementation (if None, uses built-in baselines)

```python
def evaluate_model(self, model, test_case)
```
- Evaluates a single model on a specific test case
- `model`: Model instance to evaluate
- `test_case`: Test case dictionary with graph, data, etc.
- Returns: Dictionary of metrics

```python
def compute_metrics(self, true_graph, pred_graph)
```
- Computes structural metrics between graphs
- `true_graph`: Ground truth causal graph
- `pred_graph`: Predicted causal graph
- Returns: Dictionary of metrics (SHD, precision, recall, etc.)

**Metrics Provided**:
- Structural Hamming Distance (SHD)
- Precision (true edges / predicted edges)
- Recall (true edges / total true edges)
- F1 score (harmonic mean of precision and recall)
- Accuracy (correctly identified edges and non-edges)
- Runtime (seconds)
- Memory usage (if enabled)

**Usage Example**:
```python
# Create benchmark for 10-node graphs
benchmark = CausalDiscoveryBenchmark(
    name="cd_benchmark",
    seed=42,
    num_nodes=10,
    num_graphs=20,
    num_samples=1000,
    graph_type="random",
    edge_prob=0.3
)

# Add models to evaluate
benchmark.add_model("pc_algorithm", PCAlgorithm())
benchmark.add_model("notears", NOTEARS())
benchmark.add_model("neural_discovery", NeuralDiscoveryModel())

# Add baselines
benchmark.add_baseline("random")
benchmark.add_baseline("true_graph")

# Run benchmark
benchmark.setup()
results = benchmark.run()

# Visualize results
benchmark.plot_results(
    metrics=["shd", "precision", "recall"],
    figsize=(12, 8),
    save_path="discovery_results.png"
)
```

### `CBOBenchmark`

**Purpose**: Evaluates causal Bayesian optimization methods on their ability to identify optimal interventions.

**Inheritance**: Extends `Benchmark`

**Parameters**:
- `name`: String identifier for the benchmark
- `seed`: Random seed for reproducibility
- `num_nodes`: Number of nodes in test graphs
- `num_graphs`: Number of test graphs to generate
- `num_samples`: Number of samples per dataset
- `graph_type`: Type of graphs to generate
- `intervention_budget`: Number of interventions allowed
- `maximize`: Whether to maximize or minimize the objective
- `measure_memory`: Whether to track memory usage
- `timeout`: Maximum runtime allowed per method (seconds)

**Key Methods** (in addition to inherited methods):
```python
def add_baseline(self, name, method=None)
```
- Adds a baseline method (e.g., random search, optimal)
- `name`: String identifier for the baseline
- `method`: Optional method implementation (if None, uses built-in baselines)

```python
def evaluate_model(self, model, test_case)
```
- Evaluates a single model on a specific test case
- `model`: Model instance to evaluate
- `test_case`: Test case dictionary with SCM, graph, etc.
- Returns: Dictionary of metrics

```python
def create_objective(self, scm, target_node)
```
- Creates an objective function for optimization
- `scm`: Structural causal model instance
- `target_node`: Target node to optimize
- Returns: Callable objective function

**Metrics Provided**:
- Best value found
- Regret (gap from theoretical optimum)
- Improvement ratio over baseline
- Sample efficiency (value per evaluation)
- Convergence rate
- Runtime (seconds)
- Memory usage (if enabled)

**Usage Example**:
```python
# Create benchmark
benchmark = CBOBenchmark(
    name="cbo_benchmark",
    seed=42,
    num_nodes=10,
    num_graphs=15,
    num_samples=1000,
    graph_type="random",
    intervention_budget=20,
    maximize=True
)

# Add optimization methods
benchmark.add_model("bo_known_graph", BOWithKnownGraph())
benchmark.add_model("bo_unknown_graph", BOWithUnknownGraph())
benchmark.add_model("amortized_cbo", AmortizedCBO())

# Add baselines
benchmark.add_baseline("random_search")
benchmark.add_baseline("optimal")

# Run benchmark
benchmark.setup()
results = benchmark.run()

# Visualize results
benchmark.plot_results(
    metrics=["best_value", "improvement_ratio"],
    figsize=(12, 8),
    save_path="cbo_results.png"
)
```

### `ScalabilityBenchmark`

**Purpose**: Evaluates how methods scale with increasing problem size, measuring runtime, memory usage, and accuracy.

**Inheritance**: Extends `Benchmark`

**Parameters**:
- `name`: String identifier for the benchmark
- `seed`: Random seed for reproducibility
- `min_nodes`: Minimum number of nodes to test
- `max_nodes`: Maximum number of nodes to test
- `step_size`: Increment between node counts
- `num_graphs_per_size`: Number of test graphs per size
- `num_samples`: Number of samples per dataset
- `graph_type`: Type of graphs to generate
- `measure_mode`: What to measure ("discovery", "cbo", or "both")
- `timeout`: Maximum runtime allowed per method (seconds)

**Key Methods** (in addition to inherited methods):
```python
def plot_scaling_curves(self, metric="runtime", log_scale=True, **kwargs)
```
- Plots scaling curves for the specified metric
- `metric`: Metric to visualize scaling for
- `log_scale`: Whether to use logarithmic scale
- `kwargs`: Additional plotting parameters

```python
def generate_scaling_report(self)
```
- Analyzes scaling behavior and generates report
- Returns: Dictionary with scaling analysis for each model

```python
def fit_complexity_model(self, sizes, values)
```
- Fits a complexity model to observed data
- `sizes`: List of problem sizes
- `values`: Corresponding metric values
- Returns: Tuple of (complexity class, parameters)

**Metrics Provided**:
- Runtime scaling
- Memory usage scaling
- Accuracy scaling (SHD or regret)
- Estimated complexity class
- Maximum feasible problem size

**Usage Example**:
```python
# Create scalability benchmark
benchmark = ScalabilityBenchmark(
    name="scalability_benchmark",
    seed=42,
    min_nodes=5,
    max_nodes=50,
    step_size=5,
    num_graphs_per_size=3,
    num_samples=1000,
    graph_type="random",
    measure_mode="discovery"
)

# Add models to evaluate
benchmark.add_model("fast_method", FastMethod())
benchmark.add_model("accurate_method", AccurateMethod())

# Run benchmark
benchmark.setup()
results = benchmark.run()

# Visualize scaling
benchmark.plot_scaling_curves(
    metric="runtime",
    log_scale=True,
    save_path="scaling_curves.png"
)

# Get scaling analysis
scaling_report = benchmark.generate_scaling_report()
```

### `BenchmarkRunner`

**Purpose**: Orchestrates multiple benchmarks, facilitating comprehensive evaluation across different scenarios.

**Key Features**:
- Manages multiple benchmark instances
- Provides standard benchmark suite creation
- Aggregates results across benchmarks
- Generates comparative reports

**Parameters**:
- `name`: String identifier for the benchmark runner
- `seed`: Random seed for reproducibility
- `output_dir`: Directory to save results and reports

**Key Methods**:
```python
def add_model(self, name, model, **kwargs)
```
- Registers a model for evaluation across all benchmarks
- `name`: String identifier for the model
- `model`: Model instance or callable
- `kwargs`: Additional model-specific parameters

```python
def create_benchmark(self, benchmark_type, **kwargs)
```
- Creates a new benchmark instance
- `benchmark_type`: Class or string identifier for benchmark type
- `kwargs`: Parameters for benchmark initialization
- Returns: Benchmark ID

```python
def create_standard_suite(self, graph_sizes=None, **kwargs)
```
- Creates a standard suite of benchmarks
- `graph_sizes`: List of graph sizes to test
- `kwargs`: Additional parameters for benchmarks
- Returns: List of created benchmark IDs

```python
def run_all(self, parallel=False)
```
- Runs all registered benchmarks
- `parallel`: Whether to run benchmarks in parallel
- Returns: Dictionary of results by benchmark ID

```python
def generate_summary_report(self, file_path=None)
```
- Generates a summary report of all benchmark results
- `file_path`: Optional path to save the report
- Returns: Path to the generated report

```python
def compare_models(self, metrics=None, significance_level=0.05)
```
- Performs statistical comparison between models
- `metrics`: List of metrics to compare
- `significance_level`: P-value threshold for significance
- Returns: Dictionary of comparison results

**Usage Example**:
```python
# Create benchmark runner
runner = BenchmarkRunner(
    name="comprehensive_evaluation",
    seed=42,
    output_dir="benchmark_results"
)

# Add models to evaluate in all benchmarks
runner.add_model("method1", Method1())
runner.add_model("method2", Method2())
runner.add_model("neural_method", NeuralMethod())

# Create standard benchmark suite
benchmark_ids = runner.create_standard_suite(
    graph_sizes=[10, 20, 30],
    num_graphs=10,
    num_samples=1000
)

# Run all benchmarks
results = runner.run_all()

# Generate summary report
report_path = runner.generate_summary_report()

# Compare models statistically
comparison = runner.compare_models(
    metrics=["shd", "best_value", "runtime"],
    significance_level=0.05
)
```

### Dependency Graph

The benchmarking framework has the following primary dependencies:

1. **Core Dependencies**:
   - `causal_meta.graph.causal_graph.CausalGraph`: For graph representation
   - `causal_meta.graph.generators.factory.GraphFactory`: For generating test graphs
   - `causal_meta.environments.scm.StructuralCausalModel`: For data generation

2. **Support Dependencies**:
   - Standard libraries: `numpy`, `pandas`, `matplotlib`, `networkx`
   - Performance monitoring: `time`, `resource`, `psutil`
   - Statistical analysis: `scipy.stats`

3. **Optional Integration Points**:
   - `causal_meta.meta_learning.AmortizedCausalDiscovery`: For neural causal discovery
   - `causal_meta.optimization.AmortizedCBO`: For neural intervention optimization

The benchmarking framework is designed to be modular, allowing individual components to be used independently or together as needed.

## Inference Module (`causal_meta.inference`)

### Interfaces (`causal_meta.inference.interfaces`)

**Purpose**: Defines abstract interfaces for causal inference models, establishing consistent contracts that concrete implementations must follow.

**Key Interfaces**:
- `CausalStructureInferenceModel`: Interface for models that infer causal structure from data
- `InterventionOutcomeModel`: Interface for models that predict outcomes of interventions

### Adapters (`causal_meta.inference.adapters`)

**Purpose**: Provides adapter classes that wrap existing model implementations to make them compatible with the interface-based architecture.

#### GraphEncoderAdapter (`causal_meta.inference.adapters.GraphEncoderAdapter`)

**Purpose**: Adapts GraphEncoder components to implement the CausalStructureInferenceModel interface, enabling them to be used with the interface-first architecture.

**Key Methods**:
- `__init__(graph_encoder, threshold=0.5, device=None)`: Constructor
- `infer_structure(data)`: Infers causal structure from data using the wrapped GraphEncoder
- `update_model(data)`: Updates the model with new data
- `estimate_uncertainty()`: Provides uncertainty estimates for the inferred structure

**Usage Example**:
```python
from causal_meta.meta_learning.acd_models import GraphEncoder
from causal_meta.inference.adapters import GraphEncoderAdapter
from causal_meta.inference.interfaces import CausalStructureInferenceModel

# Create a GraphEncoder
encoder = GraphEncoder(hidden_dim=64, attention_heads=2)

# Wrap with adapter to implement the interface
adapter = GraphEncoderAdapter(encoder, threshold=0.5)

# Use through the interface
data = {"observations": observations_data}
causal_graph = adapter.infer_structure(data)

# Get uncertainty estimates
uncertainty = adapter.estimate_uncertainty()
```

#### DynamicsDecoderAdapter (`causal_meta.inference.adapters.DynamicsDecoderAdapter`)

**Purpose**: Adapts DynamicsDecoder components to implement the InterventionOutcomeModel interface.

**Key Features**:
- Implements the InterventionOutcomeModel interface using the DynamicsDecoder from meta_learning
- Supports integration with different UncertaintyEstimator implementations
- Provides standardized uncertainty format for all estimators
- Supports model calibration for better uncertainty estimates
- Handles both built-in and estimator-based uncertainty quantification

**Key Methods**:
- `__init__(dynamics_decoder, uncertainty_estimator=None, return_uncertainty=False, device=None)`: Constructor
- `predict_intervention_outcome(graph, intervention, data, return_uncertainty=None)`: Predicts intervention outcomes
- `update_model(data)`: Updates the model with new data
- `estimate_uncertainty()`: Provides uncertainty estimates for predictions
- `calibrate_uncertainty(validation_data)`: Calibrates uncertainty estimates using validation data

**Usage Example**:
```python
from causal_meta.meta_learning.dynamics_decoder import DynamicsDecoder
from causal_meta.inference.adapters import DynamicsDecoderAdapter
from causal_meta.inference.uncertainty import EnsembleUncertaintyEstimator

# Create a DynamicsDecoder
decoder = DynamicsDecoder(hidden_dim=64, num_layers=2)

# Create an uncertainty estimator
estimator = EnsembleUncertaintyEstimator(num_models=5)

# Wrap with adapter to implement the interface
adapter = DynamicsDecoderAdapter(
    dynamics_decoder=decoder,
    uncertainty_estimator=estimator,
    return_uncertainty=True
)

# Prepare data
graph = inferred_causal_graph
intervention = {"target_node": 3, "value": 2.0}
data = {"observations": observations_data}

# Predict with uncertainty
predictions, uncertainty = adapter.predict_intervention_outcome(graph, intervention, data)

# Calibrate uncertainty estimates with validation data
adapter.calibrate_uncertainty(validation_data)
```

## Acquisition Strategies (`causal_meta.optimization`)

### AcquisitionStrategy (`causal_meta.optimization.interfaces.AcquisitionStrategy`)

**Purpose**: Abstract interface for strategies that select interventions based on acquisition functions in causal Bayesian optimization.

**Key Methods**:
- `compute_acquisition(model, graph, data)`: Computes acquisition values for possible interventions
- `select_intervention(model, graph, data, budget)`: Selects the best intervention given a budget
- `select_batch(model, graph, data, budget, batch_size)`: Selects a batch of diverse interventions

**Usage Example**:
```python
from causal_meta.optimization import ExpectedImprovement
from causal_meta.inference.adapters import DynamicsDecoderAdapter
from causal_meta.graph.causal_graph import CausalGraph

# Create a dynamics model
model = DynamicsDecoderAdapter(...)

# Create a graph
graph = CausalGraph()
# ... add nodes and edges ...

# Create an acquisition strategy
strategy = ExpectedImprovement(exploration_weight=0.1, maximize=True)

# Compute acquisition values for possible interventions
data = {"observations": observations_data}
acq_values = strategy.compute_acquisition(model, graph, data)

# Select the best intervention
intervention = strategy.select_intervention(model, graph, data, budget=1.0)

# Select a batch of diverse interventions
batch = strategy.select_batch(model, graph, data, budget=1.0, batch_size=5)
```

### ExpectedImprovement (`causal_meta.optimization.acquisition.ExpectedImprovement`)

**Purpose**: Implements the AcquisitionStrategy interface using Expected Improvement, which balances exploitation (high predicted mean) and exploration (high uncertainty).

**Key Methods**:
- `__init__(exploration_weight=0.01, maximize=True, intervention_candidates=None)`: Constructor
- `compute_acquisition(model, graph, data)`: Computes EI values for interventions
- `select_intervention(model, graph, data, budget)`: Selects intervention with highest EI
- `select_batch(model, graph, data, budget, batch_size)`: Selects diverse batch using EI
- `set_best_value(value)`: Sets the current best known value for improvement calculation

**Usage Example**:
```python
from causal_meta.optimization import ExpectedImprovement

# Create strategy (maximize objective)
strategy = ExpectedImprovement(
    exploration_weight=0.1,  # Control exploration vs exploitation
    maximize=True  # Whether to maximize or minimize the objective
)

# Set current best observed value (if known)
strategy.set_best_value(current_best)

# Select intervention
intervention = strategy.select_intervention(model, graph, data, budget=1.0)
```

### UpperConfidenceBound (`causal_meta.optimization.acquisition.UpperConfidenceBound`) 

**Purpose**: Implements the AcquisitionStrategy interface using Upper Confidence Bound, which balances exploration and exploitation using a weighted sum of mean and uncertainty.

**Key Methods**:
- `__init__(beta=2.0, maximize=True, intervention_candidates=None)`: Constructor
- `compute_acquisition(model, graph, data)`: Computes UCB values for interventions
- `select_intervention(model, graph, data, budget)`: Selects intervention with highest UCB
- `select_batch(model, graph, data, budget, batch_size)`: Selects diverse batch using UCB

**Usage Example**:
```python
from causal_meta.optimization import UpperConfidenceBound

# Create strategy
strategy = UpperConfidenceBound(
    beta=2.0,  # Higher beta increases exploration
    maximize=True  # Whether to maximize or minimize the objective
)

# Select intervention
intervention = strategy.select_intervention(model, graph, data, budget=1.0)
```

## Integration with Causal Bayesian Optimization

The acquisition strategies can be used with the AmortizedCausalOptimizer to perform causal Bayesian optimization:

```python
from causal_meta.optimization import ExpectedImprovement
from causal_meta.meta_learning.amortized_causal_discovery import AmortizedCausalDiscovery
from causal_meta.meta_learning.amortized_cbo import AmortizedCBO

# Create causal discovery model
acd_model = AmortizedCausalDiscovery(...)

# Create acquisition strategy
acquisition = ExpectedImprovement(exploration_weight=0.1)

# Create optimizer
optimizer = AmortizedCBO(
    model=acd_model,
    acquisition_function=acquisition
)

# Run optimization
results = optimizer.optimize(
    x=data,
    objective_fn=objective_function,
    max_iterations=10
)
```

### Non-GNN Structure Inference Models (`causal_meta.inference.models`)

#### MLPGraphEncoder (`causal_meta.inference.models.mlp_encoder.MLPGraphEncoder`)

**Purpose**: Implements a Multi-Layer Perceptron (MLP) based approach for causal structure inference from time series data, without using Graph Neural Networks.

**Key Methods**:
- `__init__(input_dim, hidden_dim=64, num_layers=3, dropout=0.1, sparsity_weight=0.1, acyclicity_weight=1.0, seq_length=10)`: Constructor
- `forward(x)`: Forward pass to process time series data and predict edge probabilities
- `predict_graph_from_data(data, threshold=0.5)`: Predict a causal graph from time series data
- `to_causal_graph(edge_probs, threshold=0.5)`: Convert edge probabilities to a CausalGraph

**Usage Example**:
```python
from causal_meta.inference.models import MLPGraphEncoder
from causal_meta.inference.adapters import MLPGraphEncoderAdapter

# Create the model
model = MLPGraphEncoder(
    input_dim=5,  # Number of variables
    hidden_dim=64,
    num_layers=3,
    seq_length=20
)

# Use an adapter to comply with the CausalStructureInferenceModel interface
adapter = MLPGraphEncoderAdapter(model)

# Prepare data
data = {"observations": observed_time_series}  # Shape: [batch_size, seq_length, n_variables]

# Infer causal structure
graph = adapter.infer_structure(data)
```

#### TransformerGraphEncoder (`causal_meta.inference.models.transformer_encoder.TransformerGraphEncoder`)

**Purpose**: Implements a Transformer-based approach for causal structure inference from time series data, leveraging self-attention mechanisms to capture temporal dependencies.

**Key Methods**:
- `__init__(input_dim, hidden_dim=64, num_heads=4, num_layers=2, dropout=0.1, sparsity_weight=0.1, acyclicity_weight=1.0)`: Constructor
- `forward(x)`: Forward pass to process time series data and predict edge probabilities
- `predict_graph_from_data(data, threshold=0.5)`: Predict a causal graph from time series data
- `to_causal_graph(edge_probs, threshold=0.5)`: Convert edge probabilities to a CausalGraph

**Usage Example**:
```python
from causal_meta.inference.models import TransformerGraphEncoder
from causal_meta.inference.adapters import TransformerGraphEncoderAdapter

# Create the model
model = TransformerGraphEncoder(
    input_dim=5,  # Number of variables
    hidden_dim=64,
    num_heads=4,
    num_layers=2
)

# Use an adapter to comply with the CausalStructureInferenceModel interface
adapter = TransformerGraphEncoderAdapter(model)

# Prepare data
data = {"observations": observed_time_series}  # Shape: [batch_size, seq_length, n_variables]

# Infer causal structure
graph = adapter.infer_structure(data)
```

### Non-GNN Adapters (`causal_meta.inference.adapters`)

#### MLPGraphEncoderAdapter (`causal_meta.inference.adapters.MLPGraphEncoderAdapter`)

**Purpose**: Adapts MLP-based graph encoder models to implement the `CausalStructureInferenceModel` interface.

**Key Methods**:
- `__init__(model, device=None)`: Constructor
- `infer_structure(data)`: Infers causal structure from data
- `update_model(data)`: Updates the model with new data
- `estimate_uncertainty()`: Provides uncertainty estimates for inferred structures

**Usage Example**:
```python
from causal_meta.inference.models import MLPGraphEncoder
from causal_meta.inference.adapters import MLPGraphEncoderAdapter

# Create MLP-based encoder
encoder = MLPGraphEncoder(
    input_dim=5,  # Number of variables
    hidden_dim=64,
    num_layers=3
)

# Wrap with adapter
adapter = MLPGraphEncoderAdapter(encoder)

# Use through the interface
data = {"observations": observed_time_series}
causal_graph = adapter.infer_structure(data)

# Get uncertainty estimates
uncertainty = adapter.estimate_uncertainty()
```

#### TransformerGraphEncoderAdapter (`causal_meta.inference.adapters.TransformerGraphEncoderAdapter`)

**Purpose**: Adapts Transformer-based graph encoder models to implement the `CausalStructureInferenceModel` interface.

**Key Methods**:
- `__init__(model, device=None)`: Constructor
- `infer_structure(data)`: Infers causal structure from data
- `update_model(data)`: Updates the model with new data
- `estimate_uncertainty()`: Provides uncertainty estimates for inferred structures

**Usage Example**:
```python
from causal_meta.inference.models import TransformerGraphEncoder
from causal_meta.inference.adapters import TransformerGraphEncoderAdapter

# Create Transformer-based encoder
encoder = TransformerGraphEncoder(
    input_dim=5,  # Number of variables
    hidden_dim=64,
    num_heads=4,
    num_layers=2
)

# Wrap with adapter
adapter = TransformerGraphEncoderAdapter(encoder)

# Use through the interface
data = {"observations": observed_time_series}
causal_graph = adapter.infer_structure(data)

# Get uncertainty estimates
uncertainty = adapter.estimate_uncertainty()
```

### Base Encoder Classes (`causal_meta.inference.models.base_encoder`)

#### MLPBaseEncoder (`causal_meta.inference.models.base_encoder.MLPBaseEncoder`)

**Purpose**: Base class for MLP-based structure inference models, providing common functionality for network construction and regularization.

**Key Methods**:
- `__init__(input_dim, hidden_dim=64, num_layers=3, dropout=0.1, sparsity_weight=0.1, acyclicity_weight=1.0)`: Constructor
- `_build_mlp(input_dim, hidden_dim, output_dim, num_layers)`: Builds an MLP with specified dimensions
- `calculate_acyclicity_regularization(edge_probs)`: Calculates acyclicity regularization term
- `calculate_sparsity_regularization(edge_probs)`: Calculates sparsity regularization term
- `calculate_loss(edge_probs, target=None, mask=None)`: Calculates total loss with regularization terms

#### TransformerBaseEncoder (`causal_meta.inference.models.base_encoder.TransformerBaseEncoder`)

**Purpose**: Base class for Transformer-based structure inference models, providing common functionality for transformer construction and regularization.

**Key Methods**:
- `__init__(input_dim, hidden_dim=64, num_heads=4, num_layers=2, dropout=0.1, sparsity_weight=0.1, acyclicity_weight=1.0)`: Constructor
- `_generate_positional_encoding(max_seq_len, hidden_dim)`: Generates positional encodings for transformer
- `_build_transformer_layer(hidden_dim, num_heads, dropout)`: Builds a transformer encoder layer
- `calculate_acyclicity_regularization(edge_probs)`: Calculates acyclicity regularization term
- `calculate_sparsity_regularization(edge_probs)`: Calculates sparsity regularization term
- `calculate_loss(edge_probs, target=None, mask=None)`: Calculates total loss with regularization terms

## Uncertainty Estimation (`causal_meta.inference.uncertainty`)

### UncertaintyEstimator (`causal_meta.inference.uncertainty.UncertaintyEstimator`)

**Purpose**: Abstract interface for uncertainty estimation in causal inference models. This interface defines the contract for components that estimate uncertainty in model predictions or inferred structures.

**Key Methods**:
- `estimate_uncertainty(model, data)`: Estimates uncertainty in model predictions or inferred structures.
- `calibrate(model, validation_data)`: Calibrates uncertainty estimates using validation data.

**Usage Example**:
```python
from causal_meta.inference.uncertainty import EnsembleUncertaintyEstimator
from causal_meta.inference.adapters import GraphEncoderAdapter
from causal_meta.meta_learning.acd_models import GraphEncoder

# Create a model
encoder = GraphEncoder(hidden_dim=64, attention_heads=2)
model = GraphEncoderAdapter(encoder)

# Create an uncertainty estimator
estimator = EnsembleUncertaintyEstimator(num_models=5)

# Prepare data
data = {"observations": observations_data}
validation_data = {"observations": validation_observations}

# Calibrate the estimator
estimator.calibrate(model, validation_data)

# Estimate uncertainty
uncertainty = estimator.estimate_uncertainty(model, data)
```

### EnsembleUncertaintyEstimator (`causal_meta.inference.uncertainty.EnsembleUncertaintyEstimator`)

**Purpose**: Estimates uncertainty using ensemble methods. This implementation uses an ensemble of models to estimate uncertainty. The variance of predictions across different models in the ensemble provides an estimate of uncertainty.

**Key Methods**:
- `__init__(num_models=5, aggregation_method='mean')`: Constructor.
- `estimate_uncertainty(model, data)`: Estimates uncertainty using ensemble variance.
- `calibrate(model, validation_data)`: Calibrates ensemble uncertainty estimates.

**Usage Example**:
```python
from causal_meta.inference.uncertainty import EnsembleUncertaintyEstimator

# Create an ensemble uncertainty estimator
estimator = EnsembleUncertaintyEstimator(
    num_models=5,
    aggregation_method='mean'
)

# Use with a model to estimate uncertainty
uncertainty = estimator.estimate_uncertainty(model, data)
```

### DropoutUncertaintyEstimator (`causal_meta.inference.uncertainty.DropoutUncertaintyEstimator`)

**Purpose**: Estimates uncertainty using Monte Carlo dropout. This implementation uses MC dropout to estimate model uncertainty. By performing multiple forward passes with dropout enabled, it approximates a Bayesian posterior distribution over predictions.

**Key Methods**:
- `__init__(num_samples=30, dropout_rate=None)`: Constructor.
- `estimate_uncertainty(model, data)`: Estimates uncertainty using Monte Carlo dropout.
- `calibrate(model, validation_data)`: Calibrates MC dropout uncertainty estimates.

**Usage Example**:
```python
from causal_meta.inference.uncertainty import DropoutUncertaintyEstimator

# Create a dropout uncertainty estimator
estimator = DropoutUncertaintyEstimator(
    num_samples=30,
    dropout_rate=0.1
)

# Use with a model to estimate uncertainty
uncertainty = estimator.estimate_uncertainty(model, data)
```

### DirectUncertaintyEstimator (`causal_meta.inference.uncertainty.DirectUncertaintyEstimator`)

**Purpose**: Uses model's direct uncertainty outputs. This implementation is for models that directly provide uncertainty estimates as part of their output. It simply extracts and possibly calibrates these direct uncertainty estimates.

**Key Methods**:
- `__init__(scale_factor=1.0)`: Constructor.
- `estimate_uncertainty(model, data)`: Extracts and scales direct uncertainty estimates.
- `calibrate(model, validation_data)`: Calibrates direct uncertainty estimates.

**Usage Example**:
```python
from causal_meta.inference.uncertainty import DirectUncertaintyEstimator

# Create a direct uncertainty estimator
estimator = DirectUncertaintyEstimator(scale_factor=1.2)

# Use with a model to estimate uncertainty
uncertainty = estimator.estimate_uncertainty(model, data)
```

### ConformalUncertaintyEstimator (`causal_meta.inference.uncertainty.ConformalUncertaintyEstimator`)

**Purpose**: Estimates uncertainty using conformal prediction. This implementation uses distribution-free conformal prediction methods to provide rigorous uncertainty estimates with statistical guarantees.

**Key Methods**:
- `__init__(alpha=0.05, method='naive')`: Constructor.
- `estimate_uncertainty(model, data)`: Estimates uncertainty using conformal prediction.
- `calibrate(model, validation_data)`: Calibrates the conformal predictor using validation data.

**Usage Example**:
```python
from causal_meta.inference.uncertainty import ConformalUncertaintyEstimator

# Create a conformal uncertainty estimator
estimator = ConformalUncertaintyEstimator(
    alpha=0.05,  # 95% confidence
    method='naive'
)

# Calibrate the estimator (required before use)
estimator.calibrate(model, validation_data)

# Use with a model to estimate uncertainty
uncertainty = estimator.estimate_uncertainty(model, data)
```

## Common Patterns for Uncertainty Estimation

1. **Selecting an Appropriate Estimator**:
   - Use `EnsembleUncertaintyEstimator` when you can train multiple models or generate samples from the model.
   - Use `DropoutUncertaintyEstimator` with models that include dropout layers.
   - Use `DirectUncertaintyEstimator` with models that directly output uncertainty (e.g., Bayesian neural networks).
   - Use `ConformalUncertaintyEstimator` when you need rigorous statistical guarantees.

2. **Integration with Models**:
   ```python
   # Example integration with a structure inference model
   from causal_meta.inference.adapters import GraphEncoderAdapter
   from causal_meta.inference.uncertainty import EnsembleUncertaintyEstimator
   
   # Create and train a model
   model = GraphEncoderAdapter(...)
   
   # Create an uncertainty estimator
   estimator = EnsembleUncertaintyEstimator(num_models=5)
   
   # Calibrate the estimator
   estimator.calibrate(model, validation_data)
   
   # Use the estimator with new data
   uncertainty = estimator.estimate_uncertainty(model, new_data)
   
   # Extract specific uncertainty metrics
   edge_probabilities = uncertainty.get("edge_probabilities")
   confidence_intervals = uncertainty.get("confidence_intervals")
   ```

3. **Visualization**:
   ```python
   # Example visualization of uncertainty
   import matplotlib.pyplot as plt
   import numpy as np
   
   # Get uncertainty estimates
   uncertainty = estimator.estimate_uncertainty(model, data)
   
   # Plot edge probabilities with confidence intervals
   edge_probs = uncertainty["edge_probabilities"]
   conf_intervals = uncertainty.get("confidence_intervals", {})
   lower_bounds = conf_intervals.get("lower", edge_probs - 0.1)
   upper_bounds = conf_intervals.get("upper", edge_probs + 0.1)
   
   plt.figure(figsize=(10, 6))
   plt.imshow(edge_probs, cmap='viridis')
   plt.colorbar(label='Edge Probability')
   plt.title('Causal Graph Edge Probabilities with Uncertainty')
   plt.xlabel('Target Node')
   plt.ylabel('Source Node')
   ```

### Updatable Interface (`causal_meta.inference.interfaces.Updatable`)

**Purpose**: Defines the contract for models that can be updated with new data. This interface enables components to implement different update strategies such as incremental updates, experience replay, or full retraining.

**Key Methods**:
- `update(data)`: Updates the model with new data, returns success indicator
- `reset()`: Resets the model to its initial state

**Usage Example**:
```python
from causal_meta.inference.interfaces import Updatable
import numpy as np

# Assume we have a model that implements the Updatable interface
class SimpleUpdatableModel(Updatable):
    def __init__(self):
        self.data = None
        self.updates_count = 0
        self.reset()
    
    def update(self, data):
        # Implement incremental updates
        self.data = data
        self.updates_count += 1
        print(f"Model updated ({self.updates_count} updates so far)")
        return True
    
    def reset(self):
        # Reset to initial state
        self.data = None
        self.updates_count = 0
        print("Model reset to initial state")

# Create the model
model = SimpleUpdatableModel()

# Update with data
mock_data = {"observations": np.random.randn(100, 5)}
success = model.update(mock_data)

# Update again with new data
new_data = {"observations": np.random.randn(50, 5)}
success = model.update(new_data)

# Reset the model
model.reset()
```

### UncertaintyEstimator Interface (`causal_meta.inference.uncertainty.UncertaintyEstimator`)

**Purpose**: Defines the contract for components that estimate uncertainty in model predictions or inferred structures. This interface enables flexible uncertainty quantification that can work with different model types.

**Key Methods**:
- `estimate_uncertainty(model, data)`: Estimates uncertainty in model outputs
- `calibrate(model, validation_data)`: Calibrates uncertainty estimates using validation data

**Implementations**:
- `EnsembleUncertaintyEstimator`: Uses ensemble methods for uncertainty estimation
- `DropoutUncertaintyEstimator`: Uses Monte Carlo dropout for uncertainty estimation
- `DirectUncertaintyEstimator`: For models that directly predict variance
- `ConformalUncertaintyEstimator`: Uses conformal prediction methods

**Usage Example**:
```python
from causal_meta.inference.uncertainty import EnsembleUncertaintyEstimator
import numpy as np

# Create an uncertainty estimator
estimator = EnsembleUncertaintyEstimator(num_models=5)

# Assume we have a model and data
model = MyModel(...)
data = {"observations": np.random.randn(100, 5)}

# Estimate uncertainty
uncertainty = estimator.estimate_uncertainty(model, data)

# Calibrate using validation data
validation_data = {"observations": np.random.randn(200, 5)}
estimator.calibrate(model, validation_data)
```

## Causal Graph Structure Learning MVP Components

The following components are designed specifically for the Causal Graph Structure Learning MVP, implementing a simplified approach to demonstrate neural network-based causal structure learning through interventional data.

### SimpleGraphLearner (`causal_meta.structure_learning.simple_graph_learner.SimpleGraphLearner`)

**Purpose**: Simple MLP-based neural network for learning causal graph structure from observational and interventional data.

**Key Methods**:
- `__init__(num_nodes, hidden_dim=64)`: Constructor for the model
- `forward(x, intervention_mask)`: Forward pass with explicit intervention information
- `compute_loss(pred_adj, true_adj=None)`: Compute loss with optional supervision
- `predict_graph(data, intervention_mask, threshold=0.5)`: Predict binary adjacency matrix

**Usage Example**:
```python
from causal_meta.structure_learning.simple_graph_learner import SimpleGraphLearner

# Create model
model = SimpleGraphLearner(num_nodes=5, hidden_dim=64)

# Prepare data
data = torch.randn(32, 5)  # 32 samples, 5 nodes
int_mask = torch.zeros(32, 5)  # No interventions initially
int_mask[:, 2] = 1.0  # Intervene on node 2

# Forward pass
pred_adj = model(data, int_mask)

# Compute loss (unsupervised)
loss = model.compute_loss(pred_adj)

# Predict binary graph
binary_adj = model.predict_graph(data, int_mask, threshold=0.5)
```

### RandomDAGGenerator (`causal_meta.structure_learning.graph_generators.RandomDAGGenerator`)

**Purpose**: Generates random Directed Acyclic Graphs (DAGs) for experimentation.

**Key Methods**:
- `generate_random_dag(num_nodes, edge_probability)`: Generate a random DAG
- `validate_acyclicity(adj_matrix)`: Check if a given adjacency matrix represents a DAG
- `visualize_dag(adj_matrix)`: Visualize a DAG from its adjacency matrix

**Usage Example**:
```python
from causal_meta.structure_learning.graph_generators import RandomDAGGenerator

# Generate random DAG
adj_matrix = RandomDAGGenerator.generate_random_dag(
    num_nodes=8,
    edge_probability=0.3
)

# Validate acyclicity
is_dag = RandomDAGGenerator.validate_acyclicity(adj_matrix)

# Visualize
RandomDAGGenerator.visualize_dag(adj_matrix)
```

### LinearSCMGenerator (`causal_meta.structure_learning.scm_generators.LinearSCMGenerator`)

**Purpose**: Creates linear Structural Causal Models (SCMs) based on a given graph structure.

**Key Methods**:
- `generate_linear_scm(adj_matrix, noise_scale=0.1)`: Generate a linear SCM
- `generate_linear_weights(adj_matrix, min_weight=-2, max_weight=2)`: Generate random weights for connections
- `add_noise_distributions(scm, noise_scale=0.1)`: Add Gaussian noise distributions to the SCM

**Usage Example**:
```python
from causal_meta.structure_learning.graph_generators import RandomDAGGenerator
from causal_meta.structure_learning.scm_generators import LinearSCMGenerator

# Generate random DAG
adj_matrix = RandomDAGGenerator.generate_random_dag(
    num_nodes=5,
    edge_probability=0.3
)

# Create linear SCM
scm = LinearSCMGenerator.generate_linear_scm(
    adj_matrix=adj_matrix,
    noise_scale=0.1
)

# Sample data
obs_data = scm.sample_data(sample_size=200)
```

### InterventionUtils (`causal_meta.structure_learning.intervention_utils.InterventionUtils`)

**Purpose**: Utilities for performing and tracking interventions.

**Key Methods**:
- `perform_random_intervention(scm, num_samples, node_idx=None)`: Perform random intervention
- `convert_to_tensor(data, device="cpu")`: Convert data to tensor
- `create_intervention_mask(num_samples, num_nodes, intervened_node)`: Create binary intervention mask

**Usage Example**:
```python
from causal_meta.structure_learning.intervention_utils import InterventionUtils

# Perform random intervention
int_data, intervened_node = InterventionUtils.perform_random_intervention(
    scm=scm,
    num_samples=20
)

# Create intervention mask
int_mask = InterventionUtils.create_intervention_mask(
    num_samples=20,
    num_nodes=5,
    intervened_node=intervened_node
)

# Convert to tensor
int_tensor = InterventionUtils.convert_to_tensor(int_data)
```

### ExperimentRunner (`causal_meta.structure_learning.experiment_runner.ExperimentRunner`)

**Purpose**: Manages the main experiment loop for progressive causal structure learning.

**Key Methods**:
- `run_experiment(config)`: Run the main experiment
- `train_step(model, optimizer, data, intervention_mask, true_adj)`: Perform training step
- `evaluate_graph(pred_adj, true_adj, threshold=0.5)`: Evaluate predictions
- `plot_results(true_adj, final_adj, history)`: Plot experiment results

**Usage Example**:
```python
from causal_meta.structure_learning.experiment_runner import ExperimentRunner
from causal_meta.structure_learning.config import ExperimentConfig

# Define configuration
config = ExperimentConfig(
    num_nodes=8,
    edge_probability=0.3,
    num_obs_samples=200,
    num_int_samples=20,
    max_iterations=50,
    hidden_dim=64,
    learning_rate=0.001,
    noise_scale=0.1,
    random_seed=42
)

# Run experiment
history, model, true_adj = ExperimentRunner.run_experiment(config)
```

### ExperimentConfig (`causal_meta.structure_learning.config.ExperimentConfig`)

**Purpose**: Configuration class for experiment parameters.

**Key Attributes**:
- `num_nodes`: Number of nodes in the causal graph
- `edge_probability`: Probability of edge between any two nodes
- `num_obs_samples`: Number of observational samples
- `num_int_samples`: Number of interventional samples per intervention
- `max_iterations`: Maximum number of interventions
- `hidden_dim`: Hidden dimension size for neural network
- `learning_rate`: Learning rate for optimizer
- `noise_scale`: Noise scale for linear SCM
- `random_seed`: Random seed for reproducibility

**Usage Example**:
```python
from causal_meta.structure_learning.config import ExperimentConfig

# Create configuration
config = ExperimentConfig(
    num_nodes=8,
    edge_probability=0.3,
    num_obs_samples=200,
    num_int_samples=20,
    max_iterations=50,
    hidden_dim=64,
    learning_rate=0.001,
    noise_scale=0.1,
    random_seed=42
)

# Access parameters
print(f"Number of nodes: {config.num_nodes}")
print(f"Learning rate: {config.learning_rate}")
```

### GraphMetrics (`causal_meta.structure_learning.metrics.GraphMetrics`)

**Purpose**: Metrics and evaluation utilities for causal graph structure learning.

**Key Methods**:
- `calculate_shd(pred_adj, true_adj)`: Calculate Structural Hamming Distance
- `calculate_edge_accuracy(pred_adj, true_adj)`: Calculate edge prediction accuracy
- `calculate_precision_recall(pred_adj, true_adj)`: Calculate precision and recall
- `calculate_metrics(pred_adj, true_adj)`: Calculate all metrics

**Usage Example**:
```python
from causal_meta.structure_learning.metrics import GraphMetrics

# Calculate metrics
metrics = GraphMetrics.calculate_metrics(pred_adj, true_adj)

print(f"SHD: {metrics['shd']}")
print(f"Accuracy: {metrics['accuracy']}")
print(f"Precision: {metrics['precision']}")
print(f"Recall: {metrics['recall']}")
```

## Important Note on MVP Components

The components described in this section follow a simplified design specifically for the MVP demonstration. They are intended to show the core concept of learning causal structure from interventional data using neural networks.

When implementing these components:

1. **Validate interfaces** against existing components in the `causal_meta` package
2. **Reuse existing code** where appropriate, particularly from the `graph`, `environments`, and `meta_learning` modules
3. **Ensure compatibility** with the broader codebase architecture
4. **Follow naming conventions** and design patterns established in the existing codebase
5. **Document clearly** how these components fit with the existing architecture

These MVP components provide a foundation that can be extended with more sophisticated approaches in future iterations.