<PRD>

# Technical Architecture

## System Components

The Meta-Learning CBO system is structured around the following core components:

```
├── causal_meta/
│   ├── graph/                  # Graph data structures and operations
│   │   ├── base.py             # Base graph classes
│   │   ├── directed_graph.py   # Directed graph implementation
│   │   ├── causal_graph.py     # Causal graph with SCM capabilities
│   │   ├── visualization.py    # Graph visualization utilities
│   │   └── generators/         # Graph generation factory
│   │       ├── factory.py      # Main graph generation factory
│   │       ├── random_graphs.py # Random graph generators
│   │       ├── scale_free.py   # Scale-free network generators
│   │       ├── predefined.py   # Predefined graph structures
│   │       ├── task_families.py # Generate families of related graphs
│   │       └── utils.py        # Generator utilities
│   │
│   ├── environments/           # Causal environments and models
│   │   ├── base.py             # Base environment interface
│   │   ├── scm.py              # Structural Causal Model implementations
│   │   ├── mechanisms.py       # Causal mechanism implementations
│   │   ├── interventions.py    # Intervention types and handlers
│   │   └── samplers.py         # Data sampling from environments
│   │
│   ├── discovery/              # Causal discovery algorithms
│   │   ├── base.py             # Base discovery interface
│   │   ├── neural.py           # Neural network-based discovery models
│   │   ├── amortized.py        # Amortized causal discovery methods
│   │   └── evaluation.py       # Metrics for evaluating discovered structures
│   │
│   ├── optimization/           # Optimization components
│   │   ├── base.py             # Base optimization interface
│   │   ├── acquisition.py      # Acquisition functions
│   │   ├── surrogate.py        # Surrogate models
│   │   ├── bayesian_opt.py     # Bayesian optimization
│   │   └── causal_bo.py        # Causal Bayesian optimization
│   │
│   ├── meta_learning/          # Meta-learning components
│   │   ├── base.py             # Base meta-learning interface
│   │   ├── maml.py             # Model-Agnostic Meta-Learning implementation
│   │   ├── task_representation.py # Task encoding and representation
│   │   ├── adaptation.py       # Fast adaptation mechanisms
│   │   ├── meta_cbo.py         # Meta-learning CBO implementation
│   │   ├── task_embeddings.py  # Task context embeddings
│   │   ├── graph_prototypes.py # Graph prototype learning
│   │   └── transfer.py         # Cross-task transfer mechanisms
│   │
│   ├── inference/              # Inference models and methods
│   │   ├── models/
│   │   │   ├── encoder.py      # Graph/task encoders
│   │   │   ├── decoder.py      # Graph decoders
│   │   │   ├── gnn.py          # Graph Neural Network models
│   │   │   └── posterior.py    # Amortized posterior inference models
│   │   └── training/
│   │       ├── losses.py       # Loss functions
│   │       ├── trainer.py      # Training utilities
│   │       └── metrics.py      # Performance metrics
│   │
│   └── utils/                  # Helper functions
│
├── configs/                    # Configuration files
├── experiments/                # Experiment runners and scripts
├── examples/                   # Usage examples
├── tests/                      # Test suite
└── notebooks/                  # Jupyter notebooks for demonstrations
```

## Data Models

### Graph Models
- **Base Graph**: Foundation for all graph implementations
- **Directed Graph**: Implementation of a directed graph with adjacency matrix
- **Causal Graph**: Extension of directed graph with causal semantics
- **Graph Factory**: Creates different graph types (random, scale-free, predefined)

### Environment Models
- **Base Environment**: Interface for causal environments
- **SCM**: Implementation of structural causal models
- **Mechanisms**: Different causal mechanism types (linear, nonlinear, neural)
- **Interventions**: Different intervention types (perfect, imperfect, soft)

### Neural Models
- **GNN Encoder**: Encodes graph structure into latent representations
- **Graph Decoder**: Reconstructs graph structure from latent space
- **Posterior Network**: Amortized inference of causal structure
- **Surrogate Model**: Neural approximation of intervention outcomes

### Meta-Learning Models
- **Task Representation**: Embeds tasks into a common representation space
- **Adaptation Network**: Fast adaptation from meta-learned parameters
- **Graph Prototypes**: Learns prototypical graph structures for transfer

## Infrastructure Requirements
- Python 3.8+ environment
- PyTorch for neural network components
- NetworkX for graph manipulation
- NumPy and SciPy for numerical computations
- Matplotlib for visualization

# Development Roadmap

## Phase 1: Foundation Development
1. **Clean Repository Structure**
   - Remove Jean-specific remnants from codebase
   - Set up new directory structure
   - Implement configuration system

2. **Core Graph Module**
   - Implement base graph classes
   - Create directed graph implementation
   - Develop causal graph extension
   - Build graph visualization utilities

3. **Graph Generation Factory**
   - Implement factory pattern for graph creation
   - Create random graph generators
   - Develop task family generation capability
   - Add predefined graph structures

4. **Causal Environment Module**
   - Create environment interface
   - Implement SCM functionality
   - Develop intervention handlers
   - Build data sampling utilities

## Phase 2: Algorithm Implementation
1. **Discovery Module**
   - Implement neural discovery models
   - Create amortized discovery methods
   - Build evaluation metrics

2. **Optimization Module**
   - Implement base optimization interface
   - Create acquisition functions
   - Develop surrogate models
   - Build Bayesian and Causal BO implementations

3. **Neural Network Components**
   - Implement GNN-based encoders
   - Create graph decoders
   - Build posterior inference networks
   - Develop training infrastructure

## Phase 3: Meta-Learning Integration
1. **Meta-Learning Core**
   - Implement MAML framework
   - Create task representation models
   - Develop fast adaptation mechanisms

2. **Meta-CBO Implementation**
   - Combine meta-learning with CBO
   - Implement task context embeddings
   - Create graph prototype learning
   - Build cross-task transfer mechanisms

## Phase 4: Integration and Testing
1. **System Integration**
   - Connect all components into cohesive pipeline
   - Implement full Meta-CBO algorithm
   - Create backward compatibility wrappers

2. **Testing Infrastructure**
   - Develop comprehensive test suite
   - Create component-specific tests
   - Set up CI/CD pipeline

3. **Example Development**
   - Create synthetic graph generation examples
   - Implement intervention-based discovery examples
   - Build full Meta-CBO demonstrations

## Phase 5: Documentation and Optimization
1. **Code Documentation**
   - Add comprehensive docstrings
   - Implement type hints
   - Set up automatic API documentation

2. **User Documentation**
   - Create getting started guide
   - Write tutorials for key use cases
   - Document API reference

3. **Performance Optimization**
   - Profile code performance
   - Optimize critical paths
   - Implement parallelization

## Phase 6: Final Review and Cleanup
1. **Code Audit**
   - Review entire codebase
   - Identify unused or redundant code
   - Check for code quality issues

2. **Cleanup**
   - Archive unused components
   - Remove dead code
   - Standardize code style
   - Document changes

# Logical Dependency Chain

## Core Foundation (Must Build First)
1. **Graph Module**: Foundation for all operations
   - Base graph class
   - Directed graph implementation
   - Causal graph extension

2. **Graph Factory**: Needed for test data generation
   - Random graph generators
   - Task family generation

3. **Causal Environments**: Required for interventions and sampling
   - SCM implementation
   - Intervention handlers
   - Data samplers

## Algorithm Layer (Depends on Foundation)
1. **Neural Network Components**: Required for meta-learning approach
   - GNN encoders/decoders
   - Training infrastructure

2. **Discovery Module**: Builds on neural components and graphs
   - Neural discovery models
   - Amortized methods

3. **Optimization Module**: Requires graph and environment modules
   - Acquisition functions
   - Surrogate models

## Meta-Learning Layer (Depends on Algorithm Layer)
1. **Meta-Learning Core**: Builds on neural components
   - MAML implementation
   - Task representation

2. **Meta-CBO**: Combines all previous components
   - Task embeddings
   - Graph prototypes
   - Cross-task transfer

## User-Facing Components (Final Layer)
1. **Examples and Demos**: Demonstrates the capabilities
   - Synthetic graph generation
   - Intervention-based discovery
   - Meta-CBO examples

2. **Documentation**: Makes the system usable
   - API documentation
   - Tutorials
   - User guides

# Risks and Mitigations

## Technical Challenges

### 1. Complex Meta-Learning Architecture
**Risk**: The meta-learning components are complex and may be difficult to implement correctly.
**Mitigation**: 
- Start with simplified versions and gradually add complexity
- Implement extensive unit tests for each component
- Create visualization tools to debug the meta-learning process

### 2. Graph Neural Network Performance
**Risk**: GNNs may not generalize well across different graph structures.
**Mitigation**:
- Experiment with different GNN architectures (GCN, GAT, GIN)
- Implement regularization techniques specific to graphs
- Use extensive validation on diverse graph families

### 3. Integration Challenges
**Risk**: Integrating all components into a cohesive system may be challenging.
**Mitigation**:
- Define clear interfaces between components early
- Create integration tests for component combinations
- Implement a modular design with well-defined boundaries

## MVP Strategy

### 1. Minimal Viable Architecture
**Risk**: Trying to implement too much at once could delay progress.
**Mitigation**:
- Define a minimal set of features for a working prototype
- Focus on a single meta-learning approach initially (MAML)
- Prioritize components that demonstrate end-to-end functionality

### 2. Technical Debt
**Risk**: Quick implementation may lead to technical debt.
**Mitigation**:
- Establish coding standards from the beginning
- Schedule regular refactoring sessions
- Maintain comprehensive test coverage

### 3. Algorithm Scalability
**Risk**: Algorithms may not scale to larger graphs or more complex tasks.
**Mitigation**:
- Test with progressively larger graphs during development
- Implement efficient data structures for graph operations
- Use minibatch processing where appropriate

## Resource Constraints

### 1. Computational Resources
**Risk**: Meta-learning may require significant computational resources.
**Mitigation**:
- Implement efficient data loading and processing
- Use gradient checkpointing for memory-intensive operations
- Design for distributed training capability

### 2. Development Complexity
**Risk**: The system is complex and may require specialized knowledge.
**Mitigation**:
- Create detailed documentation for each component
- Implement example usage for all major components
- Use dependency injection to allow component substitution

# Appendix

## Example: Meta-CBO with Graph Factory

```python
# Example workflow using Graph Factory and Meta-CBO

from causal_meta.graph.generators.factory import GraphFactory
from causal_meta.meta_learning import MetaCBO
from causal_meta.environments import SCM
import matplotlib.pyplot as plt

# 1. Create graph factory instance with desired configurations
graph_factory = GraphFactory(
    default_nodes=10,
    default_edge_probability=0.3,
    default_mechanism_type='nonlinear',
    default_noise_type='gaussian'
)

# 2. Generate a family of related tasks using factory methods
# Generate base graph
base_graph = graph_factory.create_random_graph()

# Generate family of related graphs (variations of base graph)
task_family = graph_factory.create_task_family(
    base_graph=base_graph,
    num_tasks=5,
    edge_perturbation_prob=0.1,
    mechanism_perturbation_factor=0.2
)

# 3. Initialize Meta-CBO with neural components
meta_cbo = MetaCBO(
    structure_encoder=GNNEncoder(hidden_dim=64),
    posterior_network=AmortizedPosterior(hidden_dim=128),
    surrogate_network=SurrogateModel(hidden_dim=64),
    acquisition=EntropyAcquisition(),
    meta_learning=MAML(adaptation_steps=5, alpha=0.1)
)

# 4. Meta-train on task family
meta_cbo.meta_train(
    tasks=task_family,
    iterations=1000,
    batch_size=16
)

# 5. Generate new test task using factory
# We can create specific test cases
test_task = graph_factory.create_predefined_graph(
    graph_type='chain',  # Predefined graph structure
    add_noise_edges=True,
    mechanism_type='nonlinear'
)

# 6. Fast adaptation to new task
adapted_model = meta_cbo.adapt(
    task=test_task,
    observations=test_task.sample_observations(n=100),
    interventions=test_task.sample_interventions(n=10)
)

# 7. Visualize results
fig, axes = plt.subplots(1, 2, figsize=(12, 6))
axes[0].imshow(test_task.adjacency_matrix)
axes[0].set_title("True Causal Graph")
axes[1].imshow(adapted_model.estimated_adjacency)
axes[1].set_title("Estimated Graph (Meta-CBO)")
plt.show()
```

## Technical Specifications

### Graph Factory API

```python
class GraphFactory:
    def __init__(
        self, 
        default_nodes=10, 
        default_edge_probability=0.3,
        default_mechanism_type='nonlinear',
        default_noise_type='gaussian'
    ):
        """Initialize the graph factory with default parameters."""
        pass
    
    def create_random_graph(
        self, 
        nodes=None, 
        edge_probability=None,
        mechanism_type=None,
        noise_type=None
    ):
        """Create a random Erdős–Rényi graph."""
        pass
    
    def create_scale_free_graph(
        self, 
        nodes=None, 
        alpha=0.41,
        beta=0.54,
        gamma=0.05,
        mechanism_type=None,
        noise_type=None
    ):
        """Create a scale-free network using Barabási–Albert model."""
        pass
    
    def create_predefined_graph(
        self,
        graph_type,  # 'chain', 'fork', 'collider', etc.
        nodes=None,
        add_noise_edges=False,
        noise_edge_probability=0.1,
        mechanism_type=None,
        noise_type=None
    ):
        """Create a predefined graph structure."""
        pass
    
    def create_task_family(
        self,
        base_graph,
        num_tasks,
        edge_perturbation_prob=0.1,
        mechanism_perturbation_factor=0.2,
        noise_perturbation_factor=0.1
    ):
        """Create a family of related graphs based on a base graph."""
        pass
```

### Meta-CBO API

```python
class MetaCBO:
    def __init__(
        self,
        structure_encoder,
        posterior_network,
        surrogate_network,
        acquisition,
        meta_learning
    ):
        """Initialize Meta-CBO with neural components."""
        pass
    
    def meta_train(
        self,
        tasks,
        iterations,
        batch_size,
        learning_rate=0.001,
        validation_tasks=None,
        checkpoint_interval=100
    ):
        """Meta-train on a family of tasks."""
        pass
    
    def adapt(
        self,
        task,
        observations,
        interventions=None,
        adaptation_steps=5,
        learning_rate=0.01
    ):
        """Fast adaptation to a new task."""
        pass
    
    def evaluate(
        self,
        task,
        metric='structure',  # 'structure', 'intervention', 'target'
        num_samples=100
    ):
        """Evaluate performance on a task."""
        pass
    
    def optimize_interventions(
        self,
        task,
        target_node,
        num_interventions,
        batch_size=1,
        objective='minimize'  # 'minimize', 'maximize'
    ):
        """Run interventions to optimize a target variable."""
        pass
```
</PRD>